{"meta":{"title":"Hongker的博客","subtitle":"Golang,PHP工程师","description":"做喜欢做的事,不断提高自身的水平。","author":"hongker","url":"https://hongker.github.io"},"pages":[],"posts":[{"title":"服务化03-Etcd的服务注册与发现","slug":"service-etcd","date":"2021-04-23T22:48:21.000Z","updated":"2021-04-24T13:50:38.008Z","comments":true,"path":"2021/04/24/service-etcd/","link":"","permalink":"https://hongker.github.io/2021/04/24/service-etcd/","excerpt":"本文介绍如何通过etcd实现服务注册与发现。 Etcd 一个高可用的分布式键值(key-value)数据库。etcd内部采用raft协议作为一致性算法，etcd基于Go语言实现。 服务注册与发现 服务注册A服务启动时，将当前服务运行的IP和Port提交到Etcd保存，key为ServiceA。 服务发现B服务需要调用A服务的接口时，去Etcd通过ServiceA这个key，找到存储的服务A的地址，即可发起调用。 服务注销A服务现在要重启，就要在停止前主动注销。等待重启后再次注册即可。 接下来我们来通过etcd实现：服务注册/服务发现/服务注销","text":"本文介绍如何通过etcd实现服务注册与发现。 Etcd 一个高可用的分布式键值(key-value)数据库。etcd内部采用raft协议作为一致性算法，etcd基于Go语言实现。 服务注册与发现 服务注册A服务启动时，将当前服务运行的IP和Port提交到Etcd保存，key为ServiceA。 服务发现B服务需要调用A服务的接口时，去Etcd通过ServiceA这个key，找到存储的服务A的地址，即可发起调用。 服务注销A服务现在要重启，就要在停止前主动注销。等待重启后再次注册即可。 接下来我们来通过etcd实现：服务注册/服务发现/服务注销 实现 首先初始化etcd的客户端: 123456789101112131415161718192021222324252627282930import ( \"go.etcd.io/etcd/clientv3\" \"time\")var cli *clientv3.Client // etcd客户端// Connect 连接func Connect(endpoints []string, timeout time.Duration) (error) &#123; instance, err := clientv3.New(clientv3.Config&#123; Endpoints: endpoints, DialTimeout: timeout, &#125;) if err != nil &#123; return err &#125; cli = instance return nil&#125;// KV 键值存储func KV() clientv3.KV &#123; return clientv3.NewKV(cli)&#125;// Lease 租约，控制过期时间func Lease() clientv3.Lease &#123; return clientv3.NewLease(cli)&#125; 服务组件： 实现服务注册、发现、注销的功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122import ( \"context\" \"encoding/json\" \"fmt\" \"go.etcd.io/etcd/clientv3\" \"log\")// Servicetype Service struct &#123; // 前缀 prefix string&#125;// Node 服务节点type Node struct &#123; Name string `json:\"name\"` // 服务名称,比如:order ID int `json:\"id\"` // 节点ID: 建议从1开始 Address string `json:\"address\"` // 服务地址，如：127.0.0.1:8080 Ttl int64 // 检测时间，单位:秒。比如设置5秒，那如果节点宕机5秒，这个节点就自动注销了&#125;// Key 节点的唯一键名func (node Node) Key() string &#123; return fmt.Sprintf(\"%s/%d\", node.Name, node.ID)&#125;// String 节点的存储数据，通过json序列化实现func (node Node) String() string &#123; b, _ := json.Marshal(node) return string(b)&#125;// withPrefix 拼接前缀func (service *Service) withPrefix(name string) string &#123; return fmt.Sprintf(\"/%s/%s\", service.prefix, name)&#125;// Register 服务注册func (service *Service) Register(node Node) error &#123; ctx := context.Background() // 申请lease leaseResp, err := Lease().Grant(ctx, node.Ttl) if err != nil &#123; return fmt.Errorf(\"unable to grant lease: %v\", err) &#125; // 保存数据 _, err = KV().Put(ctx, service.withPrefix(node.Key()), node.String(), clientv3.WithLease(leaseResp.ID)) if err != nil &#123; return fmt.Errorf(\"unable to put value: %v\", err) &#125; // 保持连接 if err := service.keepAlive(leaseResp.ID); err != nil &#123; return fmt.Errorf(\"unable to keep alive: %v\", err) &#125; return nil&#125;// Unregister 服务注销func (service *Service) Unregister(node Node) error &#123; if node.Name == \"\" &#123; return fmt.Errorf(\"unknown service name\") &#125; _, err := KV().Delete(context.TODO(), service.withPrefix(node.Key())) if err != nil &#123; return err &#125; return nil&#125;// Discovery 服务发现func (service *Service) Discovery(name string) ([]Node, error) &#123; resp, err := KV().Get(context.Background(), service.withPrefix(name), clientv3.WithPrefix()) if err != nil &#123; return nil, err &#125; nodes := make([]Node, 0, resp.Count) if resp.Count == 0 &#123; return nodes, nil &#125; for _, kv := range resp.Kvs &#123; var node Node if err := json.Unmarshal(kv.Value, &amp;node); err != nil &#123; continue &#125; nodes = append(nodes, node) &#125; return nodes, err&#125;// keepAlive 保持会话func (service *Service) keepAlive(leaseId clientv3.LeaseID) error &#123; keepAliveRes, err := Lease().KeepAlive(context.TODO(), leaseId) if err != nil &#123; return err &#125; go func() &#123; for &#123; select &#123; case ret := &lt;-keepAliveRes: if ret != nil &#123; log.Println(\"keep alive success\") &#125; &#125; &#125; &#125;() return nil&#125;// NewService 实例化func NewService(prefix string) *Service &#123; return &amp;Service&#123;prefix: prefix&#125;&#125; 使用 123456789101112131415161718192021func main() &#123; // 连接etcd if err := Connect([]string&#123;\"127.0.0.1:2379\"&#125;, time.Second*10); err != nil &#123; panic(err.Error()) &#125; service := NewService(\"service\") // 服务注册：注册一个叫order的服务节点 err := service.Register(Node&#123; Name: \"order\", ID: 1, Address: \"http://127.0.0.1:8081\", Ttl: 10, &#125;) // 服务发现：获取到节点信息，返回的是节点数组 node, err := service.Discovery(\"order\") // 服务注销: 程序关闭会自动注销，但是有延迟，如果想要立马注销，就调用Unregister方法 err = service.Unregister(Node&#123;Name: \"order\", ID: 1&#125;)&#125; 优化服务发现不需要每次都去查询etcd里的数据，可以通过定期查询的方式去获取数据。但是如果某个节点已注销，这样会导致信息更新滞后，请求到已注销的节点上，出现异常。所以我们通过监听的方式来保持信息同步，这样可以做到实时性更新。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// Watcher 监听器type Watcher struct &#123; service *Service // service name string // 服务名称 once sync.Once // once,保证只有第一次需要通过Discovery获取节点信息 nodes []Node // 缓存&#125;// NewWatcher 实例化watcherfunc NewWatcher(service *Service, name string) *Watcher &#123; return &amp;Watcher&#123; service: service, name: name, nodes: make([]Node, 10), &#125;&#125;// 获取节点func (watcher *Watcher) GetNodes() []Node &#123; watcher.once.Do(func() &#123; watcher.nodes, _ = watcher.service.Discovery(watcher.name) &#125;) return watcher.nodes&#125;// Watch 监听服务节点的注册与注销func (watcher *Watcher) Watch() &#123; rch := cli.Watch(context.Background(), watcher.service.withPrefix(watcher.name), clientv3.WithPrefix()) for resp := range rch &#123; for _, ev := range resp.Events &#123; switch ev.Type &#123; case mvccpb.PUT: // 新增或更新事件 // 解析node节点 var node Node if err := json.Unmarshal(ev.Kv.Value, &amp;node); err != nil &#123; continue &#125; if ev.Kv.Version == 1 &#123; // 首次创建,直接append watcher.nodes = append(watcher.nodes, node) continue &#125; for idx, n := range watcher.nodes &#123; if n.ID == node.ID &#123; watcher.nodes[idx].Address = node.Address break &#125; &#125; case mvccpb.DELETE: // 删除事件 nodes := make([]Node, 0, len(watcher.nodes)) for _, n := range watcher.nodes &#123; if string(ev.Kv.Key) != watcher.service.withPrefix(n.Key()) &#123; nodes = append(nodes, n) &#125; &#125; watcher.nodes = nodes &#125; &#125; &#125;&#125;func main() &#123; watcher := NewWatcher(service, \"order\") // 开启协程来负责监听 go watcher.Watch() for &#123; // 模拟每个一秒获取一次,来观察服务节点的注册与注销是否生效 time.Sleep(time.Second) fmt.Println(watcher.GetNodes()) &#125;&#125;","categories":[],"tags":[{"name":"micro-service","slug":"micro-service","permalink":"https://hongker.github.io/tags/micro-service/"}]},{"title":"Golang(27)-websocket进阶","slug":"golang-websocket-epoll","date":"2021-04-22T13:14:05.000Z","updated":"2021-04-22T23:06:12.957Z","comments":true,"path":"2021/04/22/golang-websocket-epoll/","link":"","permalink":"https://hongker.github.io/2021/04/22/golang-websocket-epoll/","excerpt":"之前有简单的介绍过websocket的基本用法，本文将介绍在golang里如何处理大量websocket连接。 初阶现在有一个即时通讯的需求，我们实现一个简单的websocket服务如下所示：1234567891011121314151617181920212223242526272829303132333435363738package mainimport ( \"fmt\" \"github.com/gorilla/websocket\" \"log\" \"net/http\")func main() &#123; http.ListenAndServe(\":8085\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; // 升级为websocket连接 conn, err := NewWebsocketConnection(w, r) if err != nil &#123; http.NotFound(w, r) return &#125; go func() &#123; // 开启一个协程去处理连接 defer conn.Close() // 连接结束时需要关闭 for &#123; _, msg, err := conn.ReadMessage() // 接受消息 if err != nil &#123; log.Println(\"unable to read message:\", err.Error()) return &#125; // 向客户端回话,或者其他业务逻辑 reply := fmt.Sprintf(\"received:%s\", string(msg)) if err := conn.WriteMessage(websocket.TextMessage, []byte(reply)); err != nil &#123; log.Printf(\"unable to send message\") &#125; &#125; &#125;() &#125;))&#125;var u = websocket.Upgrader&#123;CheckOrigin: func(r *http.Request) bool &#123; return true &#125;&#125; // use default options// WebsocketConn return web socket connectionfunc NewWebsocketConnection(w http.ResponseWriter, r *http.Request) (*websocket.Conn, error) &#123; return u.Upgrade(w, r, nil)&#125; 通过wscat -c localhost:8085连接到websocket,并发送hello和123,得到测试结果如下：12345&gt; hello&lt; received:hello&gt; 123&lt; received:123 思考 如果我们的服务需要面向100w个用户时，会发生什么情况？121.每创建一个websocket连接，按照以上的实现方式，我们就需要创建一个goroutine来接收客户端的信息。一个goroutine大概需要2~8kb的内存2.如果是同时有100万个连接，假设每个goroutine占用4kb内存，那么内存消耗大概在：4kb*1000000=4G。 光是保持连接，不做任何处理就已经消耗了4G的内存，还是挺恐怖的，所以下面开始介绍用epoll模型来解决这个问题。","text":"之前有简单的介绍过websocket的基本用法，本文将介绍在golang里如何处理大量websocket连接。 初阶现在有一个即时通讯的需求，我们实现一个简单的websocket服务如下所示：1234567891011121314151617181920212223242526272829303132333435363738package mainimport ( \"fmt\" \"github.com/gorilla/websocket\" \"log\" \"net/http\")func main() &#123; http.ListenAndServe(\":8085\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; // 升级为websocket连接 conn, err := NewWebsocketConnection(w, r) if err != nil &#123; http.NotFound(w, r) return &#125; go func() &#123; // 开启一个协程去处理连接 defer conn.Close() // 连接结束时需要关闭 for &#123; _, msg, err := conn.ReadMessage() // 接受消息 if err != nil &#123; log.Println(\"unable to read message:\", err.Error()) return &#125; // 向客户端回话,或者其他业务逻辑 reply := fmt.Sprintf(\"received:%s\", string(msg)) if err := conn.WriteMessage(websocket.TextMessage, []byte(reply)); err != nil &#123; log.Printf(\"unable to send message\") &#125; &#125; &#125;() &#125;))&#125;var u = websocket.Upgrader&#123;CheckOrigin: func(r *http.Request) bool &#123; return true &#125;&#125; // use default options// WebsocketConn return web socket connectionfunc NewWebsocketConnection(w http.ResponseWriter, r *http.Request) (*websocket.Conn, error) &#123; return u.Upgrade(w, r, nil)&#125; 通过wscat -c localhost:8085连接到websocket,并发送hello和123,得到测试结果如下：12345&gt; hello&lt; received:hello&gt; 123&lt; received:123 思考 如果我们的服务需要面向100w个用户时，会发生什么情况？121.每创建一个websocket连接，按照以上的实现方式，我们就需要创建一个goroutine来接收客户端的信息。一个goroutine大概需要2~8kb的内存2.如果是同时有100万个连接，假设每个goroutine占用4kb内存，那么内存消耗大概在：4kb*1000000=4G。 光是保持连接，不做任何处理就已经消耗了4G的内存，还是挺恐怖的，所以下面开始介绍用epoll模型来解决这个问题。 Epoll epoll是Linux内核为处理大批量文件描述符而作了改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。 Epoll提供了3个方法：Create、Ctl、Wait Create: 创建epoll句柄，返回文件标识符(fd)。 Ctl: 根据epoll的fd，完成注册事件、删除事件、更新事件。 Wait: 返回就绪事件。 我们可以通过epoll模型，来管理websocket连接，用来替代通过goroutine去监听的方案。 实现如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package mainimport ( \"fmt\" \"github.com/gorilla/websocket\" \"golang.org/x/sys/unix\" \"log\" \"net\" \"net/http\" \"reflect\" \"sync\" \"syscall\")func main() &#123; // 创建epoll epollFd, err := unix.EpollCreate(1) if err != nil &#123; log.Fatalf(\"unable to create epoll:%v\\n\", err) &#125; connections := make(map[int32]*websocket.Conn, 1000000) var mu sync.Mutex ch := make(chan int32, 50) // 开启协程，处理接受到的信息 go func() &#123; for &#123; select &#123; case fd := &lt;- ch: conn := connections[fd] if conn == nil &#123; continue &#125; // 接收消息 _, message, err := conn.ReadMessage() if err != nil &#123; log.Println(\"unable to read message:\", err.Error()) _ = conn.Close() // 删除epoll事件 if err := unix.EpollCtl(epollFd, syscall.EPOLL_CTL_DEL, int(fd), nil); err != nil &#123; log.Println(\"unable to remove event\") &#125; &#125; // 给客户端回消息 if err := conn.WriteMessage(websocket.TextMessage, []byte(fmt.Sprintf(\"receive:%s\", string(message)))); err != nil &#123; log.Println(\"unable to send message:\", err.Error()) &#125; &#125; &#125; &#125;() // 开启一个协程监听epoll事件 go func() &#123; for &#123; // 声明50个events，表明每次最多获取50个事件 events := make([]unix.EpollEvent, 50) // 每100ms执行一次 n, err := unix.EpollWait(epollFd, events, 100) if err != nil &#123; log.Println(\"epoll wait:\", err.Error()) continue &#125; // 取出来的是就绪的websocket连接的fd for i := 0; i &lt; n; i++ &#123; if events[i].Fd == 0 &#123; continue &#125; ch &lt;- events[i].Fd // 通过channel传递到另一个goroutine处理 &#125; &#125; &#125;() // 绑定http服务 http.ListenAndServe(\":8085\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; // 升级为websocket连接 conn, err := NewWebsocketConnection(w, r) if err != nil &#123; http.NotFound(w, r) return &#125; // 获取文件标识符 fd := GetSocketFD(conn.UnderlyingConn()) // 注册事件 if err := unix.EpollCtl(epollFd, unix.EPOLL_CTL_ADD, int(fd), &amp;unix.EpollEvent&#123;Events: unix.POLLIN | unix.POLLHUP, Fd: fd&#125;); err != nil &#123; log.Println(\"unable to add event:%v\", err.Error()) return &#125; // 保存到map里 mu.Lock() connections[fd] = conn mu.Unlock() &#125;))&#125;var u = websocket.Upgrader&#123;CheckOrigin: func(r *http.Request) bool &#123; return true &#125;&#125; // use default options// WebsocketConn return web socket connectionfunc NewWebsocketConnection(w http.ResponseWriter, r *http.Request) (*websocket.Conn, error) &#123; return u.Upgrade(w, r, nil)&#125;// GetSocketFD get socket connection fdfunc GetSocketFD(conn net.Conn) int32 &#123; tcpConn := reflect.Indirect(reflect.ValueOf(conn)).FieldByName(\"conn\") fdVal := tcpConn.FieldByName(\"fd\") pfdVal := reflect.Indirect(fdVal).FieldByName(\"pfd\") return int32(pfdVal.FieldByName(\"Sysfd\").Int())&#125; 从上面的代码可以看到，我们只开启了两个gouroutine。一个负责监听epoll的就绪事件，一个负责处理websocket的消息。这样就能省下服务器的内存空间。 拓展我在github上开源了一个websocket框架的项目，基于epoll模型和workerPool实现。想要了解更多的请查看: https://github.com/ebar-go/websocket","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang26-内存模型","slug":"golang-mem","date":"2021-04-11T15:04:46.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2021/04/11/golang-mem/","link":"","permalink":"https://hongker.github.io/2021/04/11/golang-mem/","excerpt":"本文介绍Golang的内存模型相关知识。 什么是go的内存模型 指定了一系列条件，在这些条件下，可以保证在协程中对变量的读取操作可以观察到其他协程对同一变量写操作的结果，这就是go内存模型。 为什么需要这些条件？因为编译器无法保证指令执行顺序与程序书写顺序一致。 如下示例：12345678910package mainfunc main() &#123; i := 5 go func() &#123; i = 10 &#125;() for j := 0;j&lt;100;j++ &#123; fmt.Println(i) &#125;&#125; 多运行几次，会发现结果可能不同，但可以发现，部分Println打印的i变量依然是5，说明未能立观察到协程对i变量的写操作。 所以我们为了保证协程间的变量读取的可观察，就需要建立Happen Before关系的同步事件。也就是内存模型设定的条件。 Happen Before以下几种方式，可以建立Happen Before关系的同步事件:123451.init函数2.创建/销毁goroutine3.channel4.锁5.Once","text":"本文介绍Golang的内存模型相关知识。 什么是go的内存模型 指定了一系列条件，在这些条件下，可以保证在协程中对变量的读取操作可以观察到其他协程对同一变量写操作的结果，这就是go内存模型。 为什么需要这些条件？因为编译器无法保证指令执行顺序与程序书写顺序一致。 如下示例：12345678910package mainfunc main() &#123; i := 5 go func() &#123; i = 10 &#125;() for j := 0;j&lt;100;j++ &#123; fmt.Println(i) &#125;&#125; 多运行几次，会发现结果可能不同，但可以发现，部分Println打印的i变量依然是5，说明未能立观察到协程对i变量的写操作。 所以我们为了保证协程间的变量读取的可观察，就需要建立Happen Before关系的同步事件。也就是内存模型设定的条件。 Happen Before以下几种方式，可以建立Happen Before关系的同步事件:123451.init函数2.创建/销毁goroutine3.channel4.锁5.Once init函数包a引入包b，那么包b的init就会happen before 包a的init函数。如下： 1234567// a.gopackage aimport \"b\"func init() &#123; fmt.Println(\"a\") b.DoSomething()&#125; 12345678// b.gopackage bfunc init() &#123; fmt.Println(\"b\")&#125;func DoSomething() &#123; fmt.Println(\"test\")&#125; 输出如下:123batest 创建/销毁Goroutine 创建goroutine happen before goroutine执行 goroutine执行 happen before goroutine销毁 channel 对于无缓冲的channel，recv操作happen before send123456789101112131415package mainimport \"fmt\"import \"time\"func main() &#123; i := make(chan int) go func() &#123; fmt.Println(\"send\") i &lt;- 10 &#125;() go func() &#123; fmt.Println(\"recv\") fmt.Println(&lt;-i) &#125;() time.Sleep(time.Second)&#125; 输出结果：123sendrecv10 关闭channel的操作 happen before 接受到0值。 对于容量为m的channel,第n次recv是happen before 第n+m次send1234567891011121314151617181920212223package mainimport \"fmt\"import \"time\"func main() &#123; ch := make(chan int, 5) go func() &#123; for i:=0;i&lt;10;i++ &#123; time.Sleep(100) fmt.Println(\"send\", i) ch &lt;- i &#125; close(ch) &#125;() go func() &#123; for i := range ch &#123; time.Sleep(100) fmt.Println(\"receive\", i) &#125; &#125;() time.Sleep(time.Second * 2)&#125; 输出结果发现，对于长度为5的channel,第1次接收比6次发送要先执行。 锁 对于任意的sync.Mutex或者sync.RWMutex,n&lt;m时,n次Unlock的调用happen beforeLock的调用。 对于sync.RWMutex,第n次Unlockhappen before第n次RLock，而第n次RUnlock 又是happen before第n+1次Lock sync.Once 对于fn()的单个调用会happen before所有的once.Do(fn)返回之前发生12345678910111213package mainimport \"fmt\"import \"sync\"func main() &#123; var o sync.Once i := 5 for j := 0;j&lt;3;j++ &#123; o.Do(func() &#123; i += 1 &#125;) fmt.Println(i) &#125;&#125; 执行结果：123666 备注虽然这些都是go开发中一般都知道的常识，但是我们还是需要了解，为什么会这样，为什么需要这样？","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"kubernetes介绍与安装","slug":"kubernetes-introduce","date":"2021-04-06T12:00:33.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2021/04/06/kubernetes-introduce/","link":"","permalink":"https://hongker.github.io/2021/04/06/kubernetes-introduce/","excerpt":"","text":"本文作为kubernetes系列的开篇，主要介绍一些相关概念。 什么是kubernetes kubernetes，简称K8s。是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。 在服务化时代，每个公司都会有很多个分散的项目，我们通过k8s来统一管理这些应用，不但可以提高服务的部署效率，还能提高服务的横向扩展能力。 k8s &amp; docker docker: 应用容器引擎，作为目标程序的载体，可移植，达到运行环境一致性。 k8s: 容器集群管理系统，实现容器集群的自动化部署，扩缩容，负载均衡等。 在我看来,docker就像“出租车”，k8s就是“出租车管理公司”。 相关概念Master集群控制节点。负责整个集群服务的的管理和控制。Mater节点上运行以下组件： kube-apiserver: http服务，对k8s中所有资源进行管理(增删改查)，是集群控制入口进程。kubectl是访问apiserver的客户端工具。 kube-control-manager: apiserver为对外开放的应用服务，与之相对的后台服务就是kube-control-manager,负责k8s里所有资源对象的控制。 kube-schedule: 资源调度器，负责调度pod到node节点上。 etcd: 存储各种资源的状态数据。Node除master节点外的其他机器节点。是集群的工作负载节点。Node节点上运行以下组件： kubelet: 负责pod对应的容器创建、启动、停止、资源监控等任务。 kube-proxy: 实现service的通信与负载均衡功能。 docker: 容器runtime。 Deployment当我们需要创建pod来运行应用的时候，不是直接创建Pod,而是创建一个Deployment，用它负责创建和更新应用。可以理解为pod的”管家”。 Service因为pod可能会不停的创建和销毁，其IP也会随之变化，我们想要在外部固定的访问pod上运行的应用，就需要service来暴露pod里的应用。 service定义了一组pod的逻辑集合和访问策略，不管内部的pod如何变化，我们只要保证service的访问方式不变，其内部会通过服务注册/发现来定位到pod应用。 Pod 在k8s里最小的逻辑运行单元，简单的说就是容器集合。 相同pod里运行的多个容器，共享uts、net、ipc空间等。 安装k8s集群环境通过kind安装k8s cluster,下载：123curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.10.0/kind-linux-amd64chmod +x ./kindmv ./kind /usr/bin/kind 创建集群 1kind create cluster 查看集群信息 1kubectl cluster-info 查看节点 1kubectl get nodes 删除集群 1kind delete cluster k8s环境已准备就绪。下一章将介绍如何用k8s部署go的web应用，敬请期待！","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hongker.github.io/tags/kubernetes/"}]},{"title":"Golang代码优化25-依赖注入","slug":"golang-di","date":"2021-03-31T06:13:59.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2021/03/31/golang-di/","link":"","permalink":"https://hongker.github.io/2021/03/31/golang-di/","excerpt":"本文介绍在golang中如何通过依赖注入(Dependency Inject，简称DI)管理全局服务。 什么是DI 把有依赖关系的类放到容器中，解析出这些类的实例，就是依赖注入。 DI的作用 反面例子现在我们有一个http应用，先来看下常规开发的main.go:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970func main() &#123; // 生成config实例 config := NewConfig() // 连接数据库 db, err := ConnectDatabase(config) // 判断是否有错误 if err != nil &#123; panic(err) &#125; // 生成repository实例，用于获取person数据，参数是db personRepository := repo.NewPersonRepository(db) // 生成service实例，用于调用repository的方法 personService := service.NewPersonService(config, personRepository) // 生成http服务实例 server := NewServer(config, personService) // 启动http服务 server.Run()&#125;// Servertype Server struct &#123; config *config.Config personService *service.PersonService&#125;// Handlerfunc (s *Server) Handler() http.Handler &#123; mux := http.NewServeMux() mux.HandleFunc(\"/people\", s.people) return mux&#125;// Runfunc (s *Server) Run() &#123; httpServer := &amp;http.Server&#123; Addr: \":\" + s.config.Port, Handler: s.Handler(), &#125; httpServer.ListenAndServe()&#125;// peoplefunc (s *Server) people(w http.ResponseWriter, r *http.Request) &#123; people := s.personService.FindAll() bytes, _ := json.Marshal(people) w.Header().Set(\"Content-Type\", \"application/json\") w.WriteHeader(http.StatusOK) w.Write(bytes)&#125;// NewServerfunc NewServer(config *config.Config, service *service.PersonService) *Server &#123; return &amp;Server&#123; config: config, personService: service, &#125;&#125;// 其他new方法func NewConfig() *Config &#123; // ...&#125;func ConnectDatabase(config *config.Config) (*sql.DB, error) &#123; // ... &#125;func NewPersonRepository(database *sql.DB) *PersonRepository &#123; // ... &#125;func NewPersonService(config *config.Config, repository *repo.PersonRepository) *PersonService &#123; // ...&#125; 直接看main(),你会发现包含清晰的初始化流程。 但是仔细想想，随着业务的扩展，我们如果把所有实例都在main函数里生成，main函数将变得越来越臃肿。 而且这些基础服务的实例，如果在其他包里需要引入，你就得给每个需要用到服务的地方，通过参数的方式传递。类似service.NewPersonService(config, personRepository)方法，将config和personRepository传递到service包。 问题 如何让main函数变得优雅? 如何管理全局服务实例? 如何减少重复实例化对象时传递如config这样的基础实例?","text":"本文介绍在golang中如何通过依赖注入(Dependency Inject，简称DI)管理全局服务。 什么是DI 把有依赖关系的类放到容器中，解析出这些类的实例，就是依赖注入。 DI的作用 反面例子现在我们有一个http应用，先来看下常规开发的main.go:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970func main() &#123; // 生成config实例 config := NewConfig() // 连接数据库 db, err := ConnectDatabase(config) // 判断是否有错误 if err != nil &#123; panic(err) &#125; // 生成repository实例，用于获取person数据，参数是db personRepository := repo.NewPersonRepository(db) // 生成service实例，用于调用repository的方法 personService := service.NewPersonService(config, personRepository) // 生成http服务实例 server := NewServer(config, personService) // 启动http服务 server.Run()&#125;// Servertype Server struct &#123; config *config.Config personService *service.PersonService&#125;// Handlerfunc (s *Server) Handler() http.Handler &#123; mux := http.NewServeMux() mux.HandleFunc(\"/people\", s.people) return mux&#125;// Runfunc (s *Server) Run() &#123; httpServer := &amp;http.Server&#123; Addr: \":\" + s.config.Port, Handler: s.Handler(), &#125; httpServer.ListenAndServe()&#125;// peoplefunc (s *Server) people(w http.ResponseWriter, r *http.Request) &#123; people := s.personService.FindAll() bytes, _ := json.Marshal(people) w.Header().Set(\"Content-Type\", \"application/json\") w.WriteHeader(http.StatusOK) w.Write(bytes)&#125;// NewServerfunc NewServer(config *config.Config, service *service.PersonService) *Server &#123; return &amp;Server&#123; config: config, personService: service, &#125;&#125;// 其他new方法func NewConfig() *Config &#123; // ...&#125;func ConnectDatabase(config *config.Config) (*sql.DB, error) &#123; // ... &#125;func NewPersonRepository(database *sql.DB) *PersonRepository &#123; // ... &#125;func NewPersonService(config *config.Config, repository *repo.PersonRepository) *PersonService &#123; // ...&#125; 直接看main(),你会发现包含清晰的初始化流程。 但是仔细想想，随着业务的扩展，我们如果把所有实例都在main函数里生成，main函数将变得越来越臃肿。 而且这些基础服务的实例，如果在其他包里需要引入，你就得给每个需要用到服务的地方，通过参数的方式传递。类似service.NewPersonService(config, personRepository)方法，将config和personRepository传递到service包。 问题 如何让main函数变得优雅? 如何管理全局服务实例? 如何减少重复实例化对象时传递如config这样的基础实例? 安装我使用的是uber的dig包1go get github.com/uber-go/dig 优化main函数12345678910111213141516171819202122232425262728// 构建一个DI容器func BuildContainer() *dig.Container &#123; container := dig.New() // 注入config的实例化方法 container.Provide(NewConfig) // 注入database的实例化方法 container.Provide(ConnectDatabase) // 注入repository的实例化方法 container.Provide(repo.NewPersonRepository) // 注入service的实例化方法 container.Provide(service.NewPersonService) // 注入server container.Provide(NewServer) return container&#125;func main() &#123; container := BuildContainer() err := container.Invoke(func(server *Server) &#123; server.Run() &#125;) if err != nil &#123; panic(err) &#125;&#125; 这样的main函数不需要包含任何基础实例的初始化和参数传递的过程，可以称之：Perfect! 下面是对main函数里基础服务注入的流程说明： BuildContainer，只将各个基础服务的实例化方法注入到容器里，还没有调用这些方法来实例化基础服务 container.Invoke,这里将会从容器里寻找server实例，来运行server.Run()。如果实例不存在，则调用其实例化的方法，也就是NewServer 因为NewServer(config *config.Config, service *service.PersonService) *Server依赖于config.Config和service.PersonService，故触发NewConfig和NewPersonService方法。 NewConfig不依赖与任何实例，故可以成功返回config.Config实例。 NewPersonService(config *config.Config, repository *repo.PersonRepository) *PersonService依赖config.Config和repo.PersonRepository,继而触发repo.NewPersonRepository去实例化repo.PersonRepository repo.NewPersonRepository方法依赖于db,故触发ConnectDatabase方法，用来连接数据库，实例化db实例 最后递归倒推回去，完成所有实例的初始化与注入，调用server.Run()方法启动http服务。 注意，有依赖的初始化方法，需要放在前置依赖注入之后，比如container.Provide(ConnectDatabase)就放在container.Provide(NewConfig)之后。如果找不到初始化需要的依赖对象，在Invoke时就会报错。 踩坑之前我通过下面的方式去获取容器里的基础实例：1234567891011package app// Config 配置文件func Config() (conf *config.Config) &#123; _ = container.Invoke(func(c *config.Config) &#123; conf = c &#125;) return&#125;// 其他packagefmt.Println(app.Config().GetString(\"someKey\")) 这样去获取基础实例是不正确的用法，因为dig底层是通过一个map来管理这些实例的，我们都知道map不是线程安全的，在频繁调用时偶尔会出现以下错误：1concurrent map writes 开发者回答如下：123Hey, dig is not intended to be invoked from your system&apos;s hot path. We expectit to be invoked at most once during startup, and definitely not concurrently.To discourage usage on the hot path, we have kept the APIs thread-unsafe. 参考官方git里的一个issue,里面的代码能重现该异常: Invoke not concurrency safe 所以，我们在使用dig注入的时候，将如repo.NewPersonRepository这样依赖Config和DB的实例函数，在main函数里通过container.Provide注入进去，这样仅调用一次，保证线程安全。","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang24-mongodb客户端","slug":"golang-mongodb","date":"2021-03-24T14:04:47.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2021/03/24/golang-mongodb/","link":"","permalink":"https://hongker.github.io/2021/03/24/golang-mongodb/","excerpt":"","text":"上一篇文章介绍了如何部署mongodb集群，本文介绍如何用mgo客户端操作mongodb。 安装1go get github.com/globalsign/mgo 连接mongo123456789101112131415161718import ( \"fmt\" \"github.com/globalsign/mgo\" \"log\")func main() &#123; dialInfo := &amp;mgo.DialInfo&#123; Addrs: []string&#123;\"172.17.0.1:27017\",\"172.17.0.1:27018\"&#125;, &#125; session ,err := mgo.DialWithInfo(dialInfo) if err != nil &#123; log.Fatalf(\"connect: %v\\n\", err) &#125; fmt.Println(session.DatabaseNames()) log.Println(\"connect success\")&#125; 查询1234567891011121314151617181920212223242526type User struct &#123; Name string `json:\"name\"`&#125;func Run(session *mgo.Session) &#123; collection := session.Copy().DB(\"demo\").C(\"user\") // 查看总数 count, err := collection.Count() if err != nil &#123; log.Fatalf(\"count: %v\\n\", err) &#125; log.Printf(\"collection count:%d\\n\", count) // 插入数据 if err := collection.Insert(&amp;User&#123;Name: \"bob\"&#125;); err != nil &#123; log.Fatalf(\"insert: %v\\n\", err) &#125; log.Println(\"insert success\") // 查询数据 entity := new(User) if err := collection.Find(bson.M&#123;\"name\":\"bob\"&#125;).One(entity); err != nil &#123; log.Fatalf(\"Find: %v\\n\", err) &#125; log.Printf(\"find user: %s\\n\", entity.Name)&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"服务化02-mongodb集群","slug":"service-mongodb","date":"2021-03-22T14:36:03.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2021/03/22/service-mongodb/","link":"","permalink":"https://hongker.github.io/2021/03/22/service-mongodb/","excerpt":"本文介绍mongodb集群的相关知识。 概念Replica Set 副本集：一个副本集就是一组 MongoDB 实例组成的集群，由一个主（Primary）服务器和多个备份（Secondary）服务器构成 节点（master）：主节点接收所有写入操作。主节点将对其数据集所做的所有更改记录到其 oplog。 副节点（secondary）：复制主节点的 oplog 并将操作应用到其数据集，如果主节点不可用，一个合格的副节点将被选为新的主节点。 仲裁节点（arbiter）：负载选举，当主节点不可用，它将从副节点中选一个作为主节点。","text":"本文介绍mongodb集群的相关知识。 概念Replica Set 副本集：一个副本集就是一组 MongoDB 实例组成的集群，由一个主（Primary）服务器和多个备份（Secondary）服务器构成 节点（master）：主节点接收所有写入操作。主节点将对其数据集所做的所有更改记录到其 oplog。 副节点（secondary）：复制主节点的 oplog 并将操作应用到其数据集，如果主节点不可用，一个合格的副节点将被选为新的主节点。 仲裁节点（arbiter）：负载选举，当主节点不可用，它将从副节点中选一个作为主节点。 目录结构123456.├── data # 数据│ ├── mongo1│ ├── mongo2│ └── mongo3└── docker-componse.yml 安装docker-compose.yml：1234567891011121314151617181920212223242526272829303132333435version: '3'services: mongo1: container_name: mongo1 image: mongo:4.4.4 restart: always ports: - '27017:27017' environment: - TZ=Asia/Shanghai volumes: - $PWD/mongo1/data:/data/db command: mongod --replSet mongo_cluster mongo2: container_name: mongo2 image: mongo:4.4.4 restart: always ports: - '27018:27017' environment: - TZ=Asia/Shanghai volumes: - $PWD/mongo2/data:/data/db command: mongod --replSet mongo_cluster mongo3: container_name: mongo3 image: mongo:4.4.4 restart: always ports: - '27019:27017' environment: - TZ=Asia/Shanghai volumes: - $PWD/mongo3/data:/data/db command: mongod --replSet mongo_cluster 启动:1docker-compose up -d 配置1234567891011121314151617181920docker exec -ti mongo_master bashmongocfg=&#123; &quot;_id&quot;: &quot;mongo_cluster&quot;, &quot;members&quot;:[&#123; _id:0, host:&quot;172.17.0.1:27017&quot;, priority: 2 &#125;,&#123; _id:1, host:&quot;172.17.0.1:27018&quot;, priority: 1 &#125;,&#123; _id:2, host:&quot;172.17.0.1:27019&quot;, arbiterOnly: true &#125;]&#125;rs.initiate(cfg) 最后得到结果:1234567891011&#123; \"ok\" : 1, \"$clusterTime\" : &#123; \"clusterTime\" : Timestamp(1616575307, 1), \"signature\" : &#123; \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) &#125; &#125;, \"operationTime\" : Timestamp(1616575307, 1)&#125; 同时也可以通过rs.status()查看集群状态","categories":[],"tags":[{"name":"micro-service","slug":"micro-service","permalink":"https://hongker.github.io/tags/micro-service/"}]},{"title":"Golang23-操作Elasticsearch","slug":"golang-elasticsearch","date":"2021-03-21T14:34:54.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2021/03/21/golang-elasticsearch/","link":"","permalink":"https://hongker.github.io/2021/03/21/golang-elasticsearch/","excerpt":"","text":"上一篇文章介绍了Elasticsearch集群相关的知识，本文介绍如何通过golang去处理elasticsearch数据。 安装1go get github.com/olivere/elastic/v7 连接es12345678910111213141516import ( \"fmt\" \"github.com/olivere/elastic/v7\" \"log\")func main() &#123; // 连接 var host = \"http://127.0.0.1:9200\" client, err := elastic.NewClient(elastic.SetURL(host), elastic.SetSniff(false)) if err != nil &#123; log.Fatalf(\"connect elasticsearch: %v\", err) &#125; log.Println(\"connect success\") fmt.Println(client)&#125; 创建索引1234567891011func CreateIndex(client *elastic.Client) &#123; ctx := context.Background() result, err := client.CreateIndex(\"blog\").Do(ctx) if err != nil &#123; log.Fatalf(\"create index: %v\", err) &#125; if !result.Acknowledged &#123; log.Fatalf(\"create index failed\") &#125; log.Println(\"create index success\")&#125; 插入数据12345678func InsertDoc(client *elastic.Client) &#123; indexName := \"blog\" response, err := client.Index().Index(indexName).BodyJson(`&#123;\"title\":\"hello\",\"content\":\"world\",\"created_at\":1616381976&#125;`).Do(ctx) if err != nil &#123; log.Fatalf(\"insert document: %v\", err) &#125; fmt.Printf(\"insert document success,id: %s\", response.Id)&#125; 查询1234567891011121314151617181920212223242526272829303132func QueryDoc(client *elastic.Client) &#123; indexName := \"blog\" boolQuery := elastic.NewTermQuery(\"title\", \"hello\") searchResult, err := client.Search(indexName).Query(boolQuery).Do(context.Background()) if err != nil &#123; log.Fatalf(\"query document: %v\", err) &#125; fmt.Printf(\"Query took %d milliseconds\\n\", searchResult.TookInMillis) // Number of hits if searchResult.Hits != nil &#123; fmt.Printf(\"Found a total of %d tweets\\n\", searchResult.Hits.TotalHits.Value) // Iterate through results for _, hit := range searchResult.Hits.Hits &#123; // hit.Index contains the name of the index // Deserialize hit.Source into a Tweet (could also be just a map[string]interface&#123;&#125;). var t map[string]interface&#123;&#125; err := json.Unmarshal(hit.Source, &amp;t) if err != nil &#123; // Deserialization failed &#125; // Work with tweet fmt.Printf(\"id:%s, title: %s, content: %s\\n\", hit.Id, t[\"title\"], t[\"content\"]) &#125; &#125; else &#123; // No hits fmt.Print(\"Found no tweets\\n\") &#125;&#125; 更多示例请查看：https://pkg.go.dev/github.com/olivere/elastic","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"服务化01-Elasticsearch集群","slug":"service-elasticsearch","date":"2021-03-21T14:02:27.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2021/03/21/service-elasticsearch/","link":"","permalink":"https://hongker.github.io/2021/03/21/service-elasticsearch/","excerpt":"本文介绍下Elasticsearch集群的相关知识。 什么是Elasticsearch Elasticsearch 是一个分布式、高扩展、高实时的搜索与数据分析引擎。它能很方便的使大量数据具有搜索、分析和探索的能力。充分利用Elasticsearch的水平伸缩性，能使数据在生产环境变得更有价值。 为什么要用集群用ElasticSearch集群，将单个索引的分片到多个不同分布式物理机器上存储，从而实现高可用、容错性等。ElasticSearch会自动选举实现主备服务器。 达到基本高可用，一般要至少启动3个节点，3个节点互相连接，单个节点包括所有角色，其中任意节点停机集群依然可用。 关键概念节点角色 Master，集群管理 Voting，投票选举节点 Data，数据节点 Ingest，数据编辑节点 Coordinate，协调节点 Machine Learning，集群学习节点 索引一般意义上的索引是一种基于文档（数据）生成、建立的，用于快速定位指定文档的工具。而 ElasticSearch 对索引的定义有所不同，ElasticSearch 中的索引对应 MySQL 中的 Database ，也就说 ElasticSearch 中的索引更像是一种数据存储集合，即用于存储文档。 分片分片（Shard），是Elasticsearch中的最小存储单元。 Shards分片：代表索引分片，ElasticSearch可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。 Replicas分片：代表副本分片，ElasticSearch可以设置多个索引的副本，副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高ElasticSearch的查询效率，ElasticSearch会自动对搜索请求进行负载均衡。 数据路由 当客户端发起创建document的时候，ElasticSearch需要确定这个document放在该索引哪个shard上。这个过程就是数据路由。 路由算法：分片位置shard=hash(routing) % number_of_primary_shards 如果number_of_primary_shards在查询的时候取余发生变化，则无法获取到该数据。即：在查询的时候，底层根据文档id%主分片数量获取分片位置 1231.客户端向 ES1节点（协调节点）发送写请求，通过路由计算公式得到值为0，则当前数据应被写到主分片 S0 上。2.ES1 节点将请求转发到 S0 主分片所在的节点 ES3，ES3 接受请求并写入到磁盘。3.并发将数据复制到两个副本分片 R0 上，其中通过乐观并发控制数据的冲突。一旦所有的副本分片都报告成功，则节点 ES3 将向协调节点报告成功，协调节点向客户端报告成功。 脑裂现象正常情况下，集群中的所有节点，应该对主节点的选择是一致的，即一个集群中只有一个选举出来的主节点。然而，在某些情况下，比如网络通信出现问题、主节点因为负载过大停止响应等等，就会导致重新选举主节点，此时可能会出现集群中有多个主节点的现象，即节点对集群状态的认知不一致，称之为脑裂现象。 为了尽量避免此种情况的出现，可以通过discovery.zen.minimum_master_nodes来设置最少可工作的候选主节点个数，建议设置为(候选主节点数 / 2) + 1。保证集群中有半数以上的候选主节点。 安装现在开始介绍如何通过docker搭建一个简单的Elasticsearch集群服务","text":"本文介绍下Elasticsearch集群的相关知识。 什么是Elasticsearch Elasticsearch 是一个分布式、高扩展、高实时的搜索与数据分析引擎。它能很方便的使大量数据具有搜索、分析和探索的能力。充分利用Elasticsearch的水平伸缩性，能使数据在生产环境变得更有价值。 为什么要用集群用ElasticSearch集群，将单个索引的分片到多个不同分布式物理机器上存储，从而实现高可用、容错性等。ElasticSearch会自动选举实现主备服务器。 达到基本高可用，一般要至少启动3个节点，3个节点互相连接，单个节点包括所有角色，其中任意节点停机集群依然可用。 关键概念节点角色 Master，集群管理 Voting，投票选举节点 Data，数据节点 Ingest，数据编辑节点 Coordinate，协调节点 Machine Learning，集群学习节点 索引一般意义上的索引是一种基于文档（数据）生成、建立的，用于快速定位指定文档的工具。而 ElasticSearch 对索引的定义有所不同，ElasticSearch 中的索引对应 MySQL 中的 Database ，也就说 ElasticSearch 中的索引更像是一种数据存储集合，即用于存储文档。 分片分片（Shard），是Elasticsearch中的最小存储单元。 Shards分片：代表索引分片，ElasticSearch可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。 Replicas分片：代表副本分片，ElasticSearch可以设置多个索引的副本，副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高ElasticSearch的查询效率，ElasticSearch会自动对搜索请求进行负载均衡。 数据路由 当客户端发起创建document的时候，ElasticSearch需要确定这个document放在该索引哪个shard上。这个过程就是数据路由。 路由算法：分片位置shard=hash(routing) % number_of_primary_shards 如果number_of_primary_shards在查询的时候取余发生变化，则无法获取到该数据。即：在查询的时候，底层根据文档id%主分片数量获取分片位置 1231.客户端向 ES1节点（协调节点）发送写请求，通过路由计算公式得到值为0，则当前数据应被写到主分片 S0 上。2.ES1 节点将请求转发到 S0 主分片所在的节点 ES3，ES3 接受请求并写入到磁盘。3.并发将数据复制到两个副本分片 R0 上，其中通过乐观并发控制数据的冲突。一旦所有的副本分片都报告成功，则节点 ES3 将向协调节点报告成功，协调节点向客户端报告成功。 脑裂现象正常情况下，集群中的所有节点，应该对主节点的选择是一致的，即一个集群中只有一个选举出来的主节点。然而，在某些情况下，比如网络通信出现问题、主节点因为负载过大停止响应等等，就会导致重新选举主节点，此时可能会出现集群中有多个主节点的现象，即节点对集群状态的认知不一致，称之为脑裂现象。 为了尽量避免此种情况的出现，可以通过discovery.zen.minimum_master_nodes来设置最少可工作的候选主节点个数，建议设置为(候选主节点数 / 2) + 1。保证集群中有半数以上的候选主节点。 安装现在开始介绍如何通过docker搭建一个简单的Elasticsearch集群服务 项目结构 1234567891011121314.├── config # 配置│ ├── es01│ ├── es02│ └── es03├── data # 数据│ ├── es01│ ├── es02│ └── es03├── logs # 日志│ ├── es01│ ├── es02│ └── es03└── docker-componse.yml docker-compose.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869version: &apos;2&apos;services: es01: image: elasticsearch:7.6.1 container_name: es01 restart: always environment: - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; - &quot;TAKE_FILE_OWNERSHIP=true&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - ./data/es01:/usr/share/elasticsearch/data - ./config/es01/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml - ./logs/es01:/usr/share/elasticsearch/logs ports: - 9200:9200 - 9300:9300 networks: - esnet es02: image: elasticsearch:7.6.1 container_name: es02 restart: always environment: - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; - &quot;TAKE_FILE_OWNERSHIP=true&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - ./data/es02:/usr/share/elasticsearch/data - ./config/es02/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml - ./logs/es02:/usr/share/elasticsearch/logs ports: - 9201:9200 - 9301:9300 depends_on: - es01 networks: - esnet es03: image: elasticsearch:7.6.1 container_name: es03 restart: always environment: - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; - &quot;TAKE_FILE_OWNERSHIP=true&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - ./data/es03:/usr/share/elasticsearch/data - ./config/es03/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml - ./logs/es03:/usr/share/elasticsearch/logs ports: - 9202:9200 - 9302:9300 depends_on: - es01 networks: - esnetnetworks: esnet: config/es01/elasticsearch.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 集群名称cluster.name: es-cluster# 名称node.name: es01# 主节点node.master: true# 需要存储数据node.data: true# 数据文件path.data: /usr/share/elasticsearch/data# 日志文件path.logs: /usr/share/elasticsearch/logs# 锁定物理内存地址，防止es内存被交换出去，也就是避免es使用swap交换分区，频繁的交换，会导致IOPS变高bootstrap.memory_lock: true# 服务地址network.host : 0.0.0.0# 端口,默认为9200http.port : 9200# 内部节点之间沟通端口transport.tcp.port : 9300# 服务发现种子主机，这里的172.17.0.1是我的docker网关地址，只有配置这个可访问的地址，es才能发现各个节点discovery.seed_hosts: [&quot;172.17.0.1:9300&quot; ,&quot;172.17.0.1:9301&quot;, &quot;172.17.0.1:9302&quot;]# 初始主节点,用于选举cluster.initial_master_nodes: [&quot;es01&quot;, &quot;es02&quot;, &quot;es03&quot;]# 集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错discovery.zen.ping_timeout: 120s# 设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点discovery.zen.minimum_master_nodes: 2# 跨域设置http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;http.cors.allow-methods: OPTIONS, HEAD, GET, POST, PUT, DELETEhttp.cors.allow-headers: &quot;X-Requested-With, Content-Type, Content-Length, X-User&quot; config/es02/elasticsearch.yml 12# 拷贝es01的配置，只更改以下配置接口node.name: es02 config/es03/elasticsearch.yml 12# 拷贝es01的配置，只更改以下配置接口node.name: es03 启动服务 1docker-compose -f docker-compose.yml up -d 查看集群状态现在可以通过curl来查看集群的一些状态，如下： 12345678# 查看状态curl -XGET &apos;http://localhost:9200/_cluster/health&apos;# 查看节点curl -XGET &apos;http://localhost:9200/_cat/nodes?pretty&apos;# 查看索引curl -XGET &apos;localhost:9200/_cat/indices?v&apos; 冷热分离通过设置node.attr.temperature为hot或者warm区分冷热节点。 将索引迁移到冷节点： 1curl -XPUT localhost:9200/index_name/_settings -H &quot;Content-Type: application/json&quot; -d &apos;&#123;&quot;index.routing.allocation.require.temperature&quot;:&quot;warm&quot;&#125;&apos; 将索引恢复到热节点: 1curl -XPUT localhost:9200/index_name/_settings -H &quot;Content-Type: application/json&quot; -d &apos;&#123;&quot;index.routing.allocation.require.temperature&quot;:&quot;hot&quot;&#125;&apos; 查看索引的状态 1curl -XGET &quot;localhost:9200/_cat/shards/index_name?v&amp;h=index,shard,prirep,node&amp;s=node&quot;","categories":[],"tags":[{"name":"micro-service","slug":"micro-service","permalink":"https://hongker.github.io/tags/micro-service/"}]},{"title":"Golang代码优化22-RBAC分布式同步","slug":"golang-rbac-watcher","date":"2021-02-19T13:42:50.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2021/02/19/golang-rbac-watcher/","link":"","permalink":"https://hongker.github.io/2021/02/19/golang-rbac-watcher/","excerpt":"","text":"前面介绍了rbac组件在单点服务上的基本应用场景,今天来介绍一下，在微服务架构下如何使用rbac来控制路由权限。 服务架构 这是一个很普通的微服务架构，用户通过请求服务器的路由资源，发起访问，各服务需要检查用户是否拥有权限。 RBAC组件是将权限规则存入内存里，当管理员通过权限管理后台更新的权限信息后，如何让各服务节点即时加载最新的权限规则呢？ 我们发现，管理后台产生新的权限规则，多个服务节点读取最新的权限规则，这是一个典型的生产者/消费者模型。 casbin有提供一个Watcher接口。官网也提供了如redis、etcd、kafka等解决访问，详细文档请参考：https://casbin.org/docs/en/watchers。下面就用redis做示例说明 redis基于redis的发布/订阅(Publish/Subscribe),管理员更新用户权限后，通过redis发布一条信息，其余服务节点，因为订阅了该信息，故每个客户端都会接受到一条通知，此刻更新内存的权限规则，即可实现分布式的权限更新。将此组件称为:redis-watcher Demo 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131package mainimport ( \"fmt\" \"github.com/casbin/casbin/v2/persist\" uuid \"github.com/satori/go.uuid\" \"reflect\" \"sync\" \"github.com/go-redis/redis\")// Watchertype Watcher struct &#123; options options // 选项 pubConn redis.UniversalClient //生产消息 subConn redis.UniversalClient //订阅消息 callback func(string) // 回调方法 closed chan struct&#123;&#125; once sync.Once&#125;// 选项type options struct &#123; id string // 当前节点的id channel string // redis的管道名称&#125;// Option 选项接口type Option interface &#123; Set(options *options)&#125;// channel选项type channelOption stringfunc (o channelOption) Set(opts *options) &#123; opts.channel = string(o)&#125;func WithChannel(channel string) Option &#123; return channelOption(channel)&#125;// id选项type idOption stringfunc (o idOption) Set(opts *options) &#123; opts.id = string(o)&#125;func WithID(id string) Option &#123; return idOption(id)&#125;// NewWatcher 实例化func NewWatcher(conn redis.UniversalClient, opts ...Option) (persist.Watcher, error) &#123; w := &amp;Watcher&#123; closed: make(chan struct&#123;&#125;), pubConn: conn, subConn: conn, &#125; w.options = options&#123; channel: \"/casbin\", id : uuid.NewV4().String(), &#125; for _, opt := range opts &#123; opt.Set(&amp;w.options) &#125; go func() &#123; for &#123; select &#123; case &lt;-w.closed: return default: err := w.subscribe() if err != nil &#123; fmt.Printf(\"Failure from Redis subscription: %v\", err) &#125; &#125; &#125; &#125;() return w, nil&#125;// SetUpdateCallBack sets the update callback function invoked by the watcher// when the policy is updated. Defaults to Enforcer.LoadPolicy()func (w *Watcher) SetUpdateCallback(callback func(string)) error &#123; w.callback = callback return nil&#125;// Update publishes a message to all other casbin instances telling them to// invoke their update callbackfunc (w *Watcher) Update() error &#123; // 当有权限更新时，发送当前节点的ID,通知其他节点有更新 if _, err := w.pubConn.Publish(w.options.channel, w.options.id).Result(); err != nil &#123; return err &#125; return nil&#125;// Close disconnects the watcher from redisfunc (w *Watcher) Close() &#123; w.once.Do(func() &#123; close(w.closed) _ = w.subConn.Close() _ = w.pubConn.Close() &#125;)&#125;// subscribe 订阅redisfunc (w *Watcher) subscribe() error &#123; psc := w.subConn.Subscribe(w.options.channel) defer psc.Unsubscribe() for &#123; receive, err := psc.Receive() fmt.Println(reflect.TypeOf(receive)) if err != nil &#123; fmt.Printf(\"try subscribe channel[%s] error[%s]\\n\", w.options.channel, err.Error()) return nil &#125; switch n := receive.(type) &#123; case error: return n case *redis.Message: // 需要跳过当前生产者 if n.Payload != w.options.id &amp;&amp; w.callback != nil &#123; w.callback(\"success\") // 执行回调 &#125; case *redis.Subscription: if n.Count == 0 &#123; return nil &#125; &#125; &#125;&#125; 使用方式： 123456789101112131415161718192021222324252627func main() &#123; authEnforcer, err := casbin.NewEnforcerSafe(\"rbac/conf/rbac_model.conf\") if err != nil &#123; log.Fatal(err) &#125; redisConn := redis.NewClient( &amp;redis.Options&#123; Addr: \"127.0.0.1\", Password: \"\", DB: 0, &#125;) if _, err := redisConn.Ping().Result(); err != nil &#123; log.Fatal(err) &#125; watcher, err := NewWatcher(redisConn) if err != nil &#123; log.Fatal(err) &#125; watcher.SetUpdateCallback(func(s string) &#123; // 当有权限更新时，会执行这个回调，具体更新内存的权限逻辑可以自定义 enforcer.LoadPolicy() &#125;) authEnforcer.SetWatcher(watcher)&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化21-限流器(Limiter)","slug":"golang-limiter","date":"2021-02-18T09:39:59.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2021/02/18/golang-limiter/","link":"","permalink":"https://hongker.github.io/2021/02/18/golang-limiter/","excerpt":"","text":"在实际的场景中，正常的请求不会造成系统异常。但我们也需要防止异常高并发场景导致整个系统崩溃的情况出现。下面介绍限流器的使用。 为什么需要限流器 用户增长过快、热门业务或者爬虫等恶意攻击行为致使请求量突然增大，比如学校的教务系统，到了查分之日，请求量涨到之前的 100 倍都不止，没多久该接口几乎不可使用，并引发连锁反应导致整个系统崩溃。 通过限流器，给接口设置最高访问量，保证在系统的可承受范围内，提供服务。一旦超过该阈值，不允许用户访问，保证系统的其他服务能继续正常运行。 实现1234567891011121314151617181920package limiterimport ( \"time\" \"golang.org/x/time/rate\")// Limiter 限流器type Limiter struct &#123; *rate.Limiter&#125;// New 实例化func New(maxRate int) *Limiter &#123; instance := new(Limiter) instance.Limiter = rate.NewLimiter(rate.Every(time.Second), maxRate) return instance&#125; 示例1234567891011121314151617181920212223package main// LimitMiddleware 限流器中间件func LimitMiddleware(maxRate int) gin.HandlerFunc &#123; limiter := New(maxRate) // 实例化一个限流器 return func(ctx *gin.Context) &#123; if !limiter.Allow() &#123; // 这里用于控制当限流器达到阈值的判断 ctx.JSON(403, gin.H&#123;\"message\": \"Busy\"&#125;) ctx.Abort() &#125; ctx.Next() &#125;&#125;func main() &#123; r := gin.Default() r.Use(LimitMiddleware(100)) // 每秒最高允许100个请求 r.GET(\"/test\", func(c *gin.Context) &#123; c.JSON(200, gin.H&#123; \"message\": \"pong\", &#125;) &#125;) r.Run()&#125; 当并发达到100以上时，后面的请求都会返回403。这样可以保证不会给系统更大的压力。 原理请参考：https://zhuanlan.zhihu.com/p/140440501","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化20-通过SingleFlight防止缓存击穿","slug":"golang-singleflight","date":"2021-02-18T02:57:09.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2021/02/18/golang-singleflight/","link":"","permalink":"https://hongker.github.io/2021/02/18/golang-singleflight/","excerpt":"","text":"在高并发场景中，我们最普遍的方案是采用高性能的缓存。在缓存使用过程中，需要注意缓存穿透、缓存雪崩、缓存击穿。以下介绍如何通过singleflight防止缓存击穿。 什么是缓存击穿 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。 SingleFlight在多个并发请求对一个失效的key进行源数据获取时，只让其中一个得到执行，其余阻塞等待到执行的那个请求完成后，将结果传递给阻塞的其他请求达到防止击穿的效果。 安装1go get golang.org/x/sync/singleflight 示例12345678910111213141516171819202122232425262728293031package mainimport ( \"fmt\" \"log\" \"time\" \"golang.org/x/sync/singleflight\")var singleHandle singleflight.Groupfunc main() &#123; for i := 0; i &lt; 10; i++ &#123; // 模拟10个并发 go func() &#123; fmt.Println(GetName(\"username\")) &#125;() &#125; // 等待协程执行结束 time.Sleep(3 * time.Second)&#125;// GetName 获取名称func GetName(cacheKey string) string &#123; result, _, _ := singleHandle.Do(cacheKey, func() (ret interface&#123;&#125;, err error) &#123; log.Printf(\"getting %s from database\\n\", cacheKey) log.Printf(\"setting %s in cache\\n\", cacheKey) return \"hongker\", nil &#125;) return result.(string)&#125; 结果1234567891011122021/02/18 14:26:12 getting username from database2021/02/18 14:26:12 setting username in cachehongkerhongkerhongkerhongkerhongkerhongkerhongkerhongkerhongkerhongker 只有一个协程执行从数据库中获取并设置缓存的操作，其他协程则是在等待获取缓存。避免缓存击穿。","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Go数据结构与算法系列(02)-集合","slug":"algorithm-set","date":"2020-08-04T14:11:46.000Z","updated":"2021-04-24T13:55:49.260Z","comments":true,"path":"2020/08/04/algorithm-set/","link":"","permalink":"https://hongker.github.io/2020/08/04/algorithm-set/","excerpt":"本篇文章主要介绍golang里集合的实现思路。 什么是集合？ 集合通常是由一组无序的, 不能重复的元素构成 功能 添加元素 删除元素 获取集合的元素数量 检查集合是否包含某元素 清空集合 判断集合是否为空 集合转数组 复制 接口设计如下：123456789101112131415161718type Set interface &#123; // 添加元素 Add(items ...interface&#123;&#125;) // 包含 Contain(item interface&#123;&#125;) bool // 删除 Remove(item interface&#123;&#125;) // 集合大小 Size() int // 清空 Clear() // 判断是否为空 Empty() bool // 创建副本 Duplicate() Set // 数组 ToSlice() []interface&#123;&#125;&#125; 具体实现","text":"本篇文章主要介绍golang里集合的实现思路。 什么是集合？ 集合通常是由一组无序的, 不能重复的元素构成 功能 添加元素 删除元素 获取集合的元素数量 检查集合是否包含某元素 清空集合 判断集合是否为空 集合转数组 复制 接口设计如下：123456789101112131415161718type Set interface &#123; // 添加元素 Add(items ...interface&#123;&#125;) // 包含 Contain(item interface&#123;&#125;) bool // 删除 Remove(item interface&#123;&#125;) // 集合大小 Size() int // 清空 Clear() // 判断是否为空 Empty() bool // 创建副本 Duplicate() Set // 数组 ToSlice() []interface&#123;&#125;&#125; 具体实现 线程不安全我们使用golang的map来实现集合12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import ( \"fmt\" \"strings\")// threadUnsafeSet 非线程安全的集合，采用元素值作为key，空的struct作为值type threadUnsafeSet map[interface&#123;&#125;]struct&#123;&#125;func newThreadUnsafeSet() threadUnsafeSet &#123; return make(threadUnsafeSet)&#125;func (set *threadUnsafeSet) Add(items ...interface&#123;&#125;) &#123; for _, item := range items &#123; (*set)[item] = struct&#123;&#125;&#123;&#125; &#125;&#125;func (set *threadUnsafeSet) Contain(item interface&#123;&#125;) bool &#123; _, ok := (*set)[item] return ok&#125;func (set *threadUnsafeSet) Remove(item interface&#123;&#125;) &#123; delete((*set), item)&#125;func (set *threadUnsafeSet) Size() int &#123; return len((*set))&#125;func (set *threadUnsafeSet) Clear() &#123; *set = newThreadUnsafeSet()&#125;func (set *threadUnsafeSet) Empty() bool &#123; return set.Size() == 0&#125;func (set *threadUnsafeSet) Duplicate() Set &#123; duplicateSet := newThreadUnsafeSet() for item, _ := range *set &#123; duplicateSet.Add(item) &#125; return &amp;duplicateSet&#125;func (set *threadUnsafeSet) String() string &#123; items := make([]string, 0, len(*set)) for elem := range *set &#123; items = append(items, fmt.Sprintf(\"%v\", elem)) &#125; return fmt.Sprintf(\"&#123;%s&#125;\", strings.Join(items, \", \"))&#125;func (set *threadUnsafeSet) ToSlice() []interface&#123;&#125; &#123; keys := make([]interface&#123;&#125;, 0, set.Size()) for elem := range *set &#123; keys = append(keys, elem) &#125; return keys&#125; 线程安全的集合在非线程安全集合的基础上，通过读写锁实现线程安全。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import \"sync\"type threadSafeSet struct &#123; s threadUnsafeSet sync.RWMutex&#125;func newThreadSafeSet() *threadSafeSet &#123; return &amp;threadSafeSet&#123;s: newThreadUnsafeSet()&#125;&#125;func (set *threadSafeSet) Add(items ...interface&#123;&#125;) &#123; set.Lock() //数据新增采用互斥锁 set.s.Add(items...) set.Unlock()&#125;func (set *threadSafeSet) Contain(item interface&#123;&#125;) bool &#123; set.RLock() // 采用读写锁 defer set.RUnlock() return set.s.Contain(item)&#125;func (set *threadSafeSet) Remove(item interface&#123;&#125;) &#123; set.Lock() set.s.Remove(item) set.Unlock()&#125;func (set *threadSafeSet) Size() int &#123; set.RLock() defer set.RUnlock() return set.s.Size()&#125;func (set *threadSafeSet) Clear() &#123; set.Lock() set.s.Clear() set.Unlock()&#125;func (set *threadSafeSet) Empty() bool &#123; return set.Size() == 0&#125;func (set *threadSafeSet) Duplicate() Set &#123; set.RLock() defer set.RUnlock() s := set.s.Duplicate() return &amp;threadSafeSet&#123;s: *(s.(*threadUnsafeSet))&#125;&#125;func (set *threadSafeSet) ToSlice() []interface&#123;&#125; &#123; set.RLock() defer set.RUnlock() return set.s.ToSlice()&#125; 初始化函数1234567891011func ThreadSafe(items ...interface&#123;&#125;) Set &#123; s := newThreadSafeSet() s.Add(items...) return s&#125;func ThreadUnsafe(items ...interface&#123;&#125;) Set &#123; s := newThreadUnsafeSet() s.Add(items...) return &amp;s&#125; 单元测试12345678910111213141516171819202122232425262728293031import ( \"fmt\" \"github.com/stretchr/testify/assert\" \"testing\")func TestThreadUnsafeSet_Add(t *testing.T) &#123; set := ThreadSafe() //set := ThreadUnsafe() set.Add(1,2,3,4) assert.True(t, set.Contain(1)) set.Remove(2) assert.Equal(t, 3, set.Size()) set.Clear() assert.Equal(t, 0, set.Size()) assert.True(t, set.Empty()) assert.False(t, set.Contain(5)) set.Add(5) assert.True(t, set.Contain(5)) fmt.Println(set.ToSlice()) set.Add(\"hello\", \"world\") fmt.Println(set.ToSlice()) copySet := set.Duplicate() fmt.Println(copySet.ToSlice())&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://hongker.github.io/tags/algorithm/"}]},{"title":"Go数据结构与算法系列(03)-队列","slug":"algorithm-queue","date":"2020-07-28T06:41:59.000Z","updated":"2021-04-24T13:56:07.612Z","comments":true,"path":"2020/07/28/algorithm-queue/","link":"","permalink":"https://hongker.github.io/2020/07/28/algorithm-queue/","excerpt":"本文介绍在golang里如何实现队列得数据结构 概念队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。队列中没有元素时，称为空队列。 特性 入列从尾部将元素加入到队列里。 出列从队列头部获取元素。 查看长度获取队列存储的元素个数。 清空队列将队列里的数据清空。 Demo 定义Queue接口12345678910111213// Queue 队列type Queue interface &#123; // Push 入列 Push(items ...interface&#123;&#125;) // Pop 出列 Pop() (interface&#123;&#125;) // MPop 批量出列 MPop(n int) ([]interface&#123;&#125;) // Length 长度 Length() int // Clear 清空 Clear()&#125;","text":"本文介绍在golang里如何实现队列得数据结构 概念队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。队列中没有元素时，称为空队列。 特性 入列从尾部将元素加入到队列里。 出列从队列头部获取元素。 查看长度获取队列存储的元素个数。 清空队列将队列里的数据清空。 Demo 定义Queue接口12345678910111213// Queue 队列type Queue interface &#123; // Push 入列 Push(items ...interface&#123;&#125;) // Pop 出列 Pop() (interface&#123;&#125;) // MPop 批量出列 MPop(n int) ([]interface&#123;&#125;) // Length 长度 Length() int // Clear 清空 Clear()&#125; 实现Queue接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package queueimport \"container/list\"type queue struct &#123; // 使用链表结构实现 list *list.List&#125;func New() Queue &#123; return &amp;queue&#123;list: list.New()&#125;&#125;func (q queue) Push(items ...interface&#123;&#125;) &#123; for _, item := range items &#123; q.list.PushBack(item) &#125;&#125;func (q queue) Pop() (interface&#123;&#125;) &#123; item := q.list.Front() if item == nil &#123; return nil &#125; q.list.Remove(item) return item.Value&#125;func (q queue) MPop(n int) ([]interface&#123;&#125;) &#123; if n &lt; 1 &#123; // 当n小于1，返回nil return nil &#125; var result []interface&#123;&#125; var items []*list.Element item := q.list.Front() for i := 0; i &lt;n ; i++ &#123; if item == nil &#123; // 判断元素是否为空 break &#125; items = append(items, item) item = item.Next() &#125; // 获取元素并删除队列里对应的数据 for _, item := range items &#123; q.list.Remove(item) result = append(result, item.Value) &#125; return result&#125;func (q queue) Length() int &#123; return q.list.Len()&#125;func (q queue) Clear() &#123; q.list.Init()&#125; 使用 123456789101112131415161718192021222324252627282930313233343536373839package queueimport ( \"fmt\" \"github.com/stretchr/testify/assert\" \"testing\")func TestQueue(t *testing.T) &#123; queue := New() // test Push queue.Push(1,2,3,4) // test Length assert.Equal(t, queue.Length(), 4) // test Pop item := queue.Pop() assert.Equal(t, item, 1) assert.Equal(t, queue.Length(), 3) // test MPop multiItems := queue.MPop(2) assert.Equal(t, []interface&#123;&#125;&#123;2,3&#125;, multiItems) assert.Equal(t, queue.Length(), 1) // test Clear queue.Clear() assert.Equal(t, queue.Length(), 0)&#125;func BenchmarkQueue_Push(b *testing.B) &#123; queue := New() for i := 0; i &lt; b.N; i++ &#123; queue.Push(i) &#125; fmt.Println(queue.Length())&#125; 更多请查看代码库:https://github.com/ebar-go/gostructure","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://hongker.github.io/tags/algorithm/"}]},{"title":"Golang代码优化19-自动生成API文档之Swagger","slug":"golang-swagger","date":"2020-06-10T14:17:19.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/06/10/golang-swagger/","link":"","permalink":"https://hongker.github.io/2020/06/10/golang-swagger/","excerpt":"本文介绍如何巧妙的使用go-swagger自动生成API接口文档。 什么是swagger 准备工作 API文档初始化 生成API 什么是swagger Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。 准备工作 下载swag工具 12// 通过go get下载并编译，在$GOPATH/bin目录下会生成swag命令，用于扫描注解。go get -u github.com/swaggo/swag/cmd/swag 引入ego框架,已集成好的gin-swagger组件 1go get github.com/ebar-go/ego API文档初始化 先写项目说明123456789101112131415161718192021222324// @title Swagger Example API// @version 1.0// @description This is a sample server Petstore server.// @termsOfService http://swagger.io/terms/// @contact.name hongker// @contact.url http://hongker.github.io// @contact.email xiaok2013@live.com// @license.name Apache 2.0// @license.url http://www.apache.org/licenses/LICENSE-2.0.html// @host localhost:8080// @BasePath /v1func main() &#123; s := http.NewServer() // 加载路由 route.Load(s.Router) // 启动 secure.Panic(s.Start())&#125;","text":"本文介绍如何巧妙的使用go-swagger自动生成API接口文档。 什么是swagger 准备工作 API文档初始化 生成API 什么是swagger Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。 准备工作 下载swag工具 12// 通过go get下载并编译，在$GOPATH/bin目录下会生成swag命令，用于扫描注解。go get -u github.com/swaggo/swag/cmd/swag 引入ego框架,已集成好的gin-swagger组件 1go get github.com/ebar-go/ego API文档初始化 先写项目说明123456789101112131415161718192021222324// @title Swagger Example API// @version 1.0// @description This is a sample server Petstore server.// @termsOfService http://swagger.io/terms/// @contact.name hongker// @contact.url http://hongker.github.io// @contact.email xiaok2013@live.com// @license.name Apache 2.0// @license.url http://www.apache.org/licenses/LICENSE-2.0.html// @host localhost:8080// @BasePath /v1func main() &#123; s := http.NewServer() // 加载路由 route.Load(s.Router) // 启动 secure.Panic(s.Start())&#125; 通过命令自动生成swagger.json 12// 生成的文件默认放在当前目录的docs下swag init 引入swagger的web 1234567// 我一般都是在router模块下加载import( _ \"ego-demo/docs\" // 这一行必须 \"github.com/ebar-go/ego/http/middleware\")// 通过 &#123;host&#125;/swagger/index.html访问swagger webrouter.GET(\"/swagger/*any\", middleware.Swagger()) 启动web服务，访问 /swagger/index.html就能看到效果了 生成API demo 12345678910111213// UserAuthHandler 用户登录// @Summary 用户登录// @Description 通过邮箱和密码登录，换取token// @Accept json// @Produce json// @Param email body string true \"邮箱\"// @Param pass body string true \"密码\"// @Success 0 \"success\"// @Failure 500 \"error\"// @Router /user/auth [post]func UserAuthHandler(ctx *gin.Context) &#123; // demo&#125; 说明 12345678Summary : 副标题Description : 接口描述Accept : 接收类型Produce: 响应类型Param: 参数Success: 成功的响应Failure: 失败的响应Router : 路由(包括uri, method) 使用结构体使用定义好的结构体，避免每个参数都得写一行注解。非常喜欢这种方式。 1234567891011121314151617181920212223242526// UserRegisterHandler 用户注册// @Summary 用户注册// @Description 通过邮箱和密码注册账户// @Accept json// @Produce json// @Param req body request.UserRegisterRequest true \"请求参数\"// @Success 0 \"success\"// @Failure 500 \"error\"// @Router /user/register [post]func UserRegisterHandler(ctx *gin.Context) &#123; var req request.UserRegisterRequest // 校验参数 if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; // 使用抛出异常的方式，截断代码逻辑，让recover输出响应内容，减少return secure.Panic(errors.New(statusCode.InvalidParam, err.Error())) &#125;&#125;// UserRegisterRequest 注册请求type UserRegisterRequest struct &#123; // 邮箱 Email string `json:\"email\" binding:\"required,email\" comment:\"邮箱\"` // 验证邮箱格式 // 密码 Pass string `json:\"pass\" binding:\"required,min=6,max=10\" comment:\"密码\"` // 验证密码，长度为6~10&#125; 注：1.参数名称读的是json的tag，如Email的”email”.2.参数说明读的是属性上一行的注释，如Email上面的”邮箱”。","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化18-权限RBAC","slug":"golang-rbac","date":"2020-04-25T10:08:07.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/25/golang-rbac/","link":"","permalink":"https://hongker.github.io/2020/04/25/golang-rbac/","excerpt":"","text":"本文介绍golang中RBAC(基于角色的权限控制)的使用方式 什么是RBAC RBAC 是基于角色的访问控制（Role-Based Access Control ）在 RBAC 中，权限与角色相关联，用户通过成为适当角色的成员而得到这些角色的权限。这就极大地简化了权限的管理。这样管理都是层级相互依赖的，权限赋予给角色，而把角色又赋予用户，这样的权限设计很清楚，管理起来很方便。 实现我选用的是github.com/casbin/casbin,选择原因:社区的认同(Star很高)。 安装1go get github.com/casbin/casbin 定义模型 conf/rbac_model.conf 1234567891011121314[request_definition]r = sub, obj, act[policy_definition]p = sub, obj, act[role_definition]g = _, _[policy_effect]e = some(where (p.eft == allow))[matchers]m = r.sub == p.sub &amp;&amp; keyMatch(r.obj, p.obj) &amp;&amp; (r.act == p.act || p.act == &quot;*&quot;) conf/policy.csv权限细则，可以读csv文件，可以读数据库。。 12345678p, admin, /*, *p, anonymous, /article, GETp, anonymous, /article/*, GETp, member, /permission, GETp, member, /article, GETp, member, /article/*, *g, test01, anonymousg, user01, member 说明： line 1: 定义admin角色能访问所有资源 line 2,3: 定义anonymous角色能查看文章列表、文章详情 line 4: 定义member角色能获取权限 line 5,6: 定义member角色能访问文章所有权限 line 7: 定义test01的角色为anonymous line 8: 定义user01的角色为member 定义中间件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// enforcer.gopackage mainimport ( \"github.com/casbin/casbin\" \"github.com/gin-gonic/gin\" \"log\" \"net/http\")var enforcer *casbin.Enforcer// init 初始化func init() &#123; authEnforcer, err := casbin.NewEnforcerSafe(\"conf/rbac_model.conf\", \"conf/policy.csv\") if err != nil &#123; log.Fatal(err) &#125; enforcer = authEnforcer&#125;// GetPermissionsByUser 获取用户权限，用于前端展示func GetPermissionsByUser(username string) [][]string &#123; return enforcer.GetImplicitPermissionsForUser(username)&#125;// CheckPermission 权限校验中间件func CheckPermission(ctx *gin.Context) &#123; // 获取角色，一般不会通过参数传递角色，而是根据用户当前的token解析得到用户的角色 // 这里为了演示而简单处理 role := ctx.Query(\"role\") if role == \"\" &#123; role = \"anonymous\" &#125; // 根据角色,路由，请求方法校验权限 hasPermission, err := enforcer.EnforceSafe(role, ctx.Request.URL.Path, ctx.Request.Method) // 程序异常 if err != nil &#123; ctx.String(http.StatusInternalServerError, err.Error()) ctx.Abort() &#125; // 没有权限 if !hasPermission &#123; ctx.String(http.StatusUnauthorized, \"StatusUnauthorized\") ctx.Abort() &#125; ctx.Next()&#125; web服务1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package mainimport ( \"github.com/gin-gonic/gin\" \"net/http\")func main() &#123; router := gin.Default() // 使用中间件 router.Use(CheckPermission) // 根据用户 router.GET(\"permission\", func(context *gin.Context) &#123; context.JSON(http.StatusOK, gin.H&#123; \"data\": GetPermissionsByUser(context.Query(\"user\")), &#125;) &#125;) // 定义一组文章的接口 article := router.Group(\"article\") &#123; // 列表查询 article.GET(\"\", func(context *gin.Context) &#123; context.JSON(http.StatusOK, gin.H&#123; \"data\": \"paginate\", &#125;) &#125;) // 查看详情 article.GET(\"/:id\", func(context *gin.Context) &#123; context.JSON(http.StatusOK, gin.H&#123; \"data\": \"info:\" + context.Param(\"id\"), &#125;) &#125;) // 更新 article.PUT(\"/:id\", func(context *gin.Context) &#123; context.JSON(http.StatusOK, gin.H&#123; \"data\": \"update\"+ context.Param(\"id\"), &#125;) &#125;) // 创建 article.POST(\"\", func(context *gin.Context) &#123; context.JSON(http.StatusOK, gin.H&#123; \"data\": \"create\", &#125;) &#125;) // 删除 article.DELETE(\"/:id\", func(context *gin.Context) &#123; context.JSON(http.StatusOK, gin.H&#123; \"data\": \"delete\"+ context.Param(\"id\"), &#125;) &#125;) &#125; router.Run(\":8888\")&#125; 测试 启动 1go run mian.go 测试 12345678curl localhost:8888/article// output: &#123;&quot;data&quot;:&quot;paginate&quot;&#125;curl localhost:8888/article/1// output: &#123;&quot;data&quot;:&quot;info:1&quot;&#125;curl localhost:8888/permission// output: StatusUnauthorizedcurl localhost:8888/permission?role=member&amp;user=user01// output: &#123;&quot;data&quot;:[[&quot;member&quot;,&quot;/permission&quot;,&quot;GET&quot;],[&quot;member&quot;,&quot;/article&quot;,&quot;GET&quot;],[&quot;member&quot;,&quot;/article/*&quot;,&quot;*&quot;]]&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化17-爬虫","slug":"golang-spider","date":"2020-04-17T08:53:29.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/17/golang-spider/","link":"","permalink":"https://hongker.github.io/2020/04/17/golang-spider/","excerpt":"","text":"本文介绍golang里也可以像python那样强大的使用爬虫。 什么是爬虫 网络爬虫（又称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。 说明爬虫在19年国家颁布《中华人民共和国网络安全法》里，明确指出了非法爬取数据的规定，此文章仅为学习讨论，合法学习并使用爬虫。 爬虫框架 chromedb无外部依赖，直接驱动支持chrome的DevTool协议的浏览器发起http请求 安装：1go get -u github.com/chromedb/chromedb 当然你的电脑上还需要安装chrome 示例Demo1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( \"context\" \"github.com/chromedp/chromedp\" \"log\" \"strings\")func main() &#123; // 如果是windows,出现以下错误时： // exec: \"google-chrome\": executable file not found in %PATH% // 需要通过下面方式指定运行环境 // linux只要安装了chrome,一般不会出现这些问题 allocCtx, allocCancel := chromedp.NewExecAllocator(context.Background(), chromedp.ExecPath(\"C:\\\\Users\\\\cx\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe\")) defer allocCancel() // 如果是linux,可以直接使用chrome headless模式: // chromedp.NewContext(context.Background()) ctx, cancel := chromedp.NewContext(allocCtx) defer cancel() var res string // 运行 err := chromedp.Run(ctx, // 指定url chromedp.Navigate(\"https://segmentfault.com/questions\"), // 通过指定标签页，获取html内容，并将内容写入res变量里 chromedp.Text(`div[class=\"copyright\"]`, &amp;res, chromedp.NodeVisible, chromedp.BySearch), ) if err != nil &#123; log.Fatal(err) &#125; log.Println(strings.TrimSpace(res))&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化16-Websocket","slug":"golang-websocket","date":"2020-04-17T05:49:39.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/17/golang-websocket/","link":"","permalink":"https://hongker.github.io/2020/04/17/golang-websocket/","excerpt":"","text":"本文介绍golang里使用websocket实现即时通讯。 什么是websocket WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。 安装包这是我封装好的包1go get github.com/ebar-go/ws 简单示例基于gin启动websocket服务1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( \"github.com/ebar-go/ws\" \"github.com/gin-gonic/gin\" \"net/http\")var m ws.Managerfunc init() &#123; m = ws.New()&#125;func main() &#123; // use gin router router := gin.Default() router.GET(\"/ws\", func(ctx *gin.Context) &#123; // get websocket conn conn, err := ws.GetUpgradeConnection(ctx.Writer, ctx.Request) if err != nil &#123; http.NotFound(ctx.Writer, ctx.Request) return &#125; // 指定客户端的消息处理方法 client := ws.NewConnection(conn, func(ctx *ws.Context) string &#123; // 返回响应内容 return ctx.GetMessage() &#125;) // listen go client.Listen() // register connection m.Register(client) &#125;) // start websocket service go m.Start() _ = router.Run() &#125; 测试使用wscat测试websocket1234567891011// 安装npm install -g wscat// 建立连接wscat -c ws://localhost:8080// 发送请求&gt; hello// 收到的响应&lt; hello","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"微服务02-服务注册与发现","slug":"service-register-discover","date":"2020-04-12T11:53:45.000Z","updated":"2021-04-22T22:57:00.353Z","comments":true,"path":"2020/04/12/service-register-discover/","link":"","permalink":"https://hongker.github.io/2020/04/12/service-register-discover/","excerpt":"本文介绍微服务核心模块，服务注册与发现。 什么是服务注册 将服务运行的IP与端口发送到服务中心注册，注册中心将运行服务的节点信息记录。 什么是服务发现 当需要调用某个服务提供的接口时，去注册中心，获取到对应服务的节点信息，发起请求调用服务。 注册中心常用的服务注册中心有Etcd,Consul,Zookeeper等。下面分别介绍 目录结构123456789soa├─consul│ consul.go│├─etcd│ etcd.go│└─service service.go Serivce公共的服务定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package serviceimport ( \"math/rand\" \"net\" \"strconv\" \"time\")// Node 节点type Node struct &#123; // 服务ID ID string // 服务名称 Name string // 服务地址 Address string // 服务端口 Port int // 服务标签 Tags []string&#125;// GetHost 获取服务完整的地址func (Node Node) GetHost() string &#123; return net.JoinHostPort(Node.Address, strconv.Itoa(Node.Port))&#125;// Grouptype Group struct &#123; items []Node cursor int&#125;// Count return node countfunc (group *Group) Count() int &#123; return len(group.items)&#125;// First return fist nodefunc (group *Group) First() Node &#123; return group.items[0]&#125;// Rand return a rand nodefunc (group *Group) Rand() Node &#123; rand.Seed(time.Now().Unix()) // initialize global pseudo random generator return group.items[rand.Intn(group.Count())]&#125;// Next return the next nodefunc (group *Group) Next() Node &#123; if group.cursor == group.Count() &#123; group.cursor = 0 &#125; Node := group.items[group.cursor] group.cursor++ return Node&#125;// Add add nodefunc (group *Group) Add(node Node) &#123; group.items = append(group.items, node)&#125;","text":"本文介绍微服务核心模块，服务注册与发现。 什么是服务注册 将服务运行的IP与端口发送到服务中心注册，注册中心将运行服务的节点信息记录。 什么是服务发现 当需要调用某个服务提供的接口时，去注册中心，获取到对应服务的节点信息，发起请求调用服务。 注册中心常用的服务注册中心有Etcd,Consul,Zookeeper等。下面分别介绍 目录结构123456789soa├─consul│ consul.go│├─etcd│ etcd.go│└─service service.go Serivce公共的服务定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package serviceimport ( \"math/rand\" \"net\" \"strconv\" \"time\")// Node 节点type Node struct &#123; // 服务ID ID string // 服务名称 Name string // 服务地址 Address string // 服务端口 Port int // 服务标签 Tags []string&#125;// GetHost 获取服务完整的地址func (Node Node) GetHost() string &#123; return net.JoinHostPort(Node.Address, strconv.Itoa(Node.Port))&#125;// Grouptype Group struct &#123; items []Node cursor int&#125;// Count return node countfunc (group *Group) Count() int &#123; return len(group.items)&#125;// First return fist nodefunc (group *Group) First() Node &#123; return group.items[0]&#125;// Rand return a rand nodefunc (group *Group) Rand() Node &#123; rand.Seed(time.Now().Unix()) // initialize global pseudo random generator return group.items[rand.Intn(group.Count())]&#125;// Next return the next nodefunc (group *Group) Next() Node &#123; if group.cursor == group.Count() &#123; group.cursor = 0 &#125; Node := group.items[group.cursor] group.cursor++ return Node&#125;// Add add nodefunc (group *Group) Add(node Node) &#123; group.items = append(group.items, node)&#125; EtcdETCD是一个高可用的分布式键值数据库，可用于共享配置、服务的注册和发现。ETCD采用Raft一致性算法，基于Go语言实现。ETCD作为后起之秀，又非常大的优势。 部署通过docker 部署1234567891011// 启动一个服务docker run -d -p 2379:2379 -p 2380:2380 --name etcd-server quay.io/coreos/etcd:v3.3.20// 进入服务内部docker exec -ti etcd-server /bin/sh// 将一个为hello的key，设置为worldetcdctl set hello world// 获取etcdctl get hello 安装官方包1go get github.com/coreos/etcd/client Demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package etcdimport ( \"context\" \"fmt\" \"github.com/coreos/etcd/client\" \"github.com/ebar-go/ego/component/soa/service\" \"net\" \"strconv\")var instance client.Client// InitClient 初始化Clientfunc InitClient(config client.Config) error &#123; var err error instance , err = client.New(config) return err&#125;// Register 服务注册func Register(node service.Node) error &#123; kapi := client.NewKeysAPI(instance) key := node.Name + \"/\" + node.ID val := net.JoinHostPort(node.Address, strconv.Itoa(node.Port)) resp, err := kapi.Set(context.Background(), key, val, nil) fmt.Println(resp) return err&#125;// Deregister 服务注销func Deregister(node service.Node) error &#123; kapi := client.NewKeysAPI(instance) key := node.Name + \"/\" + node.ID resp, err := kapi.Delete(context.Background(), key, nil) fmt.Println(resp) return err&#125;// Discover 服务发现func Discover(name string) error &#123; kapi := client.NewKeysAPIWithPrefix(instance, name) resp, err := kapi.Get(context.Background(), \"*\", nil) fmt.Println(resp) // TODO 待完成，因为我用docker拉取3.3.13版本以上的镜像，死都拉不下来。。特么的 return err&#125; ConsulConsul是一个高可用的分布式服务注册中心，由HashiCorp公司推出，Golang实现的开源共享的服务工具。Consul在分布式服务注册与发现方面有自己的特色，解决方案更加“一站式”，不再需要依赖其他工具。 部署通过docker部署1docker run -d -p 8500:8500 --name consul-server consul agent -server -bootstrap -ui -client=&apos;0.0.0.0&apos; 安装扩展包1go get github.com/hashicorp/consul/api Demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/**集成consul组件，包含实例化consul客户端,服务发现,服务注册,服务注销,负载均衡等方法*/package consulimport ( \"fmt\" \"github.com/ebar-go/ego/component/soa/service\" consulapi \"github.com/hashicorp/consul/api\")var client *consulapi.Client// InitClient 初始化consul客户端func InitClient(config *consulapi.Config) error &#123; var err error client, err = consulapi.NewClient(config) return err&#125;// DefaultConfig 默认配置func DefaultConfig() *consulapi.Config &#123; return consulapi.DefaultConfig()&#125;// Discover 服务发现func Discover(name string) (*service.Group, error) &#123; services, _, err := client.Health().Service(name, \"\", true, &amp;consulapi.QueryOptions&#123;&#125;) if err != nil &#123; return nil, fmt.Errorf(\"service: %s not found,%s\", name, err.Error()) &#125; if len(services) == 0 &#123; return nil, fmt.Errorf(\"service name : %s not found\", name) &#125; group := new(service.Group) for _, item := range services &#123; group.Add(service.Node&#123; ID: item.Service.ID, Name: item.Service.Service, Address: item.Service.Address, Port: item.Service.Port, Tags: item.Service.Tags, &#125;) &#125; return group, nil&#125;// Register 注册服务func Register(node service.Node) error &#123; registration := new(consulapi.AgentServiceRegistration) registration.ID = node.ID registration.Name = node.Name registration.Port = node.Port registration.Tags = node.Tags registration.Address = node.Address check := new(consulapi.AgentServiceCheck) check.HTTP = fmt.Sprintf(\"http://%s:%d%s\", registration.Address, registration.Port, \"/check\") check.Timeout = \"3s\" check.Interval = \"3s\" check.DeregisterCriticalServiceAfter = \"30s\" //check失败后30秒删除本服务 registration.Check = check return client.Agent().ServiceRegister(registration)&#125;// Deregister 注销服务func Deregister(node service.Node) error &#123; return client.Agent().ServiceDeregister(node.ID)&#125;","categories":[],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://hongker.github.io/tags/微服务/"}]},{"title":"Golang代码优化15-AOP(面向切面编程)","slug":"golang-aop","date":"2020-04-12T02:45:50.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/12/golang-aop/","link":"","permalink":"https://hongker.github.io/2020/04/12/golang-aop/","excerpt":"因为某些原因，触发了我要深入了解下AOP。 什么是AOP 核心概念 Go实现AOP 什么是AOP AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期间动态代理实现程序功能的统一维护的一种技术。扩展功能不修改源代码实现。 主要应用场景：日志记录，性能统计，安全控制，事务处理，异常处理等等。 核心概念 JoinPoint:连接点。是程序执行中的一个精确执行点，例如类中的一个方法。 PointCut：切入点。指定哪些组件的哪些方法使用切面组件。 Advice：通知，用于指定具体作用的位置，是方法之前或之后等等，分为前置通知，后置通知，异常通知，返回通知，环绕通知。 Aspect: 切面。封装通用业务逻辑的组件，即我们想要插入的代码内容。 其内在设计模式为代理模式。 Go实现AOP","text":"因为某些原因，触发了我要深入了解下AOP。 什么是AOP 核心概念 Go实现AOP 什么是AOP AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期间动态代理实现程序功能的统一维护的一种技术。扩展功能不修改源代码实现。 主要应用场景：日志记录，性能统计，安全控制，事务处理，异常处理等等。 核心概念 JoinPoint:连接点。是程序执行中的一个精确执行点，例如类中的一个方法。 PointCut：切入点。指定哪些组件的哪些方法使用切面组件。 Advice：通知，用于指定具体作用的位置，是方法之前或之后等等，分为前置通知，后置通知，异常通知，返回通知，环绕通知。 Aspect: 切面。封装通用业务逻辑的组件，即我们想要插入的代码内容。 其内在设计模式为代理模式。 Go实现AOP 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124// User type User struct &#123; Name string Pass string&#125;// Auth 验证func (u *User) Auth() &#123; // 实际业务逻辑 fmt.Printf(\"register user:%s, use pass:%s\\n\", u.Name, u.Pass)&#125;// UserAdvice type UserAdvice interface &#123; // Before 前置通知 Before(user *User) error // After 后置通知 After(user *User)&#125;// ValidatePasswordAdvice 用户名验证type ValidateNameAdvice struct &#123;&#125;// ValidatePasswordAdvice 密码验证type ValidatePasswordAdvice struct &#123; MinLength int MaxLength int&#125;func (ValidateNameAdvice) Before(user *User) error &#123; fmt.Println(\"ValidateNameAdvice before\") if user.Name == \"admin\" &#123; return errors.New(\"admin can't be used\") &#125; return nil&#125;func (ValidateNameAdvice) After(user *User) &#123; fmt.Println(\"ValidateNameAdvice after\") fmt.Printf(\"username:%s validate sucess\\n\", user.Name)&#125;// Before 前置校验func (advice ValidatePasswordAdvice) Before(user *User) error &#123; fmt.Println(\"ValidatePasswordAdvice before\") if user.Pass == \"123456\" &#123; return errors.New(\"pass isn't strong\") &#125; if len(user.Pass) &gt; advice.MaxLength &#123; return fmt.Errorf(\"len of pass must less than:%d\", advice.MaxLength) &#125; if len(user.Pass) &lt; advice.MinLength &#123; return fmt.Errorf(\"len of pass must greater than:%d\", advice.MinLength) &#125; return nil&#125;func (ValidatePasswordAdvice) After(user *User) &#123; fmt.Println(\"ValidatePasswordAdvice after\") fmt.Printf(\"password:%s validate sucess\\n\", user.Pass)&#125;// UserAdviceGroup,通知管理组type UserAdviceGroup struct &#123; items []UserAdvice&#125;// Add 注入可选通知func (g *UserAdviceGroup) Add(advice UserAdvice) &#123; g.items = append(g.items, advice)&#125;func (g *UserAdviceGroup) Before(user *User) error &#123; for _, item := range g.items &#123; if err := item.Before(user); err != nil &#123; return err &#125; &#125; return nil&#125;// Afterfunc (g *UserAdviceGroup) After(user *User) &#123; for _, item := range g.items &#123; item.After(user) &#125;&#125;// UserProxy 代理，也是切面type UserProxy struct &#123; user *User&#125;// NewUser return UserProxyfunc NewUser(name, pass string) UserProxy &#123; return UserProxy&#123;user:&amp;User&#123;Name:name, Pass:pass&#125;&#125;&#125;// Auth 校验，切入点func (p UserProxy) Auth() &#123; group := UserAdviceGroup&#123;&#125; group.Add(&amp;ValidatePasswordAdvice&#123;MaxLength:10, MinLength:6&#125;) group.Add(&amp;ValidateNameAdvice&#123;&#125;) // 前置通知 if err := group.Before(p.user); err != nil &#123; panic(err) &#125; // 实际逻辑 p.user.Auth() // 后置通知 group.After(p.user)&#125; 使用AOP模式进行解耦，分离主业务与副业务。其实也就那样。","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化14-垃圾回收","slug":"golang-gc","date":"2020-04-11T02:33:47.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/11/golang-gc/","link":"","permalink":"https://hongker.github.io/2020/04/11/golang-gc/","excerpt":"垃圾回收是golang开发者需要关注的重点知识。 什么是垃圾回收 垃圾回收（英语：Garbage Collection，缩写为GC）是一种自动内存管理机制. 垃圾回收器(Garbage Collector)尝试回收不再被程序所需要的对象所占用的内存. 经典算法引用计算将新引用对象的计数器加一，将不引用的对象的计数器减一。 标记-清除找到不可达的对象，然后做上标记。回收标记对象。因为扫描时会冻结所有的线程，执行时程序会暂停、卡顿，即Stop The World。(Dio咋瓦鲁多) Golang的GCgolang基于标记-清除算法进行优化，采用三色标记法。 原理首先将程序创建的对象都标记为白色。从root根出发扫描所有根对象，扫描所有可达的对象，标记为灰色。（root区域主要是程序运行到当前时刻的栈和全局数据区域。）从灰色对象中找到其引用对象，把灰色对象本身标记为黑色。监视对象中的内存修改，并重复上一步骤，知道灰色标记的对象不存在。此时，GC回收白色对象。最后将所有黑色标记的对象重置为白色。 三色标记法如何避免Stop the world的？因为三色标记法结束后仅剩黑色与白色对象。如果不碰触黑色对象，只清除白色对象，则不会影响程序的执行。故清除操作可以和用户程序并发执行。 针对新生成的对象，go采用了写屏障保证该对象不会被立刻清除。简单理解就是新生成的对象，一律被标记为灰色。 说实话我对原理的理解还是很生硬，仅记住三色标记法的原理。 如何进行GC优化","text":"垃圾回收是golang开发者需要关注的重点知识。 什么是垃圾回收 垃圾回收（英语：Garbage Collection，缩写为GC）是一种自动内存管理机制. 垃圾回收器(Garbage Collector)尝试回收不再被程序所需要的对象所占用的内存. 经典算法引用计算将新引用对象的计数器加一，将不引用的对象的计数器减一。 标记-清除找到不可达的对象，然后做上标记。回收标记对象。因为扫描时会冻结所有的线程，执行时程序会暂停、卡顿，即Stop The World。(Dio咋瓦鲁多) Golang的GCgolang基于标记-清除算法进行优化，采用三色标记法。 原理首先将程序创建的对象都标记为白色。从root根出发扫描所有根对象，扫描所有可达的对象，标记为灰色。（root区域主要是程序运行到当前时刻的栈和全局数据区域。）从灰色对象中找到其引用对象，把灰色对象本身标记为黑色。监视对象中的内存修改，并重复上一步骤，知道灰色标记的对象不存在。此时，GC回收白色对象。最后将所有黑色标记的对象重置为白色。 三色标记法如何避免Stop the world的？因为三色标记法结束后仅剩黑色与白色对象。如果不碰触黑色对象，只清除白色对象，则不会影响程序的执行。故清除操作可以和用户程序并发执行。 针对新生成的对象，go采用了写屏障保证该对象不会被立刻清除。简单理解就是新生成的对象，一律被标记为灰色。 说实话我对原理的理解还是很生硬，仅记住三色标记法的原理。 如何进行GC优化 减少对象的分配，合理重复利用。示例：使用sync.Pool初始化buffer池 12345678910111213141516171819202122232425// Adapter buffer pooltype Adapter struct &#123; pool sync.Pool&#125;// NewAdapterfunc NewAdapter() *Adapter &#123; return &amp;Adapter&#123;pool:sync.Pool&#123;New: func() interface&#123;&#125; &#123; return bytes.NewBuffer(make([]byte, 4096)) &#125;&#125;&#125;&#125;func main() &#123; adapter := NewAdapter() buffer := adapter.pool.Get().(*bytes.Buffer) buffer.Reset() defer func() &#123; if buffer != nil &#123; adapter.pool.Put(buffer) buffer = nil &#125; &#125;() // 使用buffer读取信息..&#125; 避免string与[]byte转换两者发生转换的时候，底层数据结结构会进行复制，因此导致 gc 效率会变低。优化如下： 1234567891011// Str2Byte return bytes of sfunc Str2Byte(s string) []byte &#123; x := (*[2]uintptr)(unsafe.Pointer(&amp;s)) h := [3]uintptr&#123;x[0], x[1], x[1]&#125; return *(*[]byte)(unsafe.Pointer(&amp;h))&#125;// Byte2Str return string of bfunc Byte2Str(b []byte) string &#123; return *(*string)(unsafe.Pointer(&amp;b))&#125; 少量使用+连接stringGo里面string是最基础的类型，是一个只读类型，针对他的每一个操作都会创建一个新的string。 如果是少量小文本拼接，用 “+” 就好；如果是大量小文本拼接，用 strings.Join；如果是大量大文本拼接，用 bytes.Buffer。 123func main() &#123; strings.Join([]string&#123;\"hello,\",\"world\"&#125;,\"\")&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化13-枚举","slug":"golang-enum","date":"2020-04-10T05:20:31.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/10/golang-enum/","link":"","permalink":"https://hongker.github.io/2020/04/10/golang-enum/","excerpt":"","text":"本文介绍golang中枚举的使用。 什么是枚举类型 是一组命名的常数，常量值可以是连续的，也可以是断续的。 说明Golang中并没有真正的枚举类型，往往都是自己定义常量，当作枚举类型来使用。 简单用法下面以订单状态来举例说明go中枚举类型的使用方式。 定义枚举常量123456789101112131415161718192021type OrderState uintconst( // 待确认 OrderConfirmed OrderState = iota + 1 // 待支付 OrderPaying // 待发货 OrderShipping // 待收货 OrderReceiving // 已收货 OrderReceived // 已完成 OrderCompleted)func main() &#123; var state =6 // 模拟从数据库中获取到的状态 if OrderState(state) == OrderCompleted &#123; fmt.Println(\"订单已完成\") &#125;&#125; 扩展 对于枚举常量，我们时常也需要展示类型的名称，如展示订单状态名称 123456789101112131415161718192021222324var ( OrderStateItems = map[OrderState]string&#123; OrderConfirmed: \"待确认\", OrderPaying: \"待支付\", OrderShipping: \"待发货\", OrderReceiving: \"待收货\", OrderReceived: \"已收货\", OrderCompleted: \"已完成\", &#125;)// OrderStateEnum 枚举类type OrderStateEnum struct &#123; // v 值 v OrderState&#125;// Name 获取订单状态名称func (e OrderStateEnum) Name() string &#123; return OrderStateItems[e.v]&#125;func main() &#123; var e = OrderStateEnum&#123;OrderCompleted&#125; fmt.Println(e.Name())&#125; 检查枚举是否合法 123456789// IsValid 检查枚举是否合法func (e OrderStateEnum) IsValid() bool &#123; _, ok := OrderStateItems[e.v] return ok&#125;func main() &#123; var e = OrderStateEnum&#123;OrderCompleted&#125; fmt.Println(e.IsValid())&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Go数据结构与算法系列(01)-排序","slug":"algorithm-sort","date":"2020-04-09T08:15:58.000Z","updated":"2021-04-24T13:55:24.060Z","comments":true,"path":"2020/04/09/algorithm-sort/","link":"","permalink":"https://hongker.github.io/2020/04/09/algorithm-sort/","excerpt":"说明 冒泡排序 选择排序 快速排序 插入排序 本文介绍通过go实现常见的排序算法。 说明虽然go的内置sort包实现了相关排序算法，但是我们要了解其原理，通过自己实现一次，加深印象。 冒泡排序 原理：比较两个相邻的元素，将值大的元素交换到右边。时间复杂度为O(n^2) Demo 123456789101112131415// BubbleSort 冒泡排序// 比较两个元素，将最大的元素放在右边func BubbleSort(a [] int) &#123; // 从最后一个元素进行排序 for first := len(a) - 1;first&gt;=1;first-- &#123; // 遍历剩余元素 for second := first - 1;second&gt;=0;second-- &#123; // 找到大的 if a[first] &lt; a[second] &#123; // 交换 a[first], a[second] = a[second], a[first] &#125; &#125; &#125;&#125; Test 12345678910import ( \"fmt\" \"testing\")var a = []int&#123;10,1,35,61,89,36,55&#125;func TestBubbleSort(t *testing.T) &#123; BubbleSort(a) fmt.Println(a)&#125; 输出: 1[1 10 35 36 55 61 89]","text":"说明 冒泡排序 选择排序 快速排序 插入排序 本文介绍通过go实现常见的排序算法。 说明虽然go的内置sort包实现了相关排序算法，但是我们要了解其原理，通过自己实现一次，加深印象。 冒泡排序 原理：比较两个相邻的元素，将值大的元素交换到右边。时间复杂度为O(n^2) Demo 123456789101112131415// BubbleSort 冒泡排序// 比较两个元素，将最大的元素放在右边func BubbleSort(a [] int) &#123; // 从最后一个元素进行排序 for first := len(a) - 1;first&gt;=1;first-- &#123; // 遍历剩余元素 for second := first - 1;second&gt;=0;second-- &#123; // 找到大的 if a[first] &lt; a[second] &#123; // 交换 a[first], a[second] = a[second], a[first] &#125; &#125; &#125;&#125; Test 12345678910import ( \"fmt\" \"testing\")var a = []int&#123;10,1,35,61,89,36,55&#125;func TestBubbleSort(t *testing.T) &#123; BubbleSort(a) fmt.Println(a)&#125; 输出: 1[1 10 35 36 55 61 89] 选择排序 原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕时间复杂度为O(n^2) Demo 1234567891011121314151617181920// SelectionSort 选择排序// 找到最小的值，分别放到数组前面。func SelectionSort(a []int) &#123; // 遍历数据 for i := 0; i&lt;len(a);i++ &#123; // 定义最小值的下标 min := i // 遍历剩下的元素，找到最小值的下表 for j :=i+1; j&lt; len(a);j++ &#123; if a[j] &lt; a[min] &#123; min = j &#125; &#125; // 交换数据 if min != i &#123; a[min], a[i] = a[i], a[min] &#125; &#125;&#125; Test 12345678910import ( \"fmt\" \"testing\")var a = []int&#123;10,1,35,61,89,36,55&#125;func TestSelectionSort(t *testing.T) &#123; SelectionSort(a) fmt.Println(a)&#125; 输出 1[1 10 35 36 55 61 89] 快速排序 原理：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行递归排序，以达到整个序列有序。 Demo 1234567891011121314151617181920212223242526272829303132// QuickSort 快速排序// low : 数组的左侧下标, high: 数组的右侧下标func QuickSort(a []int, low int, high int) &#123; if low &gt;= high &#123; // 已排序完成 return &#125; pivot := a[low] // 指定基准值 right := high left := low for &#123; // 在不超过起点(low)的情况下,如果右边的值比基准值大，则继续遍历，为了找到比基准值小的数据 for a[right] &gt;= pivot &amp;&amp; right &gt; low &#123; right-- &#125; // 在不超过终点(high)的情况下，如果左边的值比基准值小，则继续遍历，为了找到比基准值大的数据 for a[left]&lt;= pivot &amp;&amp; left &lt; high &#123; left++ &#125; if left &lt; right &#123; // 此条件表示找到对应的数据，满足可交换的条件，比基准值大的放右边，比基准值小的放左边 a[left], a[right] = a[right], a[left] &#125;else &#123; // 表示已遍历完成，退出循环 break &#125; &#125; // 这里很重要，右侧值与基准值交换，将基准值归位，此刻数组已形成右侧为比基准值小的数据，右侧为比基准值大的数据 a[low], a[right] = a[right], a[low] QuickSort(a, low, right) QuickSort(a, right+1, high)&#125; 插入排序 原理：通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 Demo 123456789101112131415161718// InsertSort 插入排序func InsertSort(a []int) &#123; // 前节点、当前值 var preIndex, current int for i:=1; i&lt;len(a);i++ &#123; preIndex = i-1 current = a[i] // 遍历，当前一个值大于当前值时 for preIndex&gt;=0 &amp;&amp; a[preIndex] &gt; current &#123; // 将前节点值向后挪一位 a[preIndex+1] = a[preIndex] // 继续向前遍历 preIndex-- &#125; // 将当前值插入 a[preIndex+1] = current &#125;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://hongker.github.io/tags/algorithm/"}]},{"title":"微服务00-架构设计","slug":"micro-service","date":"2020-04-08T13:09:24.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/08/micro-service/","link":"","permalink":"https://hongker.github.io/2020/04/08/micro-service/","excerpt":"本文介绍一些关于微服务架构设计的相关知识点。 什么是微服务 每个微服务都可以运行在自己的进程里；一系列独立运行的服务共同构建起了整个系统；每个服务为独立的业务开发，一个微服务一般完成某个特定的功能，比如订单管理，用户管理等；微服务之间通过一些轻量级的通信机制进行通信，例如通过REST API或者RPC的方式进行调用 特点 针对特定服务发布，影响小，风险小，成本低。 频繁发布版本，快速持续迭代。 低成本扩容，弹性伸缩。 架构图 模块说明","text":"本文介绍一些关于微服务架构设计的相关知识点。 什么是微服务 每个微服务都可以运行在自己的进程里；一系列独立运行的服务共同构建起了整个系统；每个服务为独立的业务开发，一个微服务一般完成某个特定的功能，比如订单管理，用户管理等；微服务之间通过一些轻量级的通信机制进行通信，例如通过REST API或者RPC的方式进行调用 特点 针对特定服务发布，影响小，风险小，成本低。 频繁发布版本，快速持续迭代。 低成本扩容，弹性伸缩。 架构图 模块说明 应用层待定。 API网关待定。 服务注册与发现待定。 业务层(中台服务)待定。 支撑服务待定。 数据层待定。 DevOps 开发与运维待定。","categories":[],"tags":[{"name":"micro-service","slug":"micro-service","permalink":"https://hongker.github.io/tags/micro-service/"}]},{"title":"Golang代码优化12-gorm","slug":"golang-sql","date":"2020-04-07T05:00:00.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/07/golang-sql/","link":"","permalink":"https://hongker.github.io/2020/04/07/golang-sql/","excerpt":"本文介绍再golang中通过gorm对mysql的操作。 什么是Gorm Golang写的，开发人员友好的ORM库。官方地址：http://gorm.book.jasperxu.com/. 安装1go get -u github.com/jinzhu/gorm 准备工作12345678910111213141516// 创建数据库create database test charset=utf8;use test;// 创建Users表drop table if exists users;create table users ( id int unsigned not null primary key auto_increment comment '主键', username varchar(50) not null default '' comment '姓名', password varchar(32) not null default '' comment '密码', is_deleted tinyint unsigned not null default 0 comment '是否删除', created_at timestamp default CURRENT_TIMESTAMP not null comment '创建时间', updated_at timestamp default CURRENT_TIMESTAMP not null on update CURRENT_TIMESTAMP comment '更新时间', key `idx_del`(`is_deleted`))engine=Innodb charset=utf8mb4 comment='示例'; 创建Connection1234567891011// Connection 创建数据库连接func Connection() *gorm.DB &#123; // dsn的格式为 用户名:密码/tcp(主机地址)/数据库名称?charset=字符格式 dsn := \"root:123456@tcp(10.0.75.2)/test?charset=utf8&amp;parseTime=True&amp;loc=Local\" db, err := gorm.Open(\"mysql\", dsn) if err != nil &#123; panic(err) &#125; return db&#125;","text":"本文介绍再golang中通过gorm对mysql的操作。 什么是Gorm Golang写的，开发人员友好的ORM库。官方地址：http://gorm.book.jasperxu.com/. 安装1go get -u github.com/jinzhu/gorm 准备工作12345678910111213141516// 创建数据库create database test charset=utf8;use test;// 创建Users表drop table if exists users;create table users ( id int unsigned not null primary key auto_increment comment '主键', username varchar(50) not null default '' comment '姓名', password varchar(32) not null default '' comment '密码', is_deleted tinyint unsigned not null default 0 comment '是否删除', created_at timestamp default CURRENT_TIMESTAMP not null comment '创建时间', updated_at timestamp default CURRENT_TIMESTAMP not null on update CURRENT_TIMESTAMP comment '更新时间', key `idx_del`(`is_deleted`))engine=Innodb charset=utf8mb4 comment='示例'; 创建Connection1234567891011// Connection 创建数据库连接func Connection() *gorm.DB &#123; // dsn的格式为 用户名:密码/tcp(主机地址)/数据库名称?charset=字符格式 dsn := \"root:123456@tcp(10.0.75.2)/test?charset=utf8&amp;parseTime=True&amp;loc=Local\" db, err := gorm.Open(\"mysql\", dsn) if err != nil &#123; panic(err) &#125; return db&#125; 定义模型 针对gorm对timestamp类型的格式化 1234567891011121314151617181920212223242526272829// Timestamp 自定义gorm的时间戳格式type Timestamp struct &#123; time.Time&#125;// MarshalJSON 解析func (t Timestamp) MarshalJSON() ([]byte, error) &#123; formatted := fmt.Sprintf(\"\\\"%s\\\"\", t.Format(date.TimeFormat)) return []byte(formatted), nil&#125;// Valuefunc (t Timestamp) Value() (driver.Value, error) &#123; var zeroTime time.Time if t.Time.UnixNano() == zeroTime.UnixNano() &#123; return nil, nil &#125; return t.Time, nil&#125;// Scan 转换时间戳func (t *Timestamp) Scan(v interface&#123;&#125;) error &#123; value, ok := v.(time.Time) if ok &#123; *t = Timestamp&#123;Time: value&#125; return nil &#125; return fmt.Errorf(\"can not convert %v to timestamp\", v)&#125; 定义模型 123456789101112131415161718const ( TableUser = \"users\")// User 用户模型type User struct &#123; ID int `gorm:\"primary_key;AUTO_INCREMENT;column:id\" json:\"id\"` Username string `json:\"username\" gorm:\"column:username\"` Password string `json:\"password\" gorm:\"column:password\"` IsDeleted int `json:\"is_deleted\" gorm:\"column:is_deleted\"` // 对time进行格式化 CreatedAt Timestamp `gorm:\"column:created_at\" json:\"created_at\"` UpdatedAt Timestamp `gorm:\"column:created_at\" json:\"updated_at\"`&#125;// TableName 指定模型的表名称func (User) TableName() string &#123; return TableUser&#125; 定义Dao设计一个Dao来进行数据表的操作 123456789101112131415161718192021222324252627282930313233// UserDaotype UserDao struct &#123; db *gorm.DB&#125;// GetUserDaofunc GetUserDao(db *gorm.DB) *UserDao &#123; return &amp;UserDao&#123;db:db&#125;&#125;// Create 创建记录func (dao *UserDao) Create(user *User) error &#123; return dao.db.Omit(\"created_at\", \"updated_at\"). Create(user).Error&#125;// GetByUsername 根据用户名获取记录func (dao *UserDao) GetByUsername(username string) (*User, error) &#123; query := dao.db.Table(TableUser).Where(\"username = ?\", username) user := new(User) if err := query.First(user).Error; err != nil &#123; return nil, err &#125; return user, nil&#125;// Update 更新字段func (dao *UserDao) Update(id int, columns map[string]interface&#123;&#125;) error &#123; return dao.db.Where(\"id = ?\", id).Updates(columns).Error&#125; 创建记录 123456789101112131415161718192021222324252627282930313233//Md5 return the encrypt string by md5 algorithmfunc Md5(s string) string &#123; h := md5.New() h.Write([]byte(s)) return hex.EncodeToString(h.Sum(nil))&#125;import ( \"crypto/md5\" \"encoding/hex\" \"fmt\" _ \"github.com/go-sql-driver/mysql\" \"github.com/jinzhu/gorm\")func main() &#123; conn := Connection() defer conn.Close() // 创建 user := &amp;User&#123; Username: \"user1\", Password: Md5(\"123456\"), // 使用md5加密 &#125; dao := GetUserDao(conn) if err := dao.Create(user); err != nil &#123; fmt.Println(\"failed to create user:\", err.Error()) &#125;else &#123; fmt.Println(\"created user success:\", user.ID) &#125;&#125; 创建成功输出:1created user success: 1 登录校验12345678910111213141516171819202122232425262728293031323334353637383940414243func main() &#123; conn := Connection() defer conn.Close() router := gin.Default() router.POST(\"/user/auth\", func(ctx *gin.Context) &#123; type AuthRequest struct &#123; Username string `json:\"username\"` // 这里要求用json请求 Password string `json:\"password\"` &#125; var request AuthRequest if err := ctx.ShouldBindJSON(&amp;request); err != nil &#123; ctx.JSON(200, gin.H&#123; \"message\" : fmt.Sprintf(\"参数错误:%s\", err.Error()), &#125;) return &#125; dao := GetUserDao(conn) user, err := dao.GetByUsername(request.Username) if err != nil &#123; ctx.JSON(200, gin.H&#123; \"message\" : fmt.Sprintf(\"用户不存在:%s\", request.Username), &#125;) return &#125; if Md5(request.Password) != user.Password &#123; ctx.JSON(200, gin.H&#123; \"message\" : \"密码错误\", &#125;) return &#125; ctx.JSON(200, gin.H&#123; \"message\" : \"success\", \"token\": \"token\", // 返回用户登录令牌 &#125;) &#125;) router.Run(\":8080\")&#125; 通过curl验证：1234567curl -X POST -H &quot;Content-Type:application/json&quot; -d &apos;&#123;&quot;username&quot;:&quot;user1&quot;,password:&quot;123456&quot;&#125;&apos; localhost:8080/user/auth// 接口返回：&#123; &quot;message&quot;: &quot;success&quot;, &quot;token&quot;: &quot;token&quot;&#125; 连接池 12345// 设置mysql的空闲连接数conn.DB().SetMaxIdleConns(options.MaxIdleConnections)// 设置mysql的最大打开的连接数conn.DB().SetMaxOpenConns(options.MaxOpenConnections) 设置连接过期时间 1conn.DB().SetConnMaxLifetime(time.Second * 10) 开启log 1conn.LogMode(true) 以上介绍的是gorm的常用的操作，如有其他疑问请查看官方文档或者再下方提问，随缘回复。。","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang优化代码11-数据校验","slug":"golang-validator","date":"2020-04-01T13:50:43.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/01/golang-validator/","link":"","permalink":"https://hongker.github.io/2020/04/01/golang-validator/","excerpt":"本文介绍github.com/go-playground/validator/v10的用法。 验证器 在项目中经常对客户端发起的接口请求参数进行校验，通常开发者必须自己编写一套验证的规则，但是使用统一的数据验证器能减轻开发者的负担，以及简化代码。程序员并不是偷懒，而是提高自己的效率。 安装1go get github.com/go-playground/validator/v10 使用 required 必填项对于请求参数来说，使用的最多的就是必填项。数字0,空string、slices,map,pointer,interface,channel,function都会校验不通过。1234567891011121314151617181920212223242526import \"github.com/go-playground/validator/v10\"// 初始化验证器var validate = validator.New()func main() &#123; var err error // 空interface var m map[string]int // 空map var ch chan int // 空channel var s []int // 空slice var p *log.Logger // 空pointer var f func() // 空func items := map[string]interface&#123;&#125;&#123; \"zero\": 0, // 改成非0会输出nil，说明通过校验，没有错误 \"string\":\"\", \"slice\": s, \"map\": m, \"pointer\" : p, \"interface\": err, \"channel\" : ch, \"function\": f, &#125; for idx, val := range items &#123; fmt.Printf(\"%s:%v\\n\", idx, validate.Var(val, \"required\")) &#125;&#125; 输出错误信息，说明校验都未通过:12345678function:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagzero:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagstring:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagslice:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagmap:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagpointer:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; taginterface:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagchannel:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tag 其他校验123456789func main() &#123; // 验证邮箱格式 fmt.Println(\"ValidateEmail:\",validate.Var(\"123456.qq.com\", \"required,email\")) // failed fmt.Println(\"ValidateEmail:\",validate.Var(\"123456@qq.com\", \"required,email\")) // success // 校验数字范围,gt:大于,gte:大于等于,lt:小于,lte:小于等于 fmt.Println(\"ValidateNumber:\", validate.Var(100, \"required,gt=100,lt=120\")) // failed fmt.Println(\"ValidateNumber:\", validate.Var(110, \"required,gte=100,lte=120\")) // success&#125;","text":"本文介绍github.com/go-playground/validator/v10的用法。 验证器 在项目中经常对客户端发起的接口请求参数进行校验，通常开发者必须自己编写一套验证的规则，但是使用统一的数据验证器能减轻开发者的负担，以及简化代码。程序员并不是偷懒，而是提高自己的效率。 安装1go get github.com/go-playground/validator/v10 使用 required 必填项对于请求参数来说，使用的最多的就是必填项。数字0,空string、slices,map,pointer,interface,channel,function都会校验不通过。1234567891011121314151617181920212223242526import \"github.com/go-playground/validator/v10\"// 初始化验证器var validate = validator.New()func main() &#123; var err error // 空interface var m map[string]int // 空map var ch chan int // 空channel var s []int // 空slice var p *log.Logger // 空pointer var f func() // 空func items := map[string]interface&#123;&#125;&#123; \"zero\": 0, // 改成非0会输出nil，说明通过校验，没有错误 \"string\":\"\", \"slice\": s, \"map\": m, \"pointer\" : p, \"interface\": err, \"channel\" : ch, \"function\": f, &#125; for idx, val := range items &#123; fmt.Printf(\"%s:%v\\n\", idx, validate.Var(val, \"required\")) &#125;&#125; 输出错误信息，说明校验都未通过:12345678function:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagzero:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagstring:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagslice:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagmap:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagpointer:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; taginterface:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tagchannel:Key: &apos;&apos; Error:Field validation for &apos;&apos; failed on the &apos;required&apos; tag 其他校验123456789func main() &#123; // 验证邮箱格式 fmt.Println(\"ValidateEmail:\",validate.Var(\"123456.qq.com\", \"required,email\")) // failed fmt.Println(\"ValidateEmail:\",validate.Var(\"123456@qq.com\", \"required,email\")) // success // 校验数字范围,gt:大于,gte:大于等于,lt:小于,lte:小于等于 fmt.Println(\"ValidateNumber:\", validate.Var(100, \"required,gt=100,lt=120\")) // failed fmt.Println(\"ValidateNumber:\", validate.Var(110, \"required,gte=100,lte=120\")) // success&#125; 校验结构体通过tag标签定义结构体属性的校验规则，一次性校验所有属性，提高效率。 123456789101112131415161718func main() &#123; type User struct &#123; Name string `json:\"name\" validate:\"required\"` Age uint8 `json:\"age\" validate:\"gte=0,lte=130\"` &#125; user := &amp;User&#123; Name: \"\", Age: 0, &#125; fmt.Println(\"ValidateUser:\", validate.Struct(user)) // failed user1 := &amp;User&#123; Name: \"test\", Age: 10, &#125; fmt.Println(\"ValidateUser:\", validate.Struct(user1)) // success&#125; 配合gin校验请求参数因为gin已对接了验证器，所以使用Bind,ShouldBind等函数即可完成参数校验 123456789101112131415161718192021222324252627282930313233func main() &#123; router := gin.Default() router.POST(\"user/auth\", func(ctx *gin.Context) &#123; type AuthRequest struct &#123; // 如果是表单提交，使用form,否则获取不到数据 Email string `json:\"email\" binding:\"required,email\"` // 验证邮箱格式 Pass string `json:\"pass\" binding:\"required,min=6,max=10\"` // 验证密码，长度为6~10 &#125; var request AuthRequest // 使用bind if err := ctx.ShouldBindJSON(&amp;request); err != nil &#123; ctx.JSON(200, gin.H&#123; \"message\" : err.Error(), &#125;) return &#125; // 模拟判断业务 if request.Email != \"123456@qq.com\" &#123; ctx.JSON(200, gin.H&#123; \"message\" : fmt.Sprintf(\"邮箱不存在:%s\", request.Email), &#125;) return &#125; ctx.JSON(200, gin.H&#123; \"message\" : \"success\", &#125;) &#125;) router.Run(\":8080\")&#125; 自定义验证器支持错误信息汉化、支持自定义字段名称。一切都在注释中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import ( \"errors\" \"github.com/go-playground/locales/zh\" ut \"github.com/go-playground/universal-translator\" \"github.com/go-playground/validator/v10\" zh_translations \"github.com/go-playground/validator/v10/translations/zh\" \"reflect\" \"sync\" \"github.com/gin-gonic/gin/binding\")// Validatortype Validator struct &#123; once sync.Once validate *validator.Validate&#125;// 定义一个中文翻译器var translation ut.Translatorfunc init() &#123; // 初始化 translation, _ = ut.New(zh.New()).GetTranslator(\"zh\")&#125;// ValidateStruct validate structfunc (v *Validator) ValidateStruct(obj interface&#123;&#125;) error &#123; value := reflect.ValueOf(obj) valueType := value.Kind() if valueType == reflect.Ptr &#123; valueType = value.Elem().Kind() &#125; if valueType == reflect.Struct &#123; v.lazyInit() if err := v.validate.Struct(obj); err != nil &#123; //验证器 for _, err := range err.(validator.ValidationErrors) &#123; return errors.New(err.Translate(translation)) &#125; &#125; &#125; return nil&#125;// Enginefunc (v *Validator) Engine() interface&#123;&#125; &#123; v.lazyInit() return v.validate&#125;// lazyInit 该方法会依次验证 Struct 的属性，遇到第一个错误的时候就会停止验证，并将错误信息返回func (v *Validator) lazyInit() &#123; v.once.Do(func() &#123; v.validate = validator.New() // 指定验证的tag名称,gin默认是binding,也可以自己改成\"validate\"或者其他的tag v.validate.SetTagName(\"binding\") // 定义一个交叫comment的tag为字段的名称,如 Name `comment:\"姓名\"` v.validate.RegisterTagNameFunc(func(fld reflect.StructField) string &#123; return fld.Tag.Get(\"comment\") &#125;) // use zh-CN _ = zh_translations.RegisterDefaultTranslations(v.validate, translation) &#125;)&#125;// 使用func main() &#123; // 设置自定义验证器 binding.Validator = new(Validator) router := gin.Default() router.POST(\"user/auth\", func(ctx *gin.Context) &#123; type AuthRequest struct &#123; // 如果是表单提交，使用form,否则获取不到数据 Email string `json:\"email\" validate:\"required,email\" comment:\"邮箱\"` // 验证邮箱格式 Pass string `json:\"pass\" binding:\"required,min=6,max=10\"` // 验证密码，长度为6~10 &#125; var request AuthRequest // 使用bind if err := ctx.ShouldBindJSON(&amp;request); err != nil &#123; ctx.JSON(200, gin.H&#123; \"message\" : err.Error(), &#125;) return &#125; // 判断业务 if request.Email != \"123456@qq.com\" &#123; ctx.JSON(200, gin.H&#123; \"message\" : fmt.Sprintf(\"邮箱不存在:%s\", request.Email), &#125;) return &#125; ctx.JSON(200, gin.H&#123; \"message\" : \"success\", &#125;) &#125;) router.Run(\":8080\")&#125; 可以自己通过如postman测试。。","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化10-gin","slug":"golang-gin","date":"2020-04-01T13:50:13.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/01/golang-gin/","link":"","permalink":"https://hongker.github.io/2020/04/01/golang-gin/","excerpt":"本文介绍gin的一些知识点,如自定义Response,中间件等。 gin Gin 是一个 go 写的 web 框架，具有高性能的优点。 初级的使用方式不介绍了，具体请查阅官方文档。官方地址：https://github.com/gin-gonic/gin 以下介绍基于gin开发项目的一些常用模块。 自定义Response每个公司都会自定义接口的数据结构。故我们需要基于Json()自定义一个更方便好用的response12345678910111213141516171819202122232425262728293031323334353637383940414243// Response 数据结构体type Response struct &#123; // StatusCode 业务状态码 StatusCode int `json:\"status_code\"` // Message 提示信息 Message string `json:\"message\"` // Data 数据，用interface&#123;&#125;的目的是可以用任意数据 Data interface&#123;&#125; `json:\"data\"` // Meta 源数据,存储如请求ID,分页等信息 Meta Meta `json:\"meta\"` // Errors 错误提示，如 xx字段不能为空等 Errors []ErrorItem `json:\"errors\"`&#125;// Meta 元数据type Meta struct &#123; RequestId string `json:\"request_id\"` // 还可以集成分页信息等&#125;// ErrorItem 错误项type ErrorItem struct &#123; Key string `json:\"key\"` Value string `json:\"error\"`&#125;// New return response instancefunc New() *Response &#123; return &amp;Response&#123; StatusCode: 200, Message: \"\", Data: nil, Meta: Meta&#123; RequestId: uuid.NewV4().String(), &#125;, Errors: []ErrorItem&#123;&#125;, &#125;&#125; 封装gin.Context以自定义一些方便的方法1234567891011121314151617181920212223242526272829// Wrapper include contexttype Wrapper struct &#123; ctx *gin.Context&#125;// WrapContextfunc WrapContext(ctx *gin.Context) *Wrapper &#123; return &amp;Wrapper&#123;ctx:ctx&#125;&#125;// Json 输出json,支持自定义response结构体func (wrapper *Wrapper) Json(response *Response) &#123; wrapper.ctx.JSON(200, response)&#125;// Success 成功的输出func (wrapper *Wrapper) Success( data interface&#123;&#125;) &#123; response := New() response.Data = data wrapper.Json(response)&#125;// Error 错误输出func (wrapper *Wrapper) Error( statusCode int, message string) &#123; response := New() response.StatusCode = statusCode response.Message = message wrapper.Json(response)&#125; 使用：123456789101112131415package mainimport ( \"github.com/gin-gonic/gin\" uuid \"github.com/satori/go.uuid\")func main() &#123; router := gin.Default() router.GET(\"/\", func(ctx *gin.Context) &#123; WrapContext(ctx).Success(\"hello,world\") &#125;) router.Run(\":8088\")&#125; 通过go run main.go运行后，浏览器访问localhost:8088 中间件介绍一些常用的中间件，如跨域、Jwt校验、请求日志等。","text":"本文介绍gin的一些知识点,如自定义Response,中间件等。 gin Gin 是一个 go 写的 web 框架，具有高性能的优点。 初级的使用方式不介绍了，具体请查阅官方文档。官方地址：https://github.com/gin-gonic/gin 以下介绍基于gin开发项目的一些常用模块。 自定义Response每个公司都会自定义接口的数据结构。故我们需要基于Json()自定义一个更方便好用的response12345678910111213141516171819202122232425262728293031323334353637383940414243// Response 数据结构体type Response struct &#123; // StatusCode 业务状态码 StatusCode int `json:\"status_code\"` // Message 提示信息 Message string `json:\"message\"` // Data 数据，用interface&#123;&#125;的目的是可以用任意数据 Data interface&#123;&#125; `json:\"data\"` // Meta 源数据,存储如请求ID,分页等信息 Meta Meta `json:\"meta\"` // Errors 错误提示，如 xx字段不能为空等 Errors []ErrorItem `json:\"errors\"`&#125;// Meta 元数据type Meta struct &#123; RequestId string `json:\"request_id\"` // 还可以集成分页信息等&#125;// ErrorItem 错误项type ErrorItem struct &#123; Key string `json:\"key\"` Value string `json:\"error\"`&#125;// New return response instancefunc New() *Response &#123; return &amp;Response&#123; StatusCode: 200, Message: \"\", Data: nil, Meta: Meta&#123; RequestId: uuid.NewV4().String(), &#125;, Errors: []ErrorItem&#123;&#125;, &#125;&#125; 封装gin.Context以自定义一些方便的方法1234567891011121314151617181920212223242526272829// Wrapper include contexttype Wrapper struct &#123; ctx *gin.Context&#125;// WrapContextfunc WrapContext(ctx *gin.Context) *Wrapper &#123; return &amp;Wrapper&#123;ctx:ctx&#125;&#125;// Json 输出json,支持自定义response结构体func (wrapper *Wrapper) Json(response *Response) &#123; wrapper.ctx.JSON(200, response)&#125;// Success 成功的输出func (wrapper *Wrapper) Success( data interface&#123;&#125;) &#123; response := New() response.Data = data wrapper.Json(response)&#125;// Error 错误输出func (wrapper *Wrapper) Error( statusCode int, message string) &#123; response := New() response.StatusCode = statusCode response.Message = message wrapper.Json(response)&#125; 使用：123456789101112131415package mainimport ( \"github.com/gin-gonic/gin\" uuid \"github.com/satori/go.uuid\")func main() &#123; router := gin.Default() router.GET(\"/\", func(ctx *gin.Context) &#123; WrapContext(ctx).Success(\"hello,world\") &#125;) router.Run(\":8088\")&#125; 通过go run main.go运行后，浏览器访问localhost:8088 中间件介绍一些常用的中间件，如跨域、Jwt校验、请求日志等。 备注引入中间件比如在注册路由之前,谨记! 跨域中间件 12345678910111213141516171819202122package middlewareimport ( \"github.com/gin-gonic/gin\")// CORS 跨域中间件func CORS(ctx *gin.Context) &#123; method := ctx.Request.Method // set response header ctx.Header(\"Access-Control-Allow-Origin\", ctx.Request.Header.Get(\"Origin\")) ctx.Header(\"Access-Control-Allow-Credentials\", \"true\") ctx.Header(\"Access-Control-Allow-Headers\", \"Content-Type, Access-Control-Allow-Headers, Authorization, X-Requested-With\") ctx.Header(\"Access-Control-Allow-Methods\", \"GET,POST,PUT,PATCH,DELETE,OPTIONS\") // 默认过滤这两个请求,使用204(No Content)这个特殊的http status code if method == \"OPTIONS\" || method == \"HEAD\" &#123; ctx.AbortWithStatus(204) return &#125; ctx.Next()&#125; 使用如下：123456789func main() &#123; router := gin.Default() router.Use(CORS) router.GET(\"/\", func(ctx *gin.Context) &#123; WrapContext(ctx).Success(\"hello,world\") &#125;) router.Run(\":8088\")&#125; Jwt校验123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package mainimport ( \"errors\" \"github.com/dgrijalva/jwt-go\" \"github.com/gin-gonic/gin\" \"strings\" \"time\")var ( TokenNotExist = errors.New(\"token not exist\") TokenValidateFailed = errors.New(\"token validate failed\") ClaimsKey = \"uniqueClaimsKey\" SignKey = \"test\")// JwtAuth jwttype JwtAuth struct &#123; SignKey []byte&#125;// ParseToken parse tokenfunc (jwtAuth JwtAuth) ParseToken(token string) (jwt.Claims, error) &#123; tokenClaims, err := jwt.Parse(token, func(token *jwt.Token) (interface&#123;&#125;, error) &#123; return jwtAuth.SignKey, nil &#125;) if err != nil &#123; return nil, err &#125; if tokenClaims.Claims == nil || !tokenClaims.Valid &#123; return nil, TokenValidateFailed &#125; return tokenClaims.Claims, nil&#125;// GenerateTokenfunc (jwtAuth JwtAuth) GenerateToken(tokenExpireTime int64 /* 过期时间 */, iss string /* key*/) (string, error) &#123; now := time.Now().Unix() exp := now + tokenExpireTime claim := jwt.MapClaims&#123; \"iss\": iss, \"iat\": now, \"exp\": exp, &#125; token := jwt.NewWithClaims(jwt.SigningMethodHS256, claim) tokenStr, err := token.SignedString(jwtAuth.SignKey) return tokenStr, err&#125;// JWT gin的jwt中间件func JWT(ctx *gin.Context) &#123; // 解析token if err := validateToken(ctx); err != nil &#123; WrapContext(ctx).Error(401, err.Error()) ctx.Abort() return &#125; ctx.Next()&#125;// validateToken 验证tokenfunc validateToken(ctx *gin.Context) error &#123; // 获取token tokenStr := ctx.GetHeader(\"Authorization\") kv := strings.Split(tokenStr, \" \") if len(kv) != 2 || kv[0] != \"Bearer\" &#123; return TokenNotExist &#125; jwtAuth := &amp;JwtAuth&#123;SignKey: []byte(SignKey)&#125; claims, err := jwtAuth.ParseToken(kv[1]) if err != nil &#123; return err &#125; // token存入context ctx.Set(ClaimsKey, claims) return nil&#125; 使用如下：123456789101112131415161718192021func main() &#123; router := gin.Default() router.GET(\"/\", func(ctx *gin.Context) &#123; WrapContext(ctx).Success(\"hello,world\") &#125;) // 指定user这组路由都需要校验jwt user := router.Group(\"/user\").Use(JWT) &#123; user.GET(\"/info\", func(ctx *gin.Context) &#123; claims, exist := ctx.Get(ClaimsKey) if !exist &#123; WrapContext(ctx).Error(1001, \"获取用户信息失败\") &#125; WrapContext(ctx).Success(claims) &#125;) &#125; router.Run(\":8088\")&#125; 请求测试：12345678curl &quot;localhost:8088/user/info&quot;// 输出:// &#123;&quot;status_code&quot;:401,&quot;message&quot;:&quot;token not exist&quot;,&quot;data&quot;:null,&quot;meta&quot;:&#123;&quot;request_id&quot;:&quot;e69361cf-1fd4-42e4-8af8-d18fac1e70fb&quot;&#125;,&quot;errors&quot;:[]&#125;// 通过GenerateToken()生成一个tokencurl -H &quot;Authorization:Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1ODU4MjQ2NzgsImlhdCI6MTU4NTgyMTA3OCwiaXNzIjoiYWEifQ.Eyo8KptVUgGfnRG8zsjDilAJOBmaXMtjqJxw__a32HY&quot; localhost:8088/user/info// 输出：&#123;&quot;status_code&quot;:200,&quot;message&quot;:&quot;&quot;,&quot;data&quot;:&#123;&quot;exp&quot;:1585824678,&quot;iat&quot;:1585821078,&quot;iss&quot;:&quot;aa&quot;&#125;,&quot;meta&quot;:&#123;&quot;request_id&quot;:&quot;464743de-1033-4656-96f8-36c1529f13e0&quot;&#125;,&quot;errors&quot;:[]&#125; 请求日志记录每个请求的重要信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import ( \"bytes\" \"fmt\" \"github.com/gin-gonic/gin\" \"io/ioutil\" \"log\" \"net/http\" \"time\")// bodyLogWriter 定义一个存储响应内容的结构体type bodyLogWriter struct &#123; gin.ResponseWriter body *bytes.Buffer&#125;// Write 读取响应数据func (w bodyLogWriter) Write(b []byte) (int, error) &#123; w.body.Write(b) return w.ResponseWriter.Write(b)&#125;// RequestLog gin的请求日志中间件func RequestLog(c *gin.Context) &#123; // 记录请求开始时间 t := time.Now() blw := &amp;bodyLogWriter&#123;body: bytes.NewBufferString(\"\"), ResponseWriter: c.Writer&#125; // 必须! c.Writer = blw // 获取请求信息 requestBody := getRequestBody(c) c.Next() // 记录请求所用时间 latency := time.Since(t) // 获取响应内容 responseBody := blw.body.String() logContext := make(map[string]interface&#123;&#125;) // 日志格式 logContext[\"request_uri\"] = c.Request.RequestURI logContext[\"request_method\"] = c.Request.Method logContext[\"refer_service_name\"] = c.Request.Referer() logContext[\"refer_request_host\"] = c.ClientIP() logContext[\"request_body\"] = requestBody logContext[\"request_time\"] = t.String() logContext[\"response_body\"] = responseBody logContext[\"time_used\"] = fmt.Sprintf(\"%v\", latency) logContext[\"header\"] = c.Request.Header log.Println(logContext)&#125;// getRequestBody 获取请求参数func getRequestBody(c *gin.Context) interface&#123;&#125; &#123; switch c.Request.Method &#123; case http.MethodGet: return c.Request.URL.Query() case http.MethodPost: fallthrough case http.MethodPut: fallthrough case http.MethodPatch: var bodyBytes []byte // 我们需要的body内容 // 可以用buffer代替ioutil.ReadAll提高性能 bodyBytes, err := ioutil.ReadAll(c.Request.Body) if err != nil &#123; return nil &#125; // 将数据还回去 c.Request.Body = ioutil.NopCloser(bytes.NewBuffer(bodyBytes)) return string(bodyBytes) &#125; return nil&#125; 使用1router.Use(ReqeustLog) 今天就到这儿吧，还有一些比如全局ID中间件，后面来写。","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化09-日志","slug":"golang-log","date":"2020-04-01T13:48:16.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/01/golang-log/","link":"","permalink":"https://hongker.github.io/2020/04/01/golang-log/","excerpt":"本文介绍在golang中的日志使用方式。 官方自带Log包 demo12345678910111213141516171819202122package mainimport \"log\"func init() &#123; // 设置log前缀 log.SetPrefix(\"TRACE: \") // 设置日志内容：日期、时间、文件 log.SetFlags(log.Ldate | log.Ltime |log.Llongfile)&#125;func main() &#123; // 打印标准日志 log.Println(\"message\") // 使用格式化输出日志 log.Printf(\"the result is :%s\", \"log\") // 致命错误,直接退出程序 log.Fatal(\"fatal message\")&#125; 自定义Logger指定目录存储日志1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package mainimport ( \"io\" \"log\" \"os\")var ( LogComponent *Logger)// Loggertype Logger struct &#123; // logPath 日志存储目录 logPath string // info 记录信息 info *log.Logger // error 记录错误 error *log.Logger // 其他如debug,trace,warning如上&#125;func (l *Logger) Info(message string) &#123; l.info.Println(message)&#125;func (l *Logger) Error(message string) &#123; l.error.Println(message)&#125;func getFile(filePath string) *os.File &#123; file, err := os.OpenFile(filePath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666) if err != nil &#123; log.Fatalf(\"Failed to open %s:%v\\n\", filePath, err) &#125; return file&#125;// NewLogger func NewLogger(logPath string) *Logger &#123; logger := &amp;Logger&#123;logPath:logPath&#125; logger.info = log.New(io.MultiWriter(getFile(logPath + \"info.log\"), os.Stderr), \"INFO: \", log.Ldate|log.Ltime|log.Llongfile) logger.error = log.New(io.MultiWriter(getFile(logPath+\"error.log\"), os.Stderr), \"ERROR: \", log.Ldate|log.Ltime|log.Llongfile) return logger&#125;func init() &#123; // 将日志放在log目录下，用绝对路径会更好点 LogComponent = NewLogger(\"./log/\")&#125;func main() &#123; LogComponent.Info(\"Special Information\") LogComponent.Error(\"Something has failed\")&#125;","text":"本文介绍在golang中的日志使用方式。 官方自带Log包 demo12345678910111213141516171819202122package mainimport \"log\"func init() &#123; // 设置log前缀 log.SetPrefix(\"TRACE: \") // 设置日志内容：日期、时间、文件 log.SetFlags(log.Ldate | log.Ltime |log.Llongfile)&#125;func main() &#123; // 打印标准日志 log.Println(\"message\") // 使用格式化输出日志 log.Printf(\"the result is :%s\", \"log\") // 致命错误,直接退出程序 log.Fatal(\"fatal message\")&#125; 自定义Logger指定目录存储日志1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package mainimport ( \"io\" \"log\" \"os\")var ( LogComponent *Logger)// Loggertype Logger struct &#123; // logPath 日志存储目录 logPath string // info 记录信息 info *log.Logger // error 记录错误 error *log.Logger // 其他如debug,trace,warning如上&#125;func (l *Logger) Info(message string) &#123; l.info.Println(message)&#125;func (l *Logger) Error(message string) &#123; l.error.Println(message)&#125;func getFile(filePath string) *os.File &#123; file, err := os.OpenFile(filePath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666) if err != nil &#123; log.Fatalf(\"Failed to open %s:%v\\n\", filePath, err) &#125; return file&#125;// NewLogger func NewLogger(logPath string) *Logger &#123; logger := &amp;Logger&#123;logPath:logPath&#125; logger.info = log.New(io.MultiWriter(getFile(logPath + \"info.log\"), os.Stderr), \"INFO: \", log.Ldate|log.Ltime|log.Llongfile) logger.error = log.New(io.MultiWriter(getFile(logPath+\"error.log\"), os.Stderr), \"ERROR: \", log.Ldate|log.Ltime|log.Llongfile) return logger&#125;func init() &#123; // 将日志放在log目录下，用绝对路径会更好点 LogComponent = NewLogger(\"./log/\")&#125;func main() &#123; LogComponent.Info(\"Special Information\") LogComponent.Error(\"Something has failed\")&#125; 使用logrus 安装1go get github.com/sirupsen/logrus 示例：1234567891011121314151617181920212223242526272829303132333435363738func main() &#123; // 实例化,实际项目中一般用全局变量来初始化一个日志管理器 logger := logrus.New() // 设置日志内容为json格式 logger.SetFormatter(&amp;logrus.JSONFormatter&#123; TimestampFormat: \"2006-01-02 15:04:05\", // 时间格式 DisableTimestamp: false, //是否禁用日期 DisableHTMLEscape: false, // 是否禁用html转义 DataKey: \"\" , FieldMap: logrus.FieldMap&#123; logrus.FieldKeyMsg : \"content\", // 修改\"msg\"字段名称为\"content\" &#125;, CallerPrettyfier: nil, PrettyPrint: false, // 是否需要格式化 &#125;) // 设置记录日志的最高等级，比如这里设置的info等级，那么只有比info低级的 Warn(), Error(), Fatal()以及自身Info()能够打印 logger.Level = logrus.InfoLevel // 指定日志的输出为文件，默认是os.Stdout f, err := os.OpenFile(\"logrus.log\", os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666) if err != nil &#123; log.Fatal(\"Failed to open:\", err.Error()) &#125; logger.Out = f logger.Info(\"this is info level\") logger.Debug(\"this is debug level\") logger.Warning(\"this is waring level\") logger.Error(\"this is error level\") // 日志+致命错误，程序直接退出 //logger.Fatal(\"this is fatal level\") // 在日志内容里增加一个字段title,它的值为user // 输出：&#123;\"content\":\"this is from user service log\",\"level\":\"info\",\"time\":\"2020-04-02 14:01:29\",\"title\":\"user\"&#125; logger.WithField(\"title\",\"user\").Info(\"this is from user service log\")&#125; uber的zap号称超高性能的日志库 安装 1go get -u go.uber.org/zap demo 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657func main() &#123; cfg := zap.Config&#123; // Level 最小启用的日志等级,可以通过cfg.Level.SetLevel()动态调整 Level: zap.NewAtomicLevelAt(zap.DebugLevel), // Development 当开启时，使用DPanic()，会直接panic,调试时极其方便 Development: false, // 格式设为json Encoding: \"json\", EncoderConfig: zapcore.EncoderConfig&#123; TimeKey: \"time\", //时间的key LevelKey: \"level\", // 日志等级的key NameKey: \"logger\", CallerKey: \"caller\", MessageKey: \"msg\", StacktraceKey: \"trace\", LineEnding: zapcore.DefaultLineEnding, EncodeLevel: zapcore.LowercaseLevelEncoder, EncodeDuration: zapcore.SecondsDurationEncoder, EncodeCaller: zapcore.ShortCallerEncoder, // 设定时间格式 EncodeTime: func(t time.Time, encoder zapcore.PrimitiveArrayEncoder) &#123; encoder.AppendString(fmt.Sprintf(\"%d%02d%02d_%02d%02d%02d\", t.Year(), t.Month(), t.Day(), t.Hour(), t.Minute(), t.Second())) &#125;, &#125;, // 日志输出目录 OutputPaths: []string&#123;\"/tmp/zap.log\"&#125;, // 将系统内的error记录到文件的地址 ErrorOutputPaths: []string&#123;\"/tmp/zap.log\"&#125;, // 加入一些初始的字段数据，比如项目名 InitialFields: map[string]interface&#123;&#125;&#123; \"system_name\": \"user\", &#125;, &#125; logger, err := cfg.Build() if err != nil &#123; log.Fatal(err.Error()) &#125; defer logger.Sync() logger.Info(\"info\", zap.Field&#123; Key: \"hello\", String: \"world\", Type: zapcore.StringType, &#125;) logger.Error(\"error\", zap.Field&#123; Key: \"hello\", String: \"world\", Type: zapcore.StringType, &#125;) logger.DPanic(\"panic\", zap.Field&#123; Key: \"hello\", String: \"world\", Type: zapcore.StringType, &#125;)&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化08-RPC通信","slug":"golang-rpc","date":"2020-04-01T06:47:59.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/01/golang-rpc/","link":"","permalink":"https://hongker.github.io/2020/04/01/golang-rpc/","excerpt":"本文介绍go里的rpc开发的知识点与相关使用场景。 什么是RPC RPC（Remote Procedure Call）远程过程调用，简单的理解是一个节点请求另一个节点提供的服务。 RPC vs REST RPC主要是基于TCP/IP协议的，而REST服务主要是基于HTTP协议的 REST通常以业务为导向，将业务对象上执行的操作映射到HTTP动词，格式非常简单。 REST也存在一些弊端，比如只支持请求/响应这种单一的通信方式，对象和字符串之间的序列化操作也会影响消息传递速度。在单个请求获取多个资源时存在着挑战，而且有时候很难将所有的动作都映射到HTTP动词。比如注册、授权等等。 由于HTTP在应用层中完成，整个通信的代价较高，远程过程调用中直接基于TCP进行远程调用，数据传输在传输层TCP层完成，更适合对效率要求比较高的场景，RPC主要依赖于客户端和服务端之间建立Socket链接进行，底层实现比REST更复杂。 主流的RPC框架主要用的就是GRPC,Thrift,Dubbo这三个，下面分别介绍下使用方式。 GRPCGRPC是Google最近公布的开源软件，基于最新的HTTP2.0协议，并支持常见的众多编程语言(Golang,C++,Java,Php,Python等等)。 安装建议先配置go module代理。否则不开VPN下载速度可能会很慢，也许直接下载失败。 123456// 安装protobuf插件go get -u github.com/golang/protobuf/protoc-gen-go// 再去下载protoc,地址:https://github.com/golang/protobuf/releasesunzip protoc-x.x.x-linux-x86_64.zip -d /usr/local/// 查看版本protoc --version 示例1 校验用户目录结构如下： 1234567.├── client # 客户端│ └── main.go├── proto│ └── user_auth.proto└── server # 服务端 └── main.go","text":"本文介绍go里的rpc开发的知识点与相关使用场景。 什么是RPC RPC（Remote Procedure Call）远程过程调用，简单的理解是一个节点请求另一个节点提供的服务。 RPC vs REST RPC主要是基于TCP/IP协议的，而REST服务主要是基于HTTP协议的 REST通常以业务为导向，将业务对象上执行的操作映射到HTTP动词，格式非常简单。 REST也存在一些弊端，比如只支持请求/响应这种单一的通信方式，对象和字符串之间的序列化操作也会影响消息传递速度。在单个请求获取多个资源时存在着挑战，而且有时候很难将所有的动作都映射到HTTP动词。比如注册、授权等等。 由于HTTP在应用层中完成，整个通信的代价较高，远程过程调用中直接基于TCP进行远程调用，数据传输在传输层TCP层完成，更适合对效率要求比较高的场景，RPC主要依赖于客户端和服务端之间建立Socket链接进行，底层实现比REST更复杂。 主流的RPC框架主要用的就是GRPC,Thrift,Dubbo这三个，下面分别介绍下使用方式。 GRPCGRPC是Google最近公布的开源软件，基于最新的HTTP2.0协议，并支持常见的众多编程语言(Golang,C++,Java,Php,Python等等)。 安装建议先配置go module代理。否则不开VPN下载速度可能会很慢，也许直接下载失败。 123456// 安装protobuf插件go get -u github.com/golang/protobuf/protoc-gen-go// 再去下载protoc,地址:https://github.com/golang/protobuf/releasesunzip protoc-x.x.x-linux-x86_64.zip -d /usr/local/// 查看版本protoc --version 示例1 校验用户目录结构如下： 1234567.├── client # 客户端│ └── main.go├── proto│ └── user_auth.proto└── server # 服务端 └── main.go 首先需要定义user_auth.proto文件：123456789101112131415161718192021222324syntax=&quot;proto3&quot;;package proto;// User 定义User服务service User &#123; // 定义用户授权方法 rpc Auth(AuthRequest) returns (AuthResponse) &#123;&#125;&#125;// AuthRequest 授权请求message AuthRequest &#123; // username string username = 1; // password string password = 2;&#125;// AuthResponse 授权响应message AuthResponse &#123; // message 提示 string message = 1; // token 授权成功后返回的令牌 string token = 2;&#125; 通过protoc生成go的编译文件123cd protoprotoc user_auth.proto --go_out=plugins=grpc:.// 执行成功后就能看到新生成的user_auth.pb.go,如果是其他语言，可以基于proto文件生成对应语言的代码。 服务端server/main.go:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import ( \"context\" \"fmt\" \"google.golang.org/grpc\" \"google.golang.org/grpc/codes\" \"google.golang.org/grpc/status\" \"log\" \"net\" pb \"test/grpc/proto\")// UserServertype UserServer struct &#123; pb.UnimplementedUserServer&#125;func (u *UserServer) Auth(ctx context.Context, request *pb.AuthRequest) (*pb.AuthResponse, error) &#123; resp := new(pb.AuthResponse) // 模拟从数据库里获取到数据后的校验 if request.GetUsername() != \"test\" &#123; // 用户不存在时返回NotFound return nil, status.Errorf(codes.NotFound, \"the user:%s not found\", request.Username) &#125; if request.GetPassword() != \"123456\" &#123; // 密码错误时返回Unauthenticated return nil, status.Error(codes.Unauthenticated, \"password is incorrect\") &#125; resp.Message = \"success\" // 成功返回令牌 resp.Token = \"userTokenFromDB\" return resp, nil&#125;func main() &#123; listen, err := net.Listen(\"tcp\",\":8090\") if err != nil &#123; log.Fatalln(err.Error()) &#125; server := grpc.NewServer() pb.RegisterUserServer(server, &amp;UserServer&#123;&#125;) fmt.Println(\"grpc server is running..\") if err := server.Serve(listen); err != nil &#123; log.Fatalln(err.Error()) &#125;&#125; 客户端client/main.go：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( \"context\" \"fmt\" \"google.golang.org/grpc\" \"google.golang.org/grpc/codes\" \"google.golang.org/grpc/status\" \"log\" pb \"test/grpc/proto\")func main() &#123; conn , err := grpc.Dial(\"127.0.0.1:8090\", grpc.WithInsecure()) if err != nil &#123; log.Fatalln(err) &#125; defer conn.Close() // new grpc client c := pb.NewUserClient(conn) // 使用超时Context控制请求，如果超过1s，则自动断开 ctx, cancel := context.WithTimeout(context.Background(), 1e9) defer cancel() // 调用Auth方法 resp, err := c.Auth(ctx, &amp;pb.AuthRequest&#123; Username: \"test\", // 可自行更改触发不同的错误 Password: \"123456\", // 可自行更改触发不同的错误 &#125;) if err != nil &#123; // 根据不同的错误码，执行相应的逻辑 if e, ok := status.FromError(err); ok &#123; switch e.Code() &#123; case codes.NotFound: fmt.Println(e.Message()) case codes.Unauthenticated: fmt.Println(e.Message()) default: fmt.Println(e.Message()) &#125; &#125; log.Fatalf(\"login failed: %v\", err) &#125; log.Printf(\"login success: %s\", resp.GetToken())&#125; 运行： 12345678910// terminal1go run server/main.go// terminal2go run client/main.go// 正常，输出:2020/04/01 18:20:13 login success: userTokenFromDB// 改变password: &quot;123&quot;,输出：login failed: rpc error: code = Unauthenticated desc = password is incorrect 备注说明一直纠结如参数错误，数据不存在等业务状态码应该使用error的code存储，还是在每个response里定义一个公共的code字段，在查阅相关资料：1https://www.bookstack.cn/read/API-design-guide/API-design-guide-07-%E9%94%99%E8%AF%AF.md 开发人员不太可能编写大量处理逻辑错误的代码，所以单独的API应该避免定义额外的错误代码。 作为参考，每个API调用平均处理3个错误就意味着大多数应用程序只是处理错误了，这对开发者来说体验不够友好。 如果选择在Response里定义code字段，调用方也许需要判断两次code。故我推荐使用GRPC里error定义好的code存储即可。 Thrift thrift 最初是 facebook 开发使用的 rpc 通信框架，后来贡献给了 apache 基金会，出来得比较早，几乎支持所有的后端语言，使用非常广泛，是不可不知的一个网络框架 下载go库 1go get git.apache.org/thrift.git/lib/go/thrift/... 编译安装前往http://thrift.apache.org/download下载源文件，我下载的版本是https://mirror.bit.edu.cn/apache/thrift/0.13.0/thrift-0.13.0.tar.gz 123456// 解压tar -zxvf thrift-0.13.0.tar.gzcd thrift-0.13.0/// 编译./configure --prefix=/usrmake -j8 怎么都编译失败。。这特么。。先暂停。。","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化07-sync包","slug":"golang-sync","date":"2020-04-01T01:38:43.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/04/01/golang-sync/","link":"","permalink":"https://hongker.github.io/2020/04/01/golang-sync/","excerpt":"本文介绍golang的sync包里的知识点与使用方式。 什么是Sync包 Golang sync包提供了基础的异步操作方法，包括互斥锁Mutex，执行一次Once和并发等待组WaitGroup主要的功能如下:1234567sync.Mutex: 互斥锁sync.RWMutex: 读写锁WaitGroup: 并发等待管理Once：执行一次Cond：信号量Pool：临时对象池Map：自带锁的map sync.Mutex&amp;sync.RWMutex sync.Mutex称为互斥锁，常用在并发编程里面。互斥锁需要保证的是同一个时间段内不能有多个并发协程同时访问某一个资源(临界区) sync.RWMutex目的是为了能够支持多个并发协程同时读取某一个资源，但只有一个并发协程能够更新资源。也就是说读和写是互斥的，写和写也是互斥的，读和读是不互斥的。这两个锁的用法在之前已介绍过，故不再重复介绍。需要的请查看：Golang代码优化04-锁 sync.WaitGroupsync.WaitGroup指的是等待组，在Golang并发编程里面非常常见，指的是等待一组工作完成后，再进行下一组工作。 123func (wg *WaitGroup) Add(delta int) Add添加n个并发协程func (wg *WaitGroup) Done() Done完成一个并发协程func (wg *WaitGroup) Wait() Wait等待其它并发协程结束 简单的理解就是Boss监督Worker工作，等待所有的Worker完成后才收工！12345678910111213141516func main() &#123; n := 100 wg := sync.WaitGroup&#123;&#125; // 监控n个协程 wg.Add(n) for i := 0; i &lt; n; i++ &#123; go func(i int) &#123; fmt.Println(i) // 标识已完成工作 wg.Done() &#125;(i) &#125; // 阻塞等待所有goroutine完成工作 wg.Wait() fmt.Println(\"All done!\")&#125; sync.Once","text":"本文介绍golang的sync包里的知识点与使用方式。 什么是Sync包 Golang sync包提供了基础的异步操作方法，包括互斥锁Mutex，执行一次Once和并发等待组WaitGroup主要的功能如下:1234567sync.Mutex: 互斥锁sync.RWMutex: 读写锁WaitGroup: 并发等待管理Once：执行一次Cond：信号量Pool：临时对象池Map：自带锁的map sync.Mutex&amp;sync.RWMutex sync.Mutex称为互斥锁，常用在并发编程里面。互斥锁需要保证的是同一个时间段内不能有多个并发协程同时访问某一个资源(临界区) sync.RWMutex目的是为了能够支持多个并发协程同时读取某一个资源，但只有一个并发协程能够更新资源。也就是说读和写是互斥的，写和写也是互斥的，读和读是不互斥的。这两个锁的用法在之前已介绍过，故不再重复介绍。需要的请查看：Golang代码优化04-锁 sync.WaitGroupsync.WaitGroup指的是等待组，在Golang并发编程里面非常常见，指的是等待一组工作完成后，再进行下一组工作。 123func (wg *WaitGroup) Add(delta int) Add添加n个并发协程func (wg *WaitGroup) Done() Done完成一个并发协程func (wg *WaitGroup) Wait() Wait等待其它并发协程结束 简单的理解就是Boss监督Worker工作，等待所有的Worker完成后才收工！12345678910111213141516func main() &#123; n := 100 wg := sync.WaitGroup&#123;&#125; // 监控n个协程 wg.Add(n) for i := 0; i &lt; n; i++ &#123; go func(i int) &#123; fmt.Println(i) // 标识已完成工作 wg.Done() &#125;(i) &#125; // 阻塞等待所有goroutine完成工作 wg.Wait() fmt.Println(\"All done!\")&#125; sync.Once sync.Once指的是只执行一次的对象实现，常用来控制某些函数只能被调用一次。 插播一条故事，关于sync.Once，在03-31与EasySwoole的作者有过一次讨论他：说说sync.Once的作用我：常用于单例模式他：一看你就是Go的初学者。我：恩，大佬说说看，我好学学一波他：本质在于、、、、go是多线程协程，而单例模式的时候，如果用锁来解决单例问题，那么效率是非常差的。这个可以参考java多线程下的同步锁问题，为此go提供了一个sync.Once机制，不过实际上，go的本质实现，也是锁。嗯，反正就是，你没回到到问题的本质。我：学习了，受益颇多。 emmm…于是乎抱着听了大佬的一波解释，因而有点怀疑的想法，下来仔细研究了sync.Once的源码，代码其实很简单，和大佬说的其实差不多。但是实际不是那么简单，写go的人真的牛逼(实在是666)。下面看看源码： 12345678910111213141516171819202122232425262728293031type Once struct &#123; // done 标识符，这里放在第一位也是有讲究的 // 一个重要的概念 hot path ，即 Do 方法的调用会是高频的，而每次调用访问 done，done位于结构体的第一个字段，可以通过结构体指针直接进行访问 // 访问其他的字段需要通过偏移量计算就慢了 done uint32 // m 互斥锁 m Mutex&#125;// Do func (o *Once) Do(f func()) &#123; // 函数atomic.LoadInt32接受一个*int32类型的指针值，并会返回该指针值指向的那个值 // 在这里读取o.done的值的同时，当前计算机中的任何CPU都不会进行其它的针对此值的读或写操作。这样的约束是受到底层硬件的支持的 // 刚开始我理解的主要作用是用原子操作可以提高性能，和大佬说的一致。但实际并非如此。普通赋值o.done = 1也可以实现相同的作用。 // 如果是普通赋值，当协程A刚执行完原子赋值操作，协程B阻塞等待加锁的时候，协程C在这里的判断为true,因为协程间对同一变量不存在同步手段，Go并不能保证协程A的赋值操作能被C读到，所以有可能在协程C里会执行o.doSlow(f),与只执行一次想违背。而使用原子操作读写，刚好可以避免这一个问题。 if atomic.LoadUint32(&amp;o.done) == 0 &#123; // Outlined slow-path to allow inlining of the fast-path. o.doSlow(f) &#125;&#125;// doSlow func (o *Once) doSlow(f func()) &#123; // 加锁，保证协程安全 o.m.Lock() defer o.m.Unlock() // 因为使用了 Mutex 进行了锁操作，o.done == 0 处于锁操作的临界区中，所以可以直接进行比较 if o.done == 0 &#123; // 原子store函数执行次数1 defer atomic.StoreUint32(&amp;o.done, 1) f() &#125;&#125; 总的来说，sync.Once的使用场景例如单例模式、系统初始化。 因为这个插曲，深入研究了sync.Once的原理，受益匪浅，还是感谢大佬的启发。虽然大佬说的有道理，但我依然坚持我的观点常用于单例模式。如果有一天谁能说服我不能这么用，我也会听听理由，自己思考一番。 sync.Condsync.Cond指的是同步条件变量，一般需要与互斥锁组合使用，本质上是一些正在等待某个条件的协程的同步机制。主要函数如下：123456// Wait 等待通知func (c *Cond) Wait()// Signal 单播通知func (c *Cond) Signal()// Broadcast 广播通知func (c *Cond) Broadcast() 示例1234567891011121314151617181920212223func main() &#123; cond := sync.NewCond(&amp;sync.Mutex&#123;&#125;) for i := 0; i &lt; 3; i++ &#123; go func(i int) &#123; cond.L.Lock() // 获取锁 fmt.Println(\"上班，摸鱼...\") cond.Wait() //等待通知 暂时阻塞 fmt.Println(\"等待下班...\") cond.L.Unlock() //释放锁 fmt.Println(\"下班，Worker:\", i) &#125;(i) &#125; time.Sleep(1e9) cond.Signal() // 让leader先走 time.Sleep(1e9) cond.Broadcast() // 全部下班 time.Sleep(2e9) // 等待协程执行完成&#125; sync.Pool通常用golang来构建高并发场景下的应用，但是由于golang内建的GC机制会影响应用的性能，为了减少GC，golang提供了对象重用的机制，也就是sync.Pool对象池 注：千万不能把它当成内存池使用。12345678910111213141516func main() &#123; var bufferPool = sync.Pool&#123; New: func() interface&#123;&#125; &#123; return new(bytes.Buffer) &#125;, &#125; for i:=0;i&lt;10;i++ &#123; // 获取buffer buffer := bufferPool.Get().(*bytes.Buffer) buffer.Reset() bufferPool.Put(buffer) buffer.Write([]byte(\"hello\" + strconv.Itoa(i)) fmt.Println( buffer.String()) &#125;&#125; 接收并读取http的响应内容实际代码之前已描述过，请查看:Golang代码优化03-Http响应处理 sync.Map貌似不建议使用了。暂不介绍","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Goland代码优化06-上下文Context","slug":"golang-context","date":"2020-03-31T11:50:27.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/03/31/golang-context/","link":"","permalink":"https://hongker.github.io/2020/03/31/golang-context/","excerpt":"本文介绍关于Context的一些要点。 什么是Context Context，上下文，golang协程的相关环境快照，其中包含函数调用以及涉及的相关的变量值。通过Context在协程之间进行数据传递，相对于维护全局变量要简单。但也有人说它想virus,到处传播，褒贬不一。所以不同的场景下，还得程序猿自己决定是否适用。 结构Context是一个树形结构。首先需要创建的是根节点。 顶层Context: Background 1234func main() &#123; // 声明一个空的Context，它将作为所有由此继承Context的根节点 ctx := context.Background()&#125; 子孙节点 WithCancel/WithDeadline/WithTimeout/WithValue 123456789101112// 带cancel返回值的Context，一旦cancel被调用，即取消该创建的contextfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc) // 带有效期cancel返回值的Context，即必须到达指定时间点调用的cancel方法才会被执行func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) // 带超时时间cancel返回值的Context，类似Deadline，前者是时间点，后者为时间间隔// 相当于WithDeadline(parent, time.Now().Add(timeout)).func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)// 带key-val的Contextfunc WithValue(parent Context, key string, val interface) Context","text":"本文介绍关于Context的一些要点。 什么是Context Context，上下文，golang协程的相关环境快照，其中包含函数调用以及涉及的相关的变量值。通过Context在协程之间进行数据传递，相对于维护全局变量要简单。但也有人说它想virus,到处传播，褒贬不一。所以不同的场景下，还得程序猿自己决定是否适用。 结构Context是一个树形结构。首先需要创建的是根节点。 顶层Context: Background 1234func main() &#123; // 声明一个空的Context，它将作为所有由此继承Context的根节点 ctx := context.Background()&#125; 子孙节点 WithCancel/WithDeadline/WithTimeout/WithValue 123456789101112// 带cancel返回值的Context，一旦cancel被调用，即取消该创建的contextfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc) // 带有效期cancel返回值的Context，即必须到达指定时间点调用的cancel方法才会被执行func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) // 带超时时间cancel返回值的Context，类似Deadline，前者是时间点，后者为时间间隔// 相当于WithDeadline(parent, time.Now().Add(timeout)).func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)// 带key-val的Contextfunc WithValue(parent Context, key string, val interface) Context 示例 控制协程同步退出 123456789101112131415161718func main() &#123; ctx, cancel := context.WithCancel(context.Background()) go func() &#123; for &#123; time.Sleep(1 * time.Second) select &#123; case &lt;-ctx.Done(): fmt.Println(\"done\") return default: fmt.Println(\"working...\") &#125; &#125; &#125;() time.Sleep(1e9 * 3) // 模拟业务逻辑执行 cancel() time.Sleep(1e9 * 2) // wait goroutine finished&#125; 全局TraceID 12345678910111213141516171819import \"github.com/satori/go.uuid\"func main() &#123; // set traceId in context ctx := context.WithValue(context.Background(), \"traceId\", uuid.NewV4().String()) // current login user ctx = context.WithValue(ctx, \"username\", \"test\") var wg sync.WaitGroup wg.Add(1) go func() &#123; defer wg.Done() traceId := ctx.Value(\"traceId\").(string) username := ctx.Value(\"username\").(string) fmt.Printf(\"traceId: %s, current user: %s\\n\", traceId, username) &#125;() // wait goroutine execute finished wg.Wait()&#125; 超时处理 12345678910111213141516171819202122func main() &#123; // 定义一个3秒自动超时的context ctx, cancel := context.WithTimeout(context.Background(), 1e9 *3) // 使用defer的特性，达到如果提前执行完成，自动调用cancel方法释放资源 defer cancel() go func() &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Printf(\"cancel:%s\\n\", ctx.Err()) return default: &#123; fmt.Println(\"do something\") time.Sleep(1e9 * 1) // 模拟业务代码执行时间 &#125; &#125; &#125; &#125;() time.Sleep(1e9 * 5)&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化05-锁","slug":"golang-lock","date":"2020-03-31T05:52:03.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/03/31/golang-lock/","link":"","permalink":"https://hongker.github.io/2020/03/31/golang-lock/","excerpt":"介绍在项目开发中，经常用到到保证数据安全的锁的使用。 sync.Mutex 互斥锁 demo1234567891011121314151617181920212223type Item struct &#123; mu sync.Mutex number int&#125;// NewItemfunc NewItem() *Item &#123; return &amp;Item&#123; mu: sync.Mutex&#123;&#125;, number: 0, &#125;&#125;// SetNumberfunc (item *Item) SetNumber(num int) &#123; item.mu.Lock() defer item.mu.Unlock() item.number = num&#125;// Numberfunc (item *Item) Number() int &#123; item.mu.Lock() defer item.mu.Unlock() return item.number&#125; 通过mu互斥锁保证写入数据和读取数据都是线程安全的。如果不用锁，在多个协程里执行SetNumber()容易导致获取的数据和预期不一致 RWMutex 读写锁在读多写少的场景中，可以优先使用读写锁RWMutex。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package mainimport ( \"fmt\" \"sync\" \"time\")func main() &#123; var wg sync.WaitGroup u := NewUser() // 通过协程并发读取，这里使用读锁，比互斥锁效率更高 for i := 0; i &lt; 5; i++ &#123; wg.Add(1) go func() &#123; defer wg.Done() fmt.Println(\"Get Age:\", u.GetAge(),time.Now().Second()) &#125;() &#125; // 激活一个申请写锁的goroutine go func() &#123; wg.Add(1) defer wg.Done() u.ChangeAge(10) &#125;() // 阻塞，直到所有wg.Done wg.Wait()&#125;// NewUser return user instancefunc NewUser() *U &#123; return &amp;U&#123; rwm: sync.RWMutex&#123;&#125;, Age: 0, &#125;&#125;// U usertype U struct &#123; rwm sync.RWMutex Age int&#125;// GetAgefunc (u *U) GetAge() int &#123; u.rwm.RLock() defer u.rwm.RUnlock() return u.Age&#125;// ChangeAgefunc (u *U) ChangeAge(age int) &#123; u.rwm.Lock() defer u.rwm.Unlock() u.Age = age&#125;","text":"介绍在项目开发中，经常用到到保证数据安全的锁的使用。 sync.Mutex 互斥锁 demo1234567891011121314151617181920212223type Item struct &#123; mu sync.Mutex number int&#125;// NewItemfunc NewItem() *Item &#123; return &amp;Item&#123; mu: sync.Mutex&#123;&#125;, number: 0, &#125;&#125;// SetNumberfunc (item *Item) SetNumber(num int) &#123; item.mu.Lock() defer item.mu.Unlock() item.number = num&#125;// Numberfunc (item *Item) Number() int &#123; item.mu.Lock() defer item.mu.Unlock() return item.number&#125; 通过mu互斥锁保证写入数据和读取数据都是线程安全的。如果不用锁，在多个协程里执行SetNumber()容易导致获取的数据和预期不一致 RWMutex 读写锁在读多写少的场景中，可以优先使用读写锁RWMutex。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package mainimport ( \"fmt\" \"sync\" \"time\")func main() &#123; var wg sync.WaitGroup u := NewUser() // 通过协程并发读取，这里使用读锁，比互斥锁效率更高 for i := 0; i &lt; 5; i++ &#123; wg.Add(1) go func() &#123; defer wg.Done() fmt.Println(\"Get Age:\", u.GetAge(),time.Now().Second()) &#125;() &#125; // 激活一个申请写锁的goroutine go func() &#123; wg.Add(1) defer wg.Done() u.ChangeAge(10) &#125;() // 阻塞，直到所有wg.Done wg.Wait()&#125;// NewUser return user instancefunc NewUser() *U &#123; return &amp;U&#123; rwm: sync.RWMutex&#123;&#125;, Age: 0, &#125;&#125;// U usertype U struct &#123; rwm sync.RWMutex Age int&#125;// GetAgefunc (u *U) GetAge() int &#123; u.rwm.RLock() defer u.rwm.RUnlock() return u.Age&#125;// ChangeAgefunc (u *U) ChangeAge(age int) &#123; u.rwm.Lock() defer u.rwm.Unlock() u.Age = age&#125; sync.WaitGroupWaitGroup相当于协程任务的管理者，监控受管理的协程是否已执行完成。1234567891011func main() &#123; wg := sync.WaitGroup&#123;&#125; wg.Add(100) for i := 0; i &lt; 100; i++ &#123; go func(i int) &#123; fmt.Println(i) wg.Done() &#125;(i) &#125; wg.Wait()&#125; 分布式Redis锁往往在服务端都是集群模式，在需要对数据进行安全的线性操作时，需要用到分布式锁。以下就是基于Redis实现的分布式锁。123456789101112131415161718192021222324252627282930313233// RedisLock Redis锁type RedisLock struct &#123; Key string&#125;// 加锁func (lock *RedisLock) Lock(second int) error &#123; if second == 0 &#123; second = 2 &#125; res, err := app.Redis().SetNX(lock.Key, 1, time.Duration(second)*time.Second).Result() if err != nil || res == false &#123; return errors.New(\"failed to lock\") &#125; return nil&#125;// 解锁func (lock *RedisLock) Unlock() error &#123; return app.Redis().Del(lock.Key).Err()&#125;func main() &#123; lock := &amp;RedisLock&#123;Key:\"uniqueLockKey\"&#125; if err := lock.Lock(); err != nil &#123; fmt.Println(err) return &#125; defer lock.Unlock() // do something&#125; 双向锁DoubleLock在日常的项目中，时常会有类似转账的业务。当A向B转账的同时，B向A转账，如果仅仅简单的在账户的基础上加锁，A向B转账，加锁A，加锁B，此刻B向A转账，加锁B，再锁A，此刻会产生循环死锁。解决方案：解开循环锁的关键，就在于固定加锁的顺序。比如：不管A向B转账，或者是B向A转账，都先加锁A，再加锁B。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// DoubleLocktype DoubleLock struct &#123; FromLock RedisLock ToLock RedisLock&#125;// Lockfunc (lock *DoubleLock) Lock(second int) error &#123; hashCodeFrom := HashCode(lock.FromLock.Key) hashCodeTo := HashCode(lock.ToLock.Key) // choose little one if hashCodeFrom &lt; hashCodeTo &#123; if err := lock.FromLock.Lock(second); err != nil &#123; return err &#125; return lock.ToLock.Lock(second) &#125; else if hashCodeFrom &gt; hashCodeTo &#123; if err := lock.ToLock.Lock(second); err != nil &#123; return err &#125; return lock.FromLock.Lock(second) &#125; return errors.New(\"key is same\")&#125;// Unlockfunc (lock *DoubleLock) Unlock() error &#123; if err := lock.FromLock.Unlock(); err != nil &#123; return err &#125; return lock.ToLock.Unlock()&#125;// HashCode func HashCode(s string) int &#123; v := int(crc32.ChecksumIEEE([]byte(s))) if v &gt;= 0 &#123; return v &#125; if -v &gt;= 0 &#123; return -v &#125; // v == MinInt return 0&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化04-Http响应处理","slug":"http-response","date":"2020-03-31T04:28:14.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2020/03/31/http-response/","link":"","permalink":"https://hongker.github.io/2020/03/31/http-response/","excerpt":"介绍读取http的response内容。 读取方式 1.使用ioutil.ReadAll()读取response12345678910111213141516171819func main () &#123; // send get request resp, err := http.Get(\"https://api.ipify.org/?format=json\") if err != nil &#123; fmt.Println(err) return &#125; // defer must execute after check error,otherwise will panic when resp is nil defer resp.Body.Close() // read body body, err := ioutil.ReadAll(resp.Body) if err != nil &#123; fmt.Println(err) return &#125; fmt.Println(string(body))&#125; 但是ioutil.ReadAll()方法有弊端,有时候却会导致一些性能问题。比如http大量请求时轻则导致内存浪费严重，重则导致内存泄漏影响业务。 2.使用buffer读取1234567891011121314151617func main () &#123; resp, err := http.Get(\"https://api.ipify.org/?format=json\") if err != nil &#123; fmt.Println(err) return &#125; defer resp.Body.Close() // new buffer buffer := bytes.NewBuffer(make([]byte, 4056)) if _, err := io.Copy(buffer, resp.Body);err != nil &#123; fmt.Println(err) return &#125; fmt.Println(buffer.String())&#125;","text":"介绍读取http的response内容。 读取方式 1.使用ioutil.ReadAll()读取response12345678910111213141516171819func main () &#123; // send get request resp, err := http.Get(\"https://api.ipify.org/?format=json\") if err != nil &#123; fmt.Println(err) return &#125; // defer must execute after check error,otherwise will panic when resp is nil defer resp.Body.Close() // read body body, err := ioutil.ReadAll(resp.Body) if err != nil &#123; fmt.Println(err) return &#125; fmt.Println(string(body))&#125; 但是ioutil.ReadAll()方法有弊端,有时候却会导致一些性能问题。比如http大量请求时轻则导致内存浪费严重，重则导致内存泄漏影响业务。 2.使用buffer读取1234567891011121314151617func main () &#123; resp, err := http.Get(\"https://api.ipify.org/?format=json\") if err != nil &#123; fmt.Println(err) return &#125; defer resp.Body.Close() // new buffer buffer := bytes.NewBuffer(make([]byte, 4056)) if _, err := io.Copy(buffer, resp.Body);err != nil &#123; fmt.Println(err) return &#125; fmt.Println(buffer.String())&#125; 3.BufferPool当需要处理较多的httpResponse时，可以选择先初始化一个Buffer池，提升效率。12345678910111213141516171819202122232425262728293031323334353637383940414243// BufferPool use sync.pool to build a buffer pooltype BufferPool struct &#123; pool sync.Pool&#125;// NewBufferPool return BufferPool instance by buffer lengthfunc NewBufferPool(bufLen int) *BufferPool &#123; return &amp;BufferPool&#123;pool:sync.Pool&#123;New: func() interface&#123;&#125; &#123; return bytes.NewBuffer(make([]byte, bufLen)) &#125;&#125;&#125;&#125;// StringifyResponse return response body as stringfunc (bp *BufferPool) StringifyResponse(response *http.Response) (string, error) &#123; if response == nil &#123; return \"\", fmt.Errorf(\"response is empty\") &#125; // close response defer func() &#123; _ = response.Body.Close() &#125;() if response.StatusCode != http.StatusOK &#123; return \"\", fmt.Errorf(\"response status code is:%d\", response.StatusCode) &#125; buffer := bp.pool.Get().(*bytes.Buffer) // get buffer from pool buffer.Reset() // reset buffer defer func() &#123; if buffer != nil &#123; bp.pool.Put(buffer) // return back buffer = nil // close &#125; &#125;() _, err := io.Copy(buffer, response.Body) if err != nil &#123; return \"\", fmt.Errorf(\"failed to read respone:%s\", err.Error()) &#125; return buffer.String(), nil&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化03-协程与管道","slug":"channel","date":"2020-03-30T08:38:50.000Z","updated":"2021-04-22T22:57:00.345Z","comments":true,"path":"2020/03/30/channel/","link":"","permalink":"https://hongker.github.io/2020/03/30/channel/","excerpt":"介绍一些常规的用法 channel的状态 channel:未初始化时为nil active:正常的channel,可读可写 closed:调用了close()后的状态 channel的操作 读 &lt;-channel 写 -&gt;channel 关闭 close 常用的channel使用方法 使用for..range 读取channel当需要不断从channel中读取数据时，使用for..range,当channel关闭时，for..range会自动退出 12345678910111213141516func main() &#123; ch := make(chan string) go sendData(ch) for out := range ch &#123; fmt.Println(out) &#125;&#125;func sendData(ch chan string) &#123; ch &lt;- \"Washington\" ch &lt;- \"Tripoli\" ch &lt;- \"London\" ch &lt;- \"Beijing\" ch &lt;- \"Tokyo\" defer close(ch)&#125; 使用value,ok判断channel是否关闭当直接读取channel时，如果channel已关闭，会触发panic,故需要判断channel是否关闭 1234567891011func main() &#123; ch := make(chan string) go sendData(ch) for &#123; if out, open := &lt;- ch; open &#123; fmt.Println(out) &#125;else &#123; break &#125; &#125;&#125; 使用select读取多个channelselect可以同时监控多个通道的情况，只处理未阻塞的case。当通道为nil时，对应的case永远为阻塞，无论读写。特殊关注：普通情况下，对nil的通道写操作是要panic的。 使用channel的声明控制读写权限协程对某个channel只读或只写 使用缓冲channel增强并发和异步有缓冲通道是异步的，无缓冲通道是同步的。有缓冲通道可供多个协程同时处理，在一定程度可提高并发性。","text":"介绍一些常规的用法 channel的状态 channel:未初始化时为nil active:正常的channel,可读可写 closed:调用了close()后的状态 channel的操作 读 &lt;-channel 写 -&gt;channel 关闭 close 常用的channel使用方法 使用for..range 读取channel当需要不断从channel中读取数据时，使用for..range,当channel关闭时，for..range会自动退出 12345678910111213141516func main() &#123; ch := make(chan string) go sendData(ch) for out := range ch &#123; fmt.Println(out) &#125;&#125;func sendData(ch chan string) &#123; ch &lt;- \"Washington\" ch &lt;- \"Tripoli\" ch &lt;- \"London\" ch &lt;- \"Beijing\" ch &lt;- \"Tokyo\" defer close(ch)&#125; 使用value,ok判断channel是否关闭当直接读取channel时，如果channel已关闭，会触发panic,故需要判断channel是否关闭 1234567891011func main() &#123; ch := make(chan string) go sendData(ch) for &#123; if out, open := &lt;- ch; open &#123; fmt.Println(out) &#125;else &#123; break &#125; &#125;&#125; 使用select读取多个channelselect可以同时监控多个通道的情况，只处理未阻塞的case。当通道为nil时，对应的case永远为阻塞，无论读写。特殊关注：普通情况下，对nil的通道写操作是要panic的。 使用channel的声明控制读写权限协程对某个channel只读或只写 使用缓冲channel增强并发和异步有缓冲通道是异步的，无缓冲通道是同步的。有缓冲通道可供多个协程同时处理，在一定程度可提高并发性。 为操作加上超时在实际开发中，无法预估时间的程序，为了保证程序安全，我们需要超时控制的操作。 123456789101112131415161718192021func main() &#123; fmt.Println(doWithTimeout(1e9 * 2))&#125;func doWithTimeout(timeout time.Duration) (int, error) &#123; select &#123; case res := &lt;- do(): return res, nil case &lt;-time.After(timeout): return 0, errors.New(\"timeout\") &#125;&#125;func do() &lt;- chan int &#123; outCh := make(chan int) go func() &#123; time.Sleep(1e9 * 3) // 模拟如复杂的sql查询 outCh &lt;- 1 &#125;() return outCh&#125; 使用chan struct{}作为信号channel使用channel传递信号，而不是传递数据时 123456789101112131415func main() &#123; done := make(chan struct&#123;&#125;) go func() &#123; time.Sleep(1e9 * 2) close(done) // 发送关闭信息 &#125;() for &#123; select &#123; case &lt;-done: fmt.Println(\"done\") return &#125; &#125;&#125; 读取Excel通过channel实现异步读取excel的demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package mainimport ( \"fmt\" \"github.com/tealeg/xlsx\")func main() &#123; // data.xls: // title // 1 // 2 // 3 reader := NewExcelReader(\"static/data.xlsx\", 10) // read go func() &#123; fmt.Println(reader.Read(0)) &#125;() // output for out := range reader.OutPut() &#123; // other process fmt.Println(out) &#125;&#125;// ExcelReader reader of exceltype ExcelReader struct &#123; // excel file name FileName string // data items chan map[string]string&#125;// NewExcelReader return ExcelReader with filename and chan lengthfunc NewExcelReader(filename string, chanLen int) *ExcelReader &#123; return &amp;ExcelReader&#123; FileName: filename, items: make(chan map[string]string, chanLen), &#125;&#125;// Read read excel sheetfunc (r *ExcelReader) Read(sheetNo int /* sheet number*/) error &#123; // open file xlFile, err := xlsx.OpenFile(r.FileName) if err != nil &#123; return err &#125; sheets := xlFile.Sheets[sheetNo] // set first row as map filed var fieldArr []string for idx, row := range sheets.Rows &#123; var arr []string // read data for _, cell := range row.Cells &#123; arr = append(arr, cell.String()) &#125; if arr == nil &#123; // filter empty row continue &#125; // read filed if idx == 0 &#123; fieldArr = arr continue &#125; item := make(map[string]string) for key, field := range fieldArr &#123; item[field] = arr[key] &#125; r.items &lt;- item &#125; // close channel when read finished close(r.items) return nil&#125;// OutPut return read datafunc (r *ExcelReader) OutPut() &lt;- chan map[string]string &#123; return r.items&#125; GoroutineGoroutines 是在 Golang 中执行并发任务的方式。Go线程实现模型MPG Machine,表示内核线程。 Processor,处理器，执行G的上下文环境，每个P会维护一个本地的go routine队列。 Goroutine,并发的最小逻辑单元，轻量级的线程。 一个线程使用一个处理器，一个处理器运行多个协程。 Runtime里与Goroutine相关函数 12345Goexit:退出当前执行的goroutineGosched:让出当前goroutine的执行权限，调度器安排其他等待的任务运行，并在下次某个时候从该位置回复执行。NumCPU:返回CPU核数量。NumGoroutine：返回正在执行和排队的任务总数。GOMAXPROCS：用来设置可以并行计算的CPU核数的最大值，并返回之前的值。 调度原理1.Processor的数量由GOMAXPROCS设置2.用户需要做的就是添加goroutine,即通过go开启协程。3.Goroutine的数量超过了Machine的处理能力，且有空余的Processor的话，runtime会自动创建Machine4.Machine拿到Processor后开始工作，取Goroutine的顺序：本地队列&gt;全局队列&gt;其他P的队列。如果没有Goroutine，Machine归还Processor后休眠。","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化02-全局变量","slug":"Golang代码优化02-全局变量","date":"2020-03-30T07:29:21.000Z","updated":"2021-04-22T22:57:00.345Z","comments":true,"path":"2020/03/30/Golang代码优化02-全局变量/","link":"","permalink":"https://hongker.github.io/2020/03/30/Golang代码优化02-全局变量/","excerpt":"在项目中，全局变量使用的较为普遍，如全局DB连接池、Redis连接池等。 初始化Go的全局变量，在main函数执行前初始化。1234var a = 1func main() &#123; fmt.Println(a)&#125; 数据库连接database初始化数据库连接12345678910package databasevar Instance *gorm.DB// initfunc init() &#123; db, err := gorm.Open(\"mysql\", \"user:password@/dbname?charset=utf8&amp;parseTime=True&amp;loc=Local\") if err != nil &#123; log.Fatalf(\"failed to connect database:%s\", err.Error()) &#125; Instance = db&#125; 使用123456package mainimport \"database\" // import,触发init函数func main() &#123; // ping mysql database.Instance.DB().Ping()&#125;","text":"在项目中，全局变量使用的较为普遍，如全局DB连接池、Redis连接池等。 初始化Go的全局变量，在main函数执行前初始化。1234var a = 1func main() &#123; fmt.Println(a)&#125; 数据库连接database初始化数据库连接12345678910package databasevar Instance *gorm.DB// initfunc init() &#123; db, err := gorm.Open(\"mysql\", \"user:password@/dbname?charset=utf8&amp;parseTime=True&amp;loc=Local\") if err != nil &#123; log.Fatalf(\"failed to connect database:%s\", err.Error()) &#125; Instance = db&#125; 使用123456package mainimport \"database\" // import,触发init函数func main() &#123; // ping mysql database.Instance.DB().Ping()&#125; 使用uber的dig库管理全局变量 示例1安装1go get go.uber.org/dig 123456789101112131415161718192021package appimport \"go.uber.org/dig\"var container = dig.New()func init() &#123; db, err := gorm.Open(\"mysql\", \"user:password@/dbname?charset=utf8&amp;parseTime=True&amp;loc=Local\") if err != nil &#123; log.Fatalf(\"failed to connect database:%s\", err.Error()) &#125; // register into container container.Provide(func() (*gorm.DB) &#123; return db &#125;)&#125;// DBConnection return *gorm.DBfunc DBConnection() (connection *gorm.DB) &#123; _ = container.Invoke(func(db *gorm.DB) &#123; connection = db &#125;) return&#125; 使用123456package mainimport \"app\" // import,触发init函数func main() &#123; // ping mysql app.DBConnection.DB().Ping()&#125; 示例2延迟加载12345678910111213141516171819202122232425262728293031package app// container instancevar container = dig.New()// EventManager type EventManager struct &#123; events []Event&#125;// Eventtype Event struct &#123; Name string&#125;// Register add events func (m *EventManager) Register(e Event) &#123; m.events = append(m.events, e)&#125;// GetEventManagerfunc GetEventManager() (manager *EventManager) &#123; if err := container.Invoke(func(m *EventManager) &#123; manager = m &#125;); err != nil &#123; manager = &amp;EventManager&#123;events: make([]Event)&#125; // register into container _ = Container.Provide(func() *EventManager&#123; return manager &#125;) &#125; return&#125;// usage// app.GetEventManager().Register(ev)","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"Golang代码优化01-错误信息","slug":"Golang代码优化01","date":"2020-03-30T07:04:12.000Z","updated":"2021-04-22T22:57:00.345Z","comments":true,"path":"2020/03/30/Golang代码优化01/","link":"","permalink":"https://hongker.github.io/2020/03/30/Golang代码优化01/","excerpt":"记录项目开发中Go写法的代码优化。 定制化error在项目开发中，我们不想直接暴露系统底层的错误，同时常规的error无法满足项目精细化的处理，我们经常会对error通过code进行分类。故定义如下:12345678910111213141516171819202122232425262728293031// Error type Error struct &#123; Code int `json:\"code\"` Message string `json:\"message\"`&#125;// Error stringfunc (e *Error) Error() string &#123; b, _ := json.Marshal(e) return string(b)&#125;// New return error with codefunc New( code int, message string) *Error &#123; return &amp;Error&#123; Code: code, Message: message, &#125;&#125;// Parse tries to parse a JSON string into an error. If that// fails, it will set the given string as the error detail.func Parse(errStr string) *Error &#123; e := new(Error) if err := json.Unmarshal([]byte(errStr), e); err != nil &#123; e.Code = http.StatusInternalServerError e.Message = err.Error() &#125; return e&#125; 使用1234567// newerr := New(200105001, \"something wrong\" )fmt.Println(\"err:\",err.Error())// parseerrParse := Parse(err.Error())fmt.Println(\"err code\": errParse.Code)","text":"记录项目开发中Go写法的代码优化。 定制化error在项目开发中，我们不想直接暴露系统底层的错误，同时常规的error无法满足项目精细化的处理，我们经常会对error通过code进行分类。故定义如下:12345678910111213141516171819202122232425262728293031// Error type Error struct &#123; Code int `json:\"code\"` Message string `json:\"message\"`&#125;// Error stringfunc (e *Error) Error() string &#123; b, _ := json.Marshal(e) return string(b)&#125;// New return error with codefunc New( code int, message string) *Error &#123; return &amp;Error&#123; Code: code, Message: message, &#125;&#125;// Parse tries to parse a JSON string into an error. If that// fails, it will set the given string as the error detail.func Parse(errStr string) *Error &#123; e := new(Error) if err := json.Unmarshal([]byte(errStr), e); err != nil &#123; e.Code = http.StatusInternalServerError e.Message = err.Error() &#125; return e&#125; 使用1234567// newerr := New(200105001, \"something wrong\" )fmt.Println(\"err:\",err.Error())// parseerrParse := Parse(err.Error())fmt.Println(\"err code\": errParse.Code) 基于Error扩展出部分常用的方法： 401 Unauthorized 1234// Unauthorized generates a 401 error.func Unauthorized(format string, v ...interface&#123;&#125;) *Error &#123; return New(http.StatusUnauthorized, fmt.Sprintf(format, v...))&#125; 403 Forbidden 1234// Forbidden generates a 403 error.func Forbidden(format string, v ...interface&#123;&#125;) *Error &#123; return New(http.StatusForbidden, fmt.Sprintf(format, v...))&#125; 404 NotFound 1234// NotFound generates a 404 error.func NotFound(format string, v ...interface&#123;&#125;) *Error &#123; return New(http.StatusNotFound, fmt.Sprintf(format, v...))&#125; 405 MethodNotAllowed 1234// MethodNotAllowed generates a 405 error.func MethodNotAllowed(format string, v ...interface&#123;&#125;) *Error &#123; return New(http.StatusMethodNotAllowed, fmt.Sprintf(format, v...))&#125; 408 Timeout 1234// Timeout generates a 408 error.func Timeout(format string, v ...interface&#123;&#125;) *Error &#123; return New(http.StatusRequestTimeout, fmt.Sprintf(format, v...))&#125; 500 InternalServer1234// InternalServerError generates a 500 error.func InternalServer(format string, v ...interface&#123;&#125;) *Error &#123; return New(http.StatusInternalServerError, fmt.Sprintf(format, v...))&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://hongker.github.io/tags/golang/"}]},{"title":"高并发解决方案","slug":"高并发解决方案","date":"2020-03-30T05:23:45.000Z","updated":"2021-04-22T22:57:00.353Z","comments":true,"path":"2020/03/30/高并发解决方案/","link":"","permalink":"https://hongker.github.io/2020/03/30/高并发解决方案/","excerpt":"","text":"本篇文章介绍在公司做库存系统接触到的高并发场景下的优化方案。 什么是高并发From:百度百科 由于分布式系统的问世，高并发（High Concurrency）通常是指通过设计保证系统能够同时并行处理很多请求。通俗来讲，高并发是指在同一个时间点，有很多用户同时的访问同一 API 接口或者 Url 地址。它经常会发生在有大活跃用户量，用户高聚集的业务场景中。 优化方向静态资源采用CDN(Content Delivery Network)是指内容分发网络，处理如html,js,css,image等静态资源。 动态资源(重点) 选择合适的web服务常见的web如nginx,swoole的HttpServer,go的HttpServer，由于各自的特性(nginx的epoll模型，swoole与go的协程)，它们都是能够轻松因对万级并发的优秀web服务。 数据层优化 读写分离: 降低数据库的负载，提高查询性能。 使用数据库连接池,减少连接实例化的次数，节省了内存和时间，提升了效率。 NoSQL:相较于MySQL的select，采用更高效的Redis数据结构缓存数据。 内存: 相较于Redis缓存查询，使用内存来缓存数据会更高效。但维护成本较高，适用缓存不经常变更的数据。 业务层优化 使用异步的方式拆分耗时较长的业务。具体方案有消息队列，协程，异步任务等。 需请求三方服务接口事，选择Http长连接。 系统层优化 集群模式，当一台服务扛不住压的时候，就需要多增加N台，提升N倍的接口处理能力。","categories":[],"tags":[{"name":"系统架构","slug":"系统架构","permalink":"https://hongker.github.io/tags/系统架构/"}]},{"title":"单例模式","slug":"单例模式","date":"2018-12-24T12:56:49.000Z","updated":"2021-04-22T22:57:00.353Z","comments":true,"path":"2018/12/24/单例模式/","link":"","permalink":"https://hongker.github.io/2018/12/24/单例模式/","excerpt":"","text":"本篇文章主要介绍单例模式。 概念单例模式，是一种常用的软件设计模式。在它的核心结构中只包含一个被称为单例的特殊类。通过单例模式可以保证系统中，应用该模式的类一个类只有一个实例。即一个类只有一个对象实例。 优点 实例控制单例模式会阻止其他对象实例化其自己的单例对象的副本，从而确保所有对象都访问唯一实例。 灵活性因为类控制了实例化过程，所以类可以灵活更改实例化过程。 示例 Demo112345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?php/** * Singleton 单例类 * * @auther hongker * @date 2018-12-24 */class Singleton&#123; /** * 实例变量 * @var mixed */ private static $instance = null; /** * 获取实例 * @return Operate */ public static function getInstance() &#123; if (self::$instance == null) &#123; self::$instance = new Operate(); &#125; return self::$instance; &#125; &#125;/** * Operate 实际操作类 */class Operate&#123; /** * 具体函数 */ public function doSomething() :void &#123; echo \"do something..\\r\\n\"; &#125;&#125;// 调用方式$instance = Singleton::getInstance();$instance-&gt;doSomething(); 使用以上的模式，对外提供Singleton::getInstance()方法，避免暴露实例化Operate类。 Demo2因为$instance是个静态变量，仅需初始化一次，便可随处适用。但不适合包含可变属性值的场景。如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;?php/** * Singleton 单例类 * * @auther hongker * @date 2018-12-24 */class Singleton&#123; /** * 实例变量 * @var mixed */ private static $instance = null; /** * 获取实例 * @return Operate */ public static function getInstance() &#123; if (self::$instance == null) &#123; self::$instance = new Operate(); &#125; return self::$instance; &#125;&#125;/** * Operate 实际操作类 */class Operate&#123; /** * 操作名称 * @var string */ private $name; /** * 具体函数 */ public function doSomething() :void &#123; echo \"do something..\\r\\n\"; &#125; /** * 获取名称 * @return string */ public function getName() : string &#123; return $this-&gt;name; &#125; /** * 设置名称 * @param string $name 操作名称 */ public function setName(string $name):void &#123; $this-&gt;name = $name; &#125;&#125;// 第一次获取实例$instance1 = Singleton::getInstance();$instance1-&gt;setName(\"get\");echo \"instance1-&gt;getName: &#123;$instance1-&gt;getName()&#125;\\r\\n\";// 第二次获取实例$instance2 = Singleton::getInstance();$instance2-&gt;setName(\"post\");echo \"instance2-&gt;getName: &#123;$instance2-&gt;getName()&#125;\\r\\n\";// 此时实例1的name属性也会发生变动echo \"instance1-&gt;getName: &#123;$instance1-&gt;getName()&#125;\\r\\n\"; 输出如下:123instance1-&gt;getName: getinstance2-&gt;getName: postinstance1-&gt;getName: post 通过这两个实例可以很好的理解单例模式的适用方式，在实际开发过程中，还有很多的场景适用单例模式，但也有不适用的，所以需要多思考。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://hongker.github.io/tags/设计模式/"}]},{"title":"设计模式","slug":"designMode","date":"2018-12-24T12:31:45.000Z","updated":"2021-04-22T22:57:00.345Z","comments":true,"path":"2018/12/24/designMode/","link":"","permalink":"https://hongker.github.io/2018/12/24/designMode/","excerpt":"","text":"本篇文章主要介绍设计模式的相关概念。 什么是设计模式百度百科: 设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。 设计模式的作用使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。 设计原则 单一职责原则 规定一个类应该只有一个发生变化的原因。 开闭原则 模块应对扩展开放，而对修改关闭。 里氏替换原则 如果调用的是父类的话，那么换成子类也完全可以运行。 依赖反转原则 指在软件里面，把父类都替换成它的子类，程序的行为没有变化。 接口隔离原则 每一个接口应该是一种角色，不多不少，不干不该干的事，该干的事都要干。 聚合服用原则 在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分。 设计模式设计模式分为三种类型，共23种。 创建型模式：单例模式、抽象工厂模式、建造者模式、工厂模式、原型模式。 结构型模式：适配器模式、桥接模式、装饰模式、组合模式、外观模式、享元模式、代理模式。 行为型模式：模版方法模式、命令模式、迭代器模式、观察者模式、中介者模式、备忘录模式、解释器模式（Interpreter模式）、状态模式、策略模式、职责链模式(责任链模式)、访问者模式。 后面的章节将细说每一种模式。代码实例统一采用PHP实现，请各位耐心的PHPer挨个看下去，代码质量取决于思想，而思想就靠设计模式来表达。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://hongker.github.io/tags/设计模式/"}]},{"title":"docker命令说明","slug":"docker命令说明","date":"2018-12-13T13:42:26.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2018/12/13/docker命令说明/","link":"","permalink":"https://hongker.github.io/2018/12/13/docker命令说明/","excerpt":"","text":"本篇文章主要介绍docker的相关命令，如果没有安装docker的请查看上一篇文章《docker介绍与安装》。 查看所有命令我们不需要去死记硬背docker 的命令，记不住时可以直接运行docker help，立马展示所有的docker相关命令，如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859Management Commands: builder Manage builds config Manage Docker configs container Manage containers engine Manage the docker engine image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services stack Manage Docker stacks swarm Manage Swarm system Manage Docker trust Manage trust on Docker images volume Manage volumesCommands: attach Attach local standard input, output, and error streams to a running container build Build an image from a Dockerfile commit Create a new image from a container&apos;s changes cp Copy files/folders between a container and the local filesystem create Create a new container deploy Deploy a new stack or update an existing stack diff Inspect changes to files or directories on a container&apos;s filesystem events Get real time events from the server exec Run a command in a running container export Export a container&apos;s filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codes 常用命令查看docker信息1docker info 查看docker的版本1docker version 拉取镜像1docker pull hello-world 运行容器根据上面下载的镜像跑一个容器1docker run hello-world 更多内容后续补充。。","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://hongker.github.io/tags/docker/"}]},{"title":"docker介绍与安装","slug":"docker","date":"2018-12-11T14:02:10.000Z","updated":"2021-04-22T22:57:00.349Z","comments":true,"path":"2018/12/11/docker/","link":"","permalink":"https://hongker.github.io/2018/12/11/docker/","excerpt":"","text":"本篇文章主要介绍微服务的利器：Docker的使用。[TOC] 什么是docker引用百度百科的说明： Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 简单的说，就是将应用程序与运行环境合为一体，以docker容器的方式运行。 更多内容请查看 docker官方地址: https://www.docker.com Docker的优点 应用隔离性使用Docker运行应用，通过使用一个容器运行一个应用，实现应用间的解耦，避免单服务器直接运行多个应用，方便管理与维护。 环境标准化一个docker镜像不管在何处运行，其内部环境都是一致不变的，故不必担心应用移植时发生环境不对导致应用运行异常的情况。 部署简单化一条run命令即可运行一个容器，so easy。 安装Docker CE以下教程以ubuntu18.04 作为运行环境进行安装，其他环境请查看 官方文档 移除旧版本(非必要) 1sudo apt-get remove docker docker-engine docker.io 安装前提软件 12345sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common 添加官方GPG Key 12345curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \\ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot; 开始安装Docker CE(社区版) 1sudo apt-get install docker-ce 查看Docker 版本 1sudo docker version 输出如下:123456789101112131415161718Client: Version: 18.09.0 API version: 1.39 Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:49:01 2018 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.0 API version: 1.39 (minimum version 1.12) Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:16:44 2018 OS/Arch: linux/amd64 Experimental: false 至此安装成功! 其他说明免去sudo鉴于每次docker命令都要使用超级权限，所以每次都得在前面加sudo,为此我们通过以下命令，去掉烦人的sudo. 如果还没有 docker group 就添加一个 1sudo groupadd docker 将用户加入该 group 内 1sudo usermod -aG docker $USER 重启Docker 1sudo service docker restart 切换当前会话到新 group 1newgrp - docker 运行成功后，登出当前用户重新登录。再次输入 docker verion，即可。 使用中国镜像国外的镜像拉取比较慢，我们通过配置中国官方镜像，可以明显的提高镜像拉取速度。这里选择修改 /etc/docker/daemon.json 文件的方式。添加上 registry-mirrors 键值。 打开文件 1sudo vim /etc/docker/daemon.json 写入以下内容 123&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125; 重启Docker 1sudo systemctl restart docker 查看是否生效通过docker info查看是否生效，如下: 12Registry Mirrors: https://registry.docker-cn.com/ 配置已生效。 下一篇将介绍docker的相关命令。","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://hongker.github.io/tags/docker/"}]},{"title":"目标","slug":"target","date":"2018-12-10T14:09:31.000Z","updated":"2021-04-22T22:57:00.353Z","comments":true,"path":"2018/12/10/target/","link":"","permalink":"https://hongker.github.io/2018/12/10/target/","excerpt":"","text":"从今天开始写博客啦，坚持写文章，日积月累，我相信必有收获。写作内容有以下几个方面: 区块链我的工作主要是研究区块链技术，前期文章围绕这个技术点来开展。主要介绍开源项目Hyperledger Fabric部署区块链网络与其相关应用开发。 Golang写法有点另类的开发语言，但是很强大！ Linux我还是linux爱好者，平时办公的系统是用的Ubuntu 18.04，也会偶尔分享一些有用又有颜值的软件。 Docker现在的互联网已经离不开微服务的架构设计，而Docker就是实现微服务化的利器，偶尔也会发布一些Docker相关文章。 数据库平时用到的数据库主要是Mysql,MongoDb,Redis，偶尔也会写些相关内容。 PHP人家说写PHP的代码质量低，为什么会有这个现象？无巧不成书，确实PHP方便简单，写着顺手，面向过程写多了，随着时间与代码行数的增加，代码自然而然就复杂难懂。所以我想通过PHP去探讨设计模式，提升PHP代码的质量。 其他生命不息，学习不止！欢迎大家积极参与讨论。","categories":[],"tags":[]}]}